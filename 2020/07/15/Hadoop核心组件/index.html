<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Hadoop核心组件 | Atlantis</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Hadoop核心组件</h1><a id="logo" href="/.">Atlantis</a><p class="description">pomo16的博客</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/toolbox/"><i class="fa fa-book"> 工具箱</i></a><a href="/community/"><i class="fa fa-comments"> 常用社区</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Hadoop核心组件</h1><div class="post-meta">Jul 15, 2020<span> | </span><span class="category"><a href="/categories/data/">data</a></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 3.5k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 12</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="post-content"><p>目前的大数据生态基本都依赖于 Hadoop 生态，其可靠、高效、可伸缩，可以处理 PB 级别的数据。Hadoop 核心组件包括 HDFS、YARN 和 MapReduce。</p>
<a id="more"></a>
<h2 id="HDFS——分布式文件存储系统"><a href="#HDFS——分布式文件存储系统" class="headerlink" title="HDFS——分布式文件存储系统"></a>HDFS——分布式文件存储系统</h2><p>HDFS（Hadoop Distributed File System） 是 Hadoop 下的分布式文件存储系统，具有高容错、高吞吐量等特性，可以部署在低成本的硬件上。</p>
<h3 id="HDFS-架构"><a href="#HDFS-架构" class="headerlink" title="HDFS 架构"></a>HDFS 架构</h3><ul>
<li>HDFS 遵循主/从架构，由单个 NameNode(NN) 和多个 DataNode(DN) 组成：<ul>
<li>NameNode：负责执行有关文件系统命名空间的操作，例如打开、关闭、重命名等。它同时还负责集群元数据的存储，记录着文件中各个数据块的位置信息。</li>
<li>DataNode：负责提供来自文件系统客户端的读写请求，执行块的创建、删除等操作。</li>
</ul>
</li>
</ul>
<p><img src="https://pomo-blog.oss-cn-shenzhen.aliyuncs.com/article/308.png" style="zoom:50%;"></p>
<ul>
<li>HDFS 的文件系统命名空间的层次结构与大多数文件系统类似，支持目录和文件的创建、移动、删除等操作，支持配置用户和访问权限，但是不支持软硬链接。NameNode 负责维护文件系统命名空间，并记录变更。</li>
</ul>
<h3 id="数据复制备份"><a href="#数据复制备份" class="headerlink" title="数据复制备份"></a>数据复制备份</h3><p>Hadoop 的设计初衷是运行在廉价的机器上，这意味着硬件是不可靠的。HDFS 提供数据复制机制来保证容错性。HDFS 将每个文件存储为一系列<strong>块</strong>，每个块由多个副本来保证容错，块的大小和复制因子可以自行配置（默认块大小=128M，复制因子=3）。</p>
<p><img src="https://pomo-blog.oss-cn-shenzhen.aliyuncs.com/article/309.png" style="zoom:50%;"></p>
<ul>
<li>复制原理：HDFS 一般都会部署在不同机房的多台容器上，通常同一机房容器之间的网络带宽大于跨机房容器之间的网络带宽。因此 HDFS 采用机架感知副本放置策略（可自定义策略）。<ul>
<li>当复制因子为 3 ：在写入程序位于 DataNode 上时，就优先将写入文件的一个副本放置在该 DataNode 上，否则放在随机 DataNode 上。之后在另一个远程机房上的任意一个节点上放置另一个副本，并在该机房上的另一个节点上放置最后一个副本。此策略可以减少机房间的写入流量，从而提高写入性能。</li>
<li>当复制因子大于 3：随机确定第 4 个和之后副本的放置位置，同时保持每个机房的副本数量低于上限，上限值通常为 <code>（复制系数 - 1）/ 机架数量 + 2</code>，需要注意的是不允许同一个 DataNode 上具有同一个块的多个副本。</li>
</ul>
</li>
<li>副本选择：为了最大限度地减少带宽消耗和读取延迟，HDFS 在执行读取请求时，优先读取距离读取器最近的副本。如果在与读取器节点相同的机房上存在副本，则优先选择该副本。如果 HDFS 群集跨越多个数据中心，则优先选择本地数据中心上的副本。</li>
</ul>
<h3 id="架构稳定性"><a href="#架构稳定性" class="headerlink" title="架构稳定性"></a>架构稳定性</h3><ul>
<li><strong>心跳机制和重新复制</strong>：每个 DataNode 定期向 NameNode 发送心跳消息，如果超过指定时间没有收到心跳消息，则将 DataNode 标记为死亡。NameNode 不会将任何新的 IO 请求转发给标记为死亡的 DataNode，也不会再使用这些 DataNode 上的数据。 由于数据不再可用，可能会导致某些块的复制因子小于其指定值，NameNode 会跟踪这些块，并在必要的时候进行重新复制。</li>
<li><strong>数据的完整性</strong>：由于存储设备故障等原因，存储在 DataNode 上的数据块也会发生损坏。为了避免读取到已经损坏的数据而导致错误，HDFS 提供了数据完整性校验机制来保证数据的完整性。（当客户端创建 HDFS 文件时，它会计算文件的每个块的<strong>校验和</strong>，并将校验和存储在同一 HDFS 命名空间下的单独的隐藏文件中。当客户端检索文件内容时，它会验证从每个 DataNode 接收的数据是否与存储在关联校验和文件中的校验和匹配。如果匹配失败，则证明数据已经损坏，此时客户端会选择从其他 DataNode 获取该块的其他可用副本。）</li>
<li><strong>元数据的磁盘故障</strong>：<code>FsImage</code>(元数据检查点，包含整个 HDFS 的所有目录文件信息) 和 <code>EditLog</code>(写操作记录) 是 HDFS 的核心数据，这些数据的意外丢失可能会导致整个 HDFS 服务不可用。为了避免这个问题，可以配置 NameNode 使其支持 <code>FsImage</code> 和 <code>EditLog</code> 多副本同步，这样 <code>FsImage</code> 或 <code>EditLog</code> 的任何改变都会引起每个副本 <code>FsImage</code> 和 <code>EditLog</code> 的同步更新。</li>
<li><strong>支持快照</strong>：快照支持在特定时刻存储数据副本，在数据意外损坏时，可以通过回滚操作恢复到健康的数据状态。</li>
</ul>
<h3 id="HDFS-特点"><a href="#HDFS-特点" class="headerlink" title="HDFS 特点"></a>HDFS 特点</h3><ul>
<li>高容错：多副本方案</li>
<li>高吞吐：支持高吞吐数据访问而非低延迟</li>
<li>大文件支持：文档大小可达 GB 到 TB 级别</li>
<li>简单一致性模型：更适合一次写入多次读取 (write-once-read-many) 的访问模型，支持将内容追加到文件末尾，但不支持数据的随机访问，不能从文件任意位置新增数据</li>
<li>跨平台移植性：具有良好的跨平台移植性，大部分大数据计算框架都将其作为数据持久化首选方案</li>
</ul>
<h3 id="HDFS-写数据原理"><a href="#HDFS-写数据原理" class="headerlink" title="HDFS 写数据原理"></a>HDFS 写数据原理</h3><p><img src="https://pomo-blog.oss-cn-shenzhen.aliyuncs.com/article/310.png" style="zoom:60%;"></p>
<p>角色主要职能：</p>
<ul>
<li>client：文件切块</li>
<li>NameNode：为每个数据块分配 DataNode</li>
<li>DataNode：通过复制管道存储数据</li>
</ul>
<p>以客户端需要写入200M数据为例：</p>
<ol>
<li>用户向 client 提供 BLOCKSIZE（大文件会被切分成块，通常是 64M 或者 128M） 和 REPLICATION FACTOR（每个数据块会被存储在不同的地方，通常是3个）参数</li>
<li>client 根据参数将大文件切分成两个块（向上取整 ：200 / 128 = 2）</li>
<li>client 告知 NameNode 要求写入一个三备份的 128M 数据块</li>
<li>NameNode 分配 DataNode 并按照升序排列告知 client（DataNode1 DataNode2 DataNode3）</li>
<li>client 只将数据（和列表）发送给 DataNode1 存储，然后 DataNode1 将相同的数据传输给 DataNode2，以此类推直到最后一个节点（DataNode3）完成存储</li>
<li>当前块完成所有节点的存储后，会发送完成信号给 NameNode</li>
<li>NameNode 告知 client 当前数据块被成功存储和备份在 HDFS 中</li>
<li>client 重复 3~7 直到所有的数据块完成传输后，告知 NameNode 所有数据块已完成写入并请求关闭文件</li>
</ol>
<h3 id="HDFS-读数据原理"><a href="#HDFS-读数据原理" class="headerlink" title="HDFS 读数据原理"></a>HDFS 读数据原理</h3><ol>
<li>client 向 NameNode 通过文件名请求文件</li>
<li>NameNode 向 client 回复这个文件的所有数据块的列表和每个数据块所对应的 DataNode 的列表（按距离客户端远近排列）</li>
<li>client 按顺序下载数据块，向每个块对应的最近 DataNode（列表中的第一个）下载数据</li>
</ol>
<h3 id="HDFS-故障类型和检测方法"><a href="#HDFS-故障类型和检测方法" class="headerlink" title="HDFS 故障类型和检测方法"></a>HDFS 故障类型和检测方法</h3><p>由于 NameNode 挂掉基本全军覆没，所以一般主要关注 DataNode 的故障检测。</p>
<ul>
<li>故障1：节点故障<ul>
<li>故障检测：心跳机制（每3s发一次给 NameNode，NameNode 10min没收到就认为死亡）会排除死亡的 DataNode</li>
</ul>
</li>
<li>故障2：通讯故障（无法收发）<ul>
<li>故障检测：每次 client 发送数据给 DataNode 时，接收者都会回复一个应答信号。有重试机制，多次失败后 client 就会认为 DataNode 挂掉或者网络故障</li>
</ul>
</li>
<li>故障3：数据损坏<ul>
<li>故障检测：client 在发送数据时头部会包含校验和，且数据和校验和会被同时存储。所有的 DataNode 定时发送数据块报告给 NameNode。在发送报告之前 DataNode 会检测校验和是否正常，不会发送损坏的数据块信息，因此 NameNode 根据数量 diff 就可得知有多少数据损坏</li>
</ul>
</li>
</ul>
<h3 id="故障处理"><a href="#故障处理" class="headerlink" title="故障处理"></a>故障处理</h3><ul>
<li>写入故障：client 在向 DataNode 写入数据的时候会接收应答信号，如果收不到某个 DataNode 的信号，client 就会调整通道跳过此节点。此时这个数据块没有被充分备份，NameNode 会稍后处理（详见 DataNode 故障）</li>
<li>读取故障：如果最近的 DataNode 挂掉，client 就会从次近的节点上读取数据</li>
<li>DataNode 故障<ul>
<li>NameNode 维护了两张表，一个是数据块列表（记录每个数据块存储在哪些 DataNode 上），一个是 DataNode 列表（记录每个 DataNode 存储了哪些数据块）。如果 NameNode 发现一个 DataNode 上的数据块已经损坏，则会更新数据块表（将此 DN 移除出该表）；如果发现是某个 DataNode 挂掉，则会同时更新两张表。</li>
<li>未充分备份的数据块处理：NameNode 通过定时扫描数据块列表就可以得知未充分备份的数据块，其可以要求未有备份的新 DataNode 去已有备份的 DataNode 拷贝数据块，使数据块充分备份。不过 HDFS 不保证至少存活一份数据，只负责尽可能地选择合理的备份位置。</li>
</ul>
</li>
</ul>
<h2 id="YARN——集群资源管理器"><a href="#YARN——集群资源管理器" class="headerlink" title="YARN——集群资源管理器"></a>YARN——集群资源管理器</h2><p>Apache YARN（Yet Another Resource Negotiator）是 hadoop 2.0 引入的集群资源管理系统。用户可以将各种服务框架部署在 YARN 上，由 YARN 进行统一地管理和资源分配。</p>
<h3 id="YARN-架构"><a href="#YARN-架构" class="headerlink" title="YARN 架构"></a>YARN 架构</h3><p><img src="https://pomo-blog.oss-cn-shenzhen.aliyuncs.com/article/311.png" style="zoom:70%;"></p>
<ul>
<li><strong>ResourceManager</strong>：<code>ResourceManager</code> 通常在独立的机器上以后台进程的形式运行，它是整个集群资源的主要协调者和管理者。<code>ResourceManager</code> 负责给用户提交的所有应用程序分配资源，它根据应用程序优先级、队列容量、ACLs、数据位置等信息，做出决策，然后以共享的、安全的、多租户的方式制定分配策略，调度集群资源。</li>
<li><strong>NodeManager</strong>：<code>NodeManager</code> 是 YARN 集群中的每个具体节点的管理者。主要负责该节点内所有容器的生命周期的管理，监视资源和跟踪节点健康。具体如下：<ul>
<li>启动时向 <code>ResourceManager</code> 注册并定时发送心跳消息，等待 <code>ResourceManager</code> 的指令</li>
<li>维护 <code>Container</code> 的生命周期，监控 <code>Container</code> 的资源使用情况</li>
<li>管理任务运行时的相关依赖，根据 <code>ApplicationMaster</code> 的需要，在启动 <code>Container</code> 之前将需要的程序及其依赖拷贝到本地</li>
</ul>
</li>
</ul>
<ul>
<li><strong>ApplicationMaster</strong>：在用户提交一个应用程序时，YARN 会启动一个轻量级的进程 <code>ApplicationMaster</code>。<code>ApplicationMaster</code> 负责协调来自 <code>ResourceManager</code> 的资源，并通过 <code>NodeManager</code> 监视容器内资源的使用情况，同时还负责任务的监控与容错。具体如下：<ul>
<li>根据应用的运行状态来决定动态计算资源需求</li>
<li>向 <code>ResourceManager</code> 申请资源，监控申请的资源的使用情况</li>
<li>跟踪任务状态和进度，报告资源的使用情况和应用的进度信息</li>
<li>负责任务的容错</li>
</ul>
</li>
<li><strong>Container</strong>：<code>Container</code> 是 YARN 中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。当 AM 向 RM 申请资源时，RM 为 AM 返回的资源是用 <code>Container</code> 表示的。YARN 会为每个任务分配一个 <code>Container</code>，该任务只能使用该 <code>Container</code> 中描述的资源。<code>ApplicationMaster</code> 可在 <code>Container</code> 内运行任何类型的任务。例如，<code>MapReduce ApplicationMaster</code> 请求一个容器来启动 map 或 reduce 任务，而 <code>Giraph ApplicationMaster</code> 请求一个容器来运行 Giraph 任务。</li>
</ul>
<h3 id="YARN-工作原理简述"><a href="#YARN-工作原理简述" class="headerlink" title="YARN 工作原理简述"></a>YARN 工作原理简述</h3><p><img src="https://pomo-blog.oss-cn-shenzhen.aliyuncs.com/article/312.png" alt></p>
<ol>
<li><code>Client</code> 提交作业到 YARN 上</li>
<li><code>Resource Manager</code> 选择一个 <code>Node Manager</code>，启动一个 <code>Container</code> 并运行 <code>Application Master</code> 实例</li>
<li><code>Application Master</code> 根据实际需要向 <code>Resource Manager</code> 请求更多的 <code>Container</code> 资源（如果作业很小, 应用管理器会选择在其自己的 JVM 中运行任务）</li>
<li><code>Application Master</code> 通过获取到的 <code>Container</code> 资源执行分布式计算</li>
</ol>
<h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><p>Hadoop MapReduce 是一个并行分布式计算框架，用于编写批处理应用程序。编写好的程序可以提交到 Hadoop 集群上用于并行处理大规模的数据集。</p>
<p>MapReduce 主要有三个阶段：</p>
<ul>
<li>Map 阶段：map 或者 mapper 将输入的数据集拆分成独立块。通常这些输入数据会存放在 HDFS，输入文件会被逐行输入到 mapper 函数中，mapper 函数会并行处理并创建一些数据块。</li>
<li>Shuffle 阶段：Map 转换到 Reduce 的中间过程，一般有 partitions、sort、combine 等操作</li>
<li>Reduce 阶段：对各个数据块上的数据并行运算，输出最终结果</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(input) &lt;k1, v1&gt; -&gt; map -&gt; &lt;k2, v2&gt; -&gt; shuffle -&gt; &lt;k2, v2&gt; -&gt; reduce -&gt; &lt;k3, v3&gt; (output)</span><br></pre></td></tr></table></figure>
<h3 id="MapReduce-具体流程"><a href="#MapReduce-具体流程" class="headerlink" title="MapReduce 具体流程"></a>MapReduce 具体流程</h3><p>以基本的词频统计为例：</p>
<p><img src="https://pomo-blog.oss-cn-shenzhen.aliyuncs.com/article/313.png" alt style="zoom:50%;"></p>
<ul>
<li>input：读取文件</li>
<li>splitting：文件按行拆分，K1 为行数，V1 为对应行的文本内容</li>
<li>mapping：每行按空格拆分，拆分得到 List(K2, V2)，K2 代表每个单词，V2 代表出现次数</li>
<li>shuffling：由于 Mapping 操作可能分发到不同的节点上并行运算，因此 shuffling 需要把相同 key 的数据转发到相同节点上合并。K2 为每个单词，List(V2) 为可迭代集合，V2 为 Mapping 中的 V2</li>
<li>reducing：对 List(V2) 进行规约求和，最终输出词频统计结果</li>
</ul>
<p>MapReduce 编程模型中 <code>splitting</code> 和 <code>shuffing</code> 操作都是由框架实现的，需要我们自己编程实现的只有 <code>mapping</code> 和 <code>reducing</code>，这也就是 MapReduce 这个称呼的来源。</p>
<h3 id="Combiner-Partitioner-and-Sort"><a href="#Combiner-Partitioner-and-Sort" class="headerlink" title="Combiner, Partitioner and Sort"></a>Combiner, Partitioner and Sort</h3><p>Combiner、 Partioner 和 Sort 是 map 运算之后的可选操作，他们属于 shuffle 阶段的实现方式。</p>
<ul>
<li><p>Combiner：执行本地化的 reduce 操作，在 map 计算之后先简单地在每个节点本地进行重复 key 的合并</p>
</li>
<li><p>Partitioner：分类器，将每个 map 的输出结果分发到新的节点上，具有相同 key 值的数据会分发到同一节点</p>
</li>
<li><p>Sort：key 有序排列，一般结合了 shuffle 操作</p>
<p><img src="https://pomo-blog.oss-cn-shenzhen.aliyuncs.com/article/314.png" style="zoom:50%;"></p>
</li>
</ul>
</div><div class="tags"><a href="/tags/Hadoop/">Hadoop</a></div><div class="post-nav"><a class="pre" href="/2020/07/15/Hive/">Hive</a><a class="next" href="/2020/06/05/Docker安装ES及IK分词器/">Docker安装ES相关</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/ElasticSearch/">ElasticSearch</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python/">Python</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/blog/">blog</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/data/">data</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/git/">git</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/go/">go</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a><span class="category-list-count">19</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/java/Redis/">Redis</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/jsp/">jsp</a><span class="category-list-count">2</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/java/jsp/Servlet/">Servlet</a><span class="category-list-count">1</span></li></ul></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/mysql/">mysql</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/projects/">projects</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/web/">web</a><span class="category-list-count">7</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/web/docker/">docker</a><span class="category-list-count">2</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/工具/">工具</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/微信小程序/">微信小程序</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/操作系统/">操作系统</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法/">算法</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/设计模式/">设计模式</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/jQuery/" style="font-size: 15px;">jQuery</a> <a href="/tags/ElasticSearch/" style="font-size: 15px;">ElasticSearch</a> <a href="/tags/Eclipse/" style="font-size: 15px;">Eclipse</a> <a href="/tags/go/" style="font-size: 15px;">go</a> <a href="/tags/http/" style="font-size: 15px;">http</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/jsp/" style="font-size: 15px;">jsp</a> <a href="/tags/JavaWeb/" style="font-size: 15px;">JavaWeb</a> <a href="/tags/rpc/" style="font-size: 15px;">rpc</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/vim/" style="font-size: 15px;">vim</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/七牛云/" style="font-size: 15px;">七牛云</a> <a href="/tags/CDN/" style="font-size: 15px;">CDN</a> <a href="/tags/blog/" style="font-size: 15px;">blog</a> <a href="/tags/RSS/" style="font-size: 15px;">RSS</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/ftp/" style="font-size: 15px;">ftp</a> <a href="/tags/设计模式/" style="font-size: 15px;">设计模式</a> <a href="/tags/projects/" style="font-size: 15px;">projects</a> <a href="/tags/jre/" style="font-size: 15px;">jre</a> <a href="/tags/jdk/" style="font-size: 15px;">jdk</a> <a href="/tags/微信小程序/" style="font-size: 15px;">微信小程序</a> <a href="/tags/Servlet/" style="font-size: 15px;">Servlet</a> <a href="/tags/IO/" style="font-size: 15px;">IO</a> <a href="/tags/Hadoop/" style="font-size: 15px;">Hadoop</a> <a href="/tags/hive/" style="font-size: 15px;">hive</a> <a href="/tags/集合/" style="font-size: 15px;">集合</a> <a href="/tags/Spring/" style="font-size: 15px;">Spring</a> <a href="/tags/操作系统/" style="font-size: 15px;">操作系统</a> <a href="/tags/数组/" style="font-size: 15px;">数组</a> <a href="/tags/String/" style="font-size: 15px;">String</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/mysql/" style="font-size: 15px;">mysql</a> <a href="/tags/Redis/" style="font-size: 15px;">Redis</a> <a href="/tags/JVM/" style="font-size: 15px;">JVM</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/07/15/Hive/">Hive</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/07/15/Hadoop核心组件/">Hadoop核心组件</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/05/Docker安装ES及IK分词器/">Docker安装ES相关</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/03/Go-数组和切片/">Go 数组、字符串和切片</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/06/02/Go-struct-类型Channel/">Go struct{}类型Channel</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/05/16/Concurrency-in-Go/">Concurrency in Go</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/04/22/Docker搭建FTP/">Docker搭建FTP</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/30/Go-Garbage-Collection/">Go Garbage Collection</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/20/git/">git</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/18/ElasticSearch/">ElasticSearch</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/pomo16" title="我的Github" target="_blank">我的Github</a><ul></ul><a href="https://blog.csdn.net/pomo16" title="我的CSDN" target="_blank">我的CSDN</a><ul></ul><a href="http://pomo16.coding.me/" title="我的老博客(荒废已久)" target="_blank">我的老博客(荒废已久)</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">Atlantis.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script><!-- 添加点击爱心功能--><script type="text/javascript" src="/js/clicklove.js?v=0.0.0"></script></div></body></html>