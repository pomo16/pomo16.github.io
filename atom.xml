<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Atlantis</title>
  
  <subtitle>pomo16的博客</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-07-15T15:29:19.178Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>pomo16</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hive</title>
    <link href="http://yoursite.com/2020/07/15/Hive/"/>
    <id>http://yoursite.com/2020/07/15/Hive/</id>
    <published>2020-07-15T15:27:41.000Z</published>
    <updated>2020-07-15T15:29:19.178Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Hive-简介"><a href="#Hive-简介" class="headerlink" title="Hive 简介"></a>Hive 简介</h2><p>Hive 是一个构建在 Hadoop 之上的数据仓库，它可以将结构化的数据文件映射成表，并提供类 SQL 查询功能，用于查询的 SQL 语句会被转化为 MapReduce 作业，然后提交到 Hadoop 上运行。有以下特点：</p><ul><li>简单、易上手（sql）</li><li>灵活性高，可自定义用户函数（UDF）和存储格式</li><li>为超大的数据集设计的计算和存储能力，集群扩展容易</li><li>统一的元数据管理，可与 presto／impala／sparksql 等共享数据</li><li>执行延迟高，不适合做数据的实时处理，但适合做海量数据的离线处理</li></ul><h2 id="Hive-体系架构"><a href="#Hive-体系架构" class="headerlink" title="Hive 体系架构"></a>Hive 体系架构</h2><p><img src="http://qnya.pomo16.club/315.png" alt style="zoom:50%;"></p><ul><li><strong>command-line shell &amp; thrift/jdbc</strong>：数据操作方式<ul><li><strong>command-line shell</strong>：通过 hive 命令行的方式来操作数据</li><li><strong>thrift/jdbc</strong>：通过 thrift 协议按照标准的 JDBC 的方式操作数据</li></ul></li><li><strong>Metastore</strong>：一个管理库表元数据的服务<ul><li>客户端连接 Metastore 服务，Metastore 再去连接 MySQL 数据库来存取元数据。有了 Metastore 服务，就可以有多个客户端同时连接，而且这些客户端不需要知道 MySQL 数据库的用户名和密码，只需要连接 Metastore 服务即可。</li></ul></li><li><strong>HQL 执行流程</strong><ul><li>语法解析：Antlr 定义 SQL 的语法规则，完成 SQL 词法、语法解析，将 SQL 转化为抽象语法树 AST Tree</li><li>语义解析：遍历 AST Tree，抽象出查询的基本组成单元 QueryBlock</li><li>生成逻辑执行计划：遍历 QueryBlock，翻译为执行操作树 OperatorTree</li><li>优化逻辑执行计划：逻辑层优化器进行 OperatorTree 变换，合并不必要的 ReduceSinkOperator，减少 shuffle 数据量</li><li>生成物理执行计划：遍历 OperatorTree，翻译为 MapReduce 任务</li><li>优化物理执行计划：物理层优化器进行 MapReduce 任务的变换，生成最终的执行计划</li></ul></li></ul><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><h3 id="基本数据类型"><a href="#基本数据类型" class="headerlink" title="基本数据类型"></a>基本数据类型</h3><table><thead><tr><th>大类</th><th>类型</th></tr></thead><tbody><tr><td><strong>Integers（整型）</strong></td><td>TINYINT（1 字节的有符号整数）、SMALLINT（2 字节的有符号整数）、INT（4 字节的有符号整数）、BIGINT（8 字节的有符号整数）</td></tr><tr><td><strong>Boolean（布尔型）</strong></td><td>BOOLEAN（TRUE/FALSE）</td></tr><tr><td><strong>Floating point numbers（浮点型）</strong></td><td>FLOAT（单精度浮点型）、DOUBLE（双精度浮点型）</td></tr><tr><td><strong>Fixed point numbers（定点数）</strong></td><td>DECIMAL（用户自定义精度定点数，比如 DECIMAL(7,2)）</td></tr><tr><td><strong>String types（字符串）</strong></td><td>STRING（指定字符集的字符序列）、VARCHAR（具有最大长度限制的字符序列）、 CHAR（固定长度的字符序列）</td></tr><tr><td><strong>Date and time types（日期时间类型）</strong></td><td>TIMESTAMP（时间戳）、TIMESTAMP WITH LOCAL TIME ZONE（时间戳，纳秒精度）、DATE（日期类型）</td></tr><tr><td><strong>Binary types（二进制类型）</strong></td><td>BINARY（字节序列）</td></tr></tbody></table><p>TIMESTAMP 和 TIMESTAMP WITH LOCAL TIME ZONE 的区别：</p><ul><li><strong>TIMESTAMP WITH LOCAL TIME ZONE</strong>：用户提交时间给数据库时，会被转换成数据库所在的时区来保存。查询时则按照查询客户端的不同，转换为查询客户端所在时区的时间</li><li><strong>TIMESTAMP</strong> ：提交什么时间就保存什么时间，查询时也不做任何转换</li></ul><h3 id="隐式转换"><a href="#隐式转换" class="headerlink" title="隐式转换"></a>隐式转换</h3><p>Hive 中基本数据类型遵循以下的层次结构，按照这个层次结构，子类型到祖先类型允许隐式转换。例如 INT 类型的数据允许隐式转换为 BIGINT 类型。额外注意的是：按照类型层次结构允许将 STRING 类型隐式转换为 DOUBLE 类型。</p><p><img src="/Users/bytedance/Desktop/blog/temp/316.png" alt="image-20200712102125576" style="zoom:50%;"></p><h3 id="复杂类型"><a href="#复杂类型" class="headerlink" title="复杂类型"></a>复杂类型</h3><table><thead><tr><th>类型</th><th>描述</th><th>示例</th></tr></thead><tbody><tr><td><strong>STRUCT</strong></td><td>类似于对象，是字段的集合，字段的类型可以不同，可以使用 <code>名称.字段名</code> 方式进行访问</td><td>STRUCT (‘xiaoming’, 12 , ‘2018-12-12’)</td></tr><tr><td><strong>MAP</strong></td><td>键值对的集合，可以使用 <code>名称[key]</code> 的方式访问对应的值</td><td>map(‘a’, 1, ‘b’, 2)</td></tr><tr><td><strong>ARRAY</strong></td><td>数组是一组具有相同类型和名称的变量的集合，可以使用 <code>名称[index]</code> 访问对应的值</td><td>ARRAY(‘a’, ‘b’, ‘c’, ‘d’)</td></tr></tbody></table><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> students(</span><br><span class="line">  <span class="keyword">name</span>      <span class="keyword">STRING</span>,   <span class="comment">-- 姓名</span></span><br><span class="line">  age       <span class="built_in">INT</span>,      <span class="comment">-- 年龄</span></span><br><span class="line">  subject   <span class="built_in">ARRAY</span>&lt;<span class="keyword">STRING</span>&gt;,   <span class="comment">--学科</span></span><br><span class="line">  score     <span class="keyword">MAP</span>&lt;<span class="keyword">STRING</span>,<span class="built_in">FLOAT</span>&gt;,  <span class="comment">--各个学科考试成绩</span></span><br><span class="line">  address   <span class="keyword">STRUCT</span>&lt;houseNumber:<span class="built_in">int</span>, street:<span class="keyword">STRING</span>, city:<span class="keyword">STRING</span>, province：<span class="keyword">STRING</span>&gt;  <span class="comment">--家庭居住地址</span></span><br><span class="line">) <span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">"\t"</span>;</span><br></pre></td></tr></table></figure><h3 id="内容格式"><a href="#内容格式" class="headerlink" title="内容格式"></a>内容格式</h3><p>当数据存储在文本文件中，必须按照一定格式区别行和列，如使用逗号作为分隔符的 CSV 文件 (Comma-Separated Values) 或者使用制表符作为分隔值的 TSV 文件 (Tab-Separated Values)。但此时也存在一个缺点，就是正常的文件内容中也可能出现逗号或者制表符。</p><p>所以 Hive 默认使用了几个平时很少出现的字符，这些字符一般不会作为内容出现在文件中。Hive 默认的行和列分隔符如下表所示：</p><table><thead><tr><th>分隔符</th><th>描述</th></tr></thead><tbody><tr><td><strong>\n</strong></td><td>对于文本文件来说，每行是一条记录，所以可以使用换行符来分割记录</td></tr><tr><td><strong>^A (Ctrl+A)</strong></td><td>分割字段 (列)，在 CREATE TABLE 语句中也可以使用八进制编码 <code>\001</code> 来表示</td></tr><tr><td><strong>^B</strong></td><td>用于分割 ARRAY 或者 STRUCT 中的元素，或者用于 MAP 中键值对之间的分割， 在 CREATE TABLE 语句中也可以使用八进制编码 <code>\002</code> 表示</td></tr><tr><td><strong>^C</strong></td><td>用于 MAP 中键和值之间的分割，在 CREATE TABLE 语句中也可以使用八进制编码 <code>\003</code> 表示</td></tr></tbody></table><p>使用示例：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> page_view(viewTime <span class="built_in">INT</span>, userid <span class="built_in">BIGINT</span>)</span><br><span class="line"> <span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span></span><br><span class="line">   <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\001'</span></span><br><span class="line">   COLLECTION ITEMS <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\002'</span></span><br><span class="line">   <span class="keyword">MAP</span> <span class="keyword">KEYS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\003'</span></span><br><span class="line"> <span class="keyword">STORED</span> <span class="keyword">AS</span> SEQUENCEFILE;</span><br></pre></td></tr></table></figure><h2 id="存储格式"><a href="#存储格式" class="headerlink" title="存储格式"></a>存储格式</h2><h3 id="支持的存储格式"><a href="#支持的存储格式" class="headerlink" title="支持的存储格式"></a>支持的存储格式</h3><p>Hive 会在 HDFS 为每个数据库上创建一个目录，数据库中的表是该目录的子目录，表中的数据会以文件的形式存储在对应的表目录下。Hive 支持以下几种文件存储格式：</p><table><thead><tr><th>格式</th><th>说明</th></tr></thead><tbody><tr><td><strong>TextFile</strong></td><td>存储为纯文本文件。 这是 Hive 默认的文件存储格式。这种存储方式数据不做压缩，磁盘开销大，数据解析开销大。</td></tr><tr><td><strong>SequenceFile</strong></td><td>SequenceFile 是 Hadoop API 提供的一种二进制文件，它将数据以&lt;key,value&gt;的形式序列化到文件中。这种二进制文件内部使用 Hadoop 的标准的 Writable 接口实现序列化和反序列化。它与 Hadoop API 中的 MapFile 是互相兼容的。Hive 中的 SequenceFile 继承自 Hadoop API 的 SequenceFile，不过它的 key 为空，使用 value 存放实际的值，这样是为了避免 MR 在运行 map 阶段进行额外的排序操作。</td></tr><tr><td><strong>RCFile</strong></td><td>RCFile 文件格式是 FaceBook 开源的一种 Hive 的文件存储格式，首先将表分为几个行组，对每个行组内的数据按列存储，每一列的数据都是分开存储。</td></tr><tr><td><strong>ORC Files</strong></td><td>ORC 是在一定程度上扩展了 RCFile，是对 RCFile 的优化。</td></tr><tr><td><strong>Avro Files</strong></td><td>Avro 是一个数据序列化系统，设计用于支持大批量数据交换的应用。它的主要特点有：支持二进制序列化方式，可以便捷，快速地处理大量数据；动态语言友好，Avro 提供的机制使动态语言可以方便地处理 Avro 数据。</td></tr><tr><td><strong>Parquet</strong></td><td>Parquet 是基于 Dremel 的数据模型和算法实现的，面向分析型业务的列式存储格式。它通过按列进行高效压缩和特殊的编码技术，从而在降低存储空间的同时提高了 IO 效率。</td></tr></tbody></table><blockquote><p>以上压缩格式中 ORC 和 Parquet 的综合性能突出，使用较为广泛，推荐使用这两种格式。</p></blockquote><h3 id="指定存储格式"><a href="#指定存储格式" class="headerlink" title="指定存储格式"></a>指定存储格式</h3><p>通常在创建表的时候使用 <code>STORED AS</code> 参数指定：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> page_view(viewTime <span class="built_in">INT</span>, userid <span class="built_in">BIGINT</span>)</span><br><span class="line"> <span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span></span><br><span class="line">   <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\001'</span></span><br><span class="line">   COLLECTION ITEMS <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\002'</span></span><br><span class="line">   <span class="keyword">MAP</span> <span class="keyword">KEYS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\003'</span></span><br><span class="line"> <span class="keyword">STORED</span> <span class="keyword">AS</span> SEQUENCEFILE;</span><br></pre></td></tr></table></figure><ul><li>STORED AS TEXTFILE</li><li>STORED AS SEQUENCEFILE</li><li>STORED AS ORC</li><li>STORED AS PARQUET</li><li>STORED AS AVRO</li><li>STORED AS RCFILE</li></ul><h2 id="内部表和外部表"><a href="#内部表和外部表" class="headerlink" title="内部表和外部表"></a>内部表和外部表</h2><p>内部表又叫做管理表 (Managed/Internal Table)，创建表时不做任何指定，默认创建的就是内部表。想要创建外部表 (External Table)，则需要使用 External 进行修饰。 内部表和外部表主要区别如下：</p><table><thead><tr><th></th><th>内部表</th><th>外部表</th></tr></thead><tbody><tr><td>数据存储位置</td><td>内部表数据存储的位置由 hive.metastore.warehouse.dir 参数指定，默认情况下表的数据存储在 HDFS 的 <code>/user/hive/warehouse/数据库名.db/表名/</code> 目录下</td><td>外部表数据的存储位置创建表时由 <code>Location</code> 参数指定；</td></tr><tr><td>导入数据</td><td>在导入数据到内部表，内部表将数据移动到自己的数据仓库目录下，数据的生命周期由 Hive 来进行管理</td><td>外部表不会将数据移动到自己的数据仓库目录下，只是在元数据中存储了数据的位置</td></tr><tr><td>删除表</td><td>删除元数据（metadata）和文件</td><td>只删除元数据（metadata）</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      介绍Hive基本架构等基础知识
    
    </summary>
    
      <category term="data" scheme="http://yoursite.com/categories/data/"/>
    
    
      <category term="hive" scheme="http://yoursite.com/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop核心组件</title>
    <link href="http://yoursite.com/2020/07/15/Hadoop%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6/"/>
    <id>http://yoursite.com/2020/07/15/Hadoop核心组件/</id>
    <published>2020-07-15T15:24:37.000Z</published>
    <updated>2020-07-15T15:27:22.027Z</updated>
    
    <content type="html"><![CDATA[<p>目前的大数据生态基本都依赖于 Hadoop 生态，其可靠、高效、可伸缩，可以处理 PB 级别的数据。Hadoop 核心组件包括 HDFS、YARN 和 MapReduce。</p><a id="more"></a><h2 id="HDFS——分布式文件存储系统"><a href="#HDFS——分布式文件存储系统" class="headerlink" title="HDFS——分布式文件存储系统"></a>HDFS——分布式文件存储系统</h2><p>HDFS（Hadoop Distributed File System） 是 Hadoop 下的分布式文件存储系统，具有高容错、高吞吐量等特性，可以部署在低成本的硬件上。</p><h3 id="HDFS-架构"><a href="#HDFS-架构" class="headerlink" title="HDFS 架构"></a>HDFS 架构</h3><ul><li>HDFS 遵循主/从架构，由单个 NameNode(NN) 和多个 DataNode(DN) 组成：<ul><li>NameNode：负责执行有关文件系统命名空间的操作，例如打开、关闭、重命名等。它同时还负责集群元数据的存储，记录着文件中各个数据块的位置信息。</li><li>DataNode：负责提供来自文件系统客户端的读写请求，执行块的创建、删除等操作。</li></ul></li></ul><p><img src="http://qnya.pomo16.club/308.png" style="zoom:50%;"></p><ul><li>HDFS 的文件系统命名空间的层次结构与大多数文件系统类似，支持目录和文件的创建、移动、删除等操作，支持配置用户和访问权限，但是不支持软硬链接。NameNode 负责维护文件系统命名空间，并记录变更。</li></ul><h3 id="数据复制备份"><a href="#数据复制备份" class="headerlink" title="数据复制备份"></a>数据复制备份</h3><p>Hadoop 的设计初衷是运行在廉价的机器上，这意味着硬件是不可靠的。HDFS 提供数据复制机制来保证容错性。HDFS 将每个文件存储为一系列<strong>块</strong>，每个块由多个副本来保证容错，块的大小和复制因子可以自行配置（默认块大小=128M，复制因子=3）。</p><p><img src="http://qnya.pomo16.club/309.png" style="zoom:50%;"></p><ul><li>复制原理：HDFS 一般都会部署在不同机房的多台容器上，通常同一机房容器之间的网络带宽大于跨机房容器之间的网络带宽。因此 HDFS 采用机架感知副本放置策略（可自定义策略）。<ul><li>当复制因子为 3 ：在写入程序位于 DataNode 上时，就优先将写入文件的一个副本放置在该 DataNode 上，否则放在随机 DataNode 上。之后在另一个远程机房上的任意一个节点上放置另一个副本，并在该机房上的另一个节点上放置最后一个副本。此策略可以减少机房间的写入流量，从而提高写入性能。</li><li>当复制因子大于 3：随机确定第 4 个和之后副本的放置位置，同时保持每个机房的副本数量低于上限，上限值通常为 <code>（复制系数 - 1）/ 机架数量 + 2</code>，需要注意的是不允许同一个 DataNode 上具有同一个块的多个副本。</li></ul></li><li>副本选择：为了最大限度地减少带宽消耗和读取延迟，HDFS 在执行读取请求时，优先读取距离读取器最近的副本。如果在与读取器节点相同的机房上存在副本，则优先选择该副本。如果 HDFS 群集跨越多个数据中心，则优先选择本地数据中心上的副本。</li></ul><h3 id="架构稳定性"><a href="#架构稳定性" class="headerlink" title="架构稳定性"></a>架构稳定性</h3><ul><li><strong>心跳机制和重新复制</strong>：每个 DataNode 定期向 NameNode 发送心跳消息，如果超过指定时间没有收到心跳消息，则将 DataNode 标记为死亡。NameNode 不会将任何新的 IO 请求转发给标记为死亡的 DataNode，也不会再使用这些 DataNode 上的数据。 由于数据不再可用，可能会导致某些块的复制因子小于其指定值，NameNode 会跟踪这些块，并在必要的时候进行重新复制。</li><li><strong>数据的完整性</strong>：由于存储设备故障等原因，存储在 DataNode 上的数据块也会发生损坏。为了避免读取到已经损坏的数据而导致错误，HDFS 提供了数据完整性校验机制来保证数据的完整性。（当客户端创建 HDFS 文件时，它会计算文件的每个块的<strong>校验和</strong>，并将校验和存储在同一 HDFS 命名空间下的单独的隐藏文件中。当客户端检索文件内容时，它会验证从每个 DataNode 接收的数据是否与存储在关联校验和文件中的校验和匹配。如果匹配失败，则证明数据已经损坏，此时客户端会选择从其他 DataNode 获取该块的其他可用副本。）</li><li><strong>元数据的磁盘故障</strong>：<code>FsImage</code>(元数据检查点，包含整个 HDFS 的所有目录文件信息) 和 <code>EditLog</code>(写操作记录) 是 HDFS 的核心数据，这些数据的意外丢失可能会导致整个 HDFS 服务不可用。为了避免这个问题，可以配置 NameNode 使其支持 <code>FsImage</code> 和 <code>EditLog</code> 多副本同步，这样 <code>FsImage</code> 或 <code>EditLog</code> 的任何改变都会引起每个副本 <code>FsImage</code> 和 <code>EditLog</code> 的同步更新。</li><li><strong>支持快照</strong>：快照支持在特定时刻存储数据副本，在数据意外损坏时，可以通过回滚操作恢复到健康的数据状态。</li></ul><h3 id="HDFS-特点"><a href="#HDFS-特点" class="headerlink" title="HDFS 特点"></a>HDFS 特点</h3><ul><li>高容错：多副本方案</li><li>高吞吐：支持高吞吐数据访问而非低延迟</li><li>大文件支持：文档大小可达 GB 到 TB 级别</li><li>简单一致性模型：更适合一次写入多次读取 (write-once-read-many) 的访问模型，支持将内容追加到文件末尾，但不支持数据的随机访问，不能从文件任意位置新增数据</li><li>跨平台移植性：具有良好的跨平台移植性，大部分大数据计算框架都将其作为数据持久化首选方案</li></ul><h3 id="HDFS-写数据原理"><a href="#HDFS-写数据原理" class="headerlink" title="HDFS 写数据原理"></a>HDFS 写数据原理</h3><p><img src="http://qnya.pomo16.club/310.png" style="zoom:30%;"></p><p>角色主要职能：</p><ul><li>client：文件切块</li><li>NameNode：为每个数据块分配 DataNode</li><li>DataNode：通过复制管道存储数据</li></ul><p>以客户端需要写入200M数据为例：</p><ol><li>用户向 client 提供 BLOCKSIZE（大文件会被切分成块，通常是 64M 或者 128M） 和 REPLICATION FACTOR（每个数据块会被存储在不同的地方，通常是3个）参数</li><li>client 根据参数将大文件切分成两个块（向上取整 ：200 / 128 = 2）</li><li>client 告知 NameNode 要求写入一个三备份的 128M 数据块</li><li>NameNode 分配 DataNode 并按照升序排列告知 client（DataNode1 DataNode2 DataNode3）</li><li>client 只将数据（和列表）发送给 DataNode1 存储，然后 DataNode1 将相同的数据传输给 DataNode2，以此类推直到最后一个节点（DataNode3）完成存储</li><li>当前块完成所有节点的存储后，会发送完成信号给 NameNode</li><li>NameNode 告知 client 当前数据块被成功存储和备份在 HDFS 中</li><li>client 重复 3~7 直到所有的数据块完成传输后，告知 NameNode 所有数据块已完成写入并请求关闭文件</li></ol><h3 id="HDFS-读数据原理"><a href="#HDFS-读数据原理" class="headerlink" title="HDFS 读数据原理"></a>HDFS 读数据原理</h3><ol><li>client 向 NameNode 通过文件名请求文件</li><li>NameNode 向 client 回复这个文件的所有数据块的列表和每个数据块所对应的 DataNode 的列表（按距离客户端远近排列）</li><li>client 按顺序下载数据块，向每个块对应的最近 DataNode（列表中的第一个）下载数据</li></ol><h3 id="HDFS-故障类型和检测方法"><a href="#HDFS-故障类型和检测方法" class="headerlink" title="HDFS 故障类型和检测方法"></a>HDFS 故障类型和检测方法</h3><p>由于 NameNode 挂掉基本全军覆没，所以一般主要关注 DataNode 的故障检测。</p><ul><li>故障1：节点故障<ul><li>故障检测：心跳机制（每3s发一次给 NameNode，NameNode 10min没收到就认为死亡）会排除死亡的 DataNode</li></ul></li><li>故障2：通讯故障（无法收发）<ul><li>故障检测：每次 client 发送数据给 DataNode 时，接收者都会回复一个应答信号。有重试机制，多次失败后 client 就会认为 DataNode 挂掉或者网络故障</li></ul></li><li>故障3：数据损坏<ul><li>故障检测：client 在发送数据时头部会包含校验和，且数据和校验和会被同时存储。所有的 DataNode 定时发送数据块报告给 NameNode。在发送报告之前 DataNode 会检测校验和是否正常，不会发送损坏的数据块信息，因此 NameNode 根据数量 diff 就可得知有多少数据损坏</li></ul></li></ul><h3 id="故障处理"><a href="#故障处理" class="headerlink" title="故障处理"></a>故障处理</h3><ul><li>写入故障：client 在向 DataNode 写入数据的时候会接收应答信号，如果收不到某个 DataNode 的信号，client 就会调整通道跳过此节点。此时这个数据块没有被充分备份，NameNode 会稍后处理（详见 DataNode 故障）</li><li>读取故障：如果最近的 DataNode 挂掉，client 就会从次近的节点上读取数据</li><li>DataNode 故障<ul><li>NameNode 维护了两张表，一个是数据块列表（记录每个数据块存储在哪些 DataNode 上），一个是 DataNode 列表（记录每个 DataNode 存储了哪些数据块）。如果 NameNode 发现一个 DataNode 上的数据块已经损坏，则会更新数据块表（将此 DN 移除出该表）；如果发现是某个 DataNode 挂掉，则会同时更新两张表。</li><li>未充分备份的数据块处理：NameNode 通过定时扫描数据块列表就可以得知未充分备份的数据块，其可以要求未有备份的新 DataNode 去已有备份的 DataNode 拷贝数据块，使数据块充分备份。不过 HDFS 不保证至少存活一份数据，只负责尽可能地选择合理的备份位置。</li></ul></li></ul><h2 id="YARN——集群资源管理器"><a href="#YARN——集群资源管理器" class="headerlink" title="YARN——集群资源管理器"></a>YARN——集群资源管理器</h2><p>Apache YARN（Yet Another Resource Negotiator）是 hadoop 2.0 引入的集群资源管理系统。用户可以将各种服务框架部署在 YARN 上，由 YARN 进行统一地管理和资源分配。</p><h3 id="YARN-架构"><a href="#YARN-架构" class="headerlink" title="YARN 架构"></a>YARN 架构</h3><p><img src="http://qnya.pomo16.club/311.png" style="zoom:70%;"></p><ul><li><strong>ResourceManager</strong>：<code>ResourceManager</code> 通常在独立的机器上以后台进程的形式运行，它是整个集群资源的主要协调者和管理者。<code>ResourceManager</code> 负责给用户提交的所有应用程序分配资源，它根据应用程序优先级、队列容量、ACLs、数据位置等信息，做出决策，然后以共享的、安全的、多租户的方式制定分配策略，调度集群资源。</li><li><strong>NodeManager</strong>：<code>NodeManager</code> 是 YARN 集群中的每个具体节点的管理者。主要负责该节点内所有容器的生命周期的管理，监视资源和跟踪节点健康。具体如下：<ul><li>启动时向 <code>ResourceManager</code> 注册并定时发送心跳消息，等待 <code>ResourceManager</code> 的指令</li><li>维护 <code>Container</code> 的生命周期，监控 <code>Container</code> 的资源使用情况</li><li>管理任务运行时的相关依赖，根据 <code>ApplicationMaster</code> 的需要，在启动 <code>Container</code> 之前将需要的程序及其依赖拷贝到本地</li></ul></li></ul><ul><li><strong>ApplicationMaster</strong>：在用户提交一个应用程序时，YARN 会启动一个轻量级的进程 <code>ApplicationMaster</code>。<code>ApplicationMaster</code> 负责协调来自 <code>ResourceManager</code> 的资源，并通过 <code>NodeManager</code> 监视容器内资源的使用情况，同时还负责任务的监控与容错。具体如下：<ul><li>根据应用的运行状态来决定动态计算资源需求</li><li>向 <code>ResourceManager</code> 申请资源，监控申请的资源的使用情况</li><li>跟踪任务状态和进度，报告资源的使用情况和应用的进度信息</li><li>负责任务的容错</li></ul></li><li><strong>Container</strong>：<code>Container</code> 是 YARN 中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。当 AM 向 RM 申请资源时，RM 为 AM 返回的资源是用 <code>Container</code> 表示的。YARN 会为每个任务分配一个 <code>Container</code>，该任务只能使用该 <code>Container</code> 中描述的资源。<code>ApplicationMaster</code> 可在 <code>Container</code> 内运行任何类型的任务。例如，<code>MapReduce ApplicationMaster</code> 请求一个容器来启动 map 或 reduce 任务，而 <code>Giraph ApplicationMaster</code> 请求一个容器来运行 Giraph 任务。</li></ul><h3 id="YARN-工作原理简述"><a href="#YARN-工作原理简述" class="headerlink" title="YARN 工作原理简述"></a>YARN 工作原理简述</h3><p><img src="http://qnya.pomo16.club/312.png" alt></p><ol><li><code>Client</code> 提交作业到 YARN 上</li><li><code>Resource Manager</code> 选择一个 <code>Node Manager</code>，启动一个 <code>Container</code> 并运行 <code>Application Master</code> 实例</li><li><code>Application Master</code> 根据实际需要向 <code>Resource Manager</code> 请求更多的 <code>Container</code> 资源（如果作业很小, 应用管理器会选择在其自己的 JVM 中运行任务）</li><li><code>Application Master</code> 通过获取到的 <code>Container</code> 资源执行分布式计算</li></ol><h2 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h2><p>Hadoop MapReduce 是一个并行分布式计算框架，用于编写批处理应用程序。编写好的程序可以提交到 Hadoop 集群上用于并行处理大规模的数据集。</p><p>MapReduce 主要有三个阶段：</p><ul><li>Map 阶段：map 或者 mapper 将输入的数据集拆分成独立块。通常这些输入数据会存放在 HDFS，输入文件会被逐行输入到 mapper 函数中，mapper 函数会并行处理并创建一些数据块。</li><li>Shuffle 阶段：Map 转换到 Reduce 的中间过程，一般有 partitions、sort、combine 等操作</li><li>Reduce 阶段：对各个数据块上的数据并行运算，输出最终结果</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(input) &lt;k1, v1&gt; -&gt; map -&gt; &lt;k2, v2&gt; -&gt; shuffle -&gt; &lt;k2, v2&gt; -&gt; reduce -&gt; &lt;k3, v3&gt; (output)</span><br></pre></td></tr></table></figure><h3 id="MapReduce-具体流程"><a href="#MapReduce-具体流程" class="headerlink" title="MapReduce 具体流程"></a>MapReduce 具体流程</h3><p>以基本的词频统计为例：</p><p><img src="http://qnya.pomo16.club/313.png" alt style="zoom:50%;"></p><ul><li>input：读取文件</li><li>splitting：文件按行拆分，K1 为行数，V1 为对应行的文本内容</li><li>mapping：每行按空格拆分，拆分得到 List(K2, V2)，K2 代表每个单词，V2 代表出现次数</li><li>shuffling：由于 Mapping 操作可能分发到不同的节点上并行运算，因此 shuffling 需要把相同 key 的数据转发到相同节点上合并。K2 为每个单词，List(V2) 为可迭代集合，V2 为 Mapping 中的 V2</li><li>reducing：对 List(V2) 进行规约求和，最终输出词频统计结果</li></ul><p>MapReduce 编程模型中 <code>splitting</code> 和 <code>shuffing</code> 操作都是由框架实现的，需要我们自己编程实现的只有 <code>mapping</code> 和 <code>reducing</code>，这也就是 MapReduce 这个称呼的来源。</p><h3 id="Combiner-Partitioner-and-Sort"><a href="#Combiner-Partitioner-and-Sort" class="headerlink" title="Combiner, Partitioner and Sort"></a>Combiner, Partitioner and Sort</h3><p>Combiner、 Partioner 和 Sort 是 map 运算之后的可选操作，他们属于 shuffle 阶段的实现方式。</p><ul><li><p>Combiner：执行本地化的 reduce 操作，在 map 计算之后先简单地在每个节点本地进行重复 key 的合并</p></li><li><p>Partitioner：分类器，将每个 map 的输出结果分发到新的节点上，具有相同 key 值的数据会分发到同一节点</p></li><li><p>Sort：key 有序排列，一般结合了 shuffle 操作</p><p><img src="http://qnya.pomo16.club/314.png" style="zoom:70%;"></p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;目前的大数据生态基本都依赖于 Hadoop 生态，其可靠、高效、可伸缩，可以处理 PB 级别的数据。Hadoop 核心组件包括 HDFS、YARN 和 MapReduce。&lt;/p&gt;
    
    </summary>
    
      <category term="data" scheme="http://yoursite.com/categories/data/"/>
    
    
      <category term="Hadoop" scheme="http://yoursite.com/tags/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Docker安装ES相关</title>
    <link href="http://yoursite.com/2020/06/05/Docker%E5%AE%89%E8%A3%85ES%E5%8F%8AIK%E5%88%86%E8%AF%8D%E5%99%A8/"/>
    <id>http://yoursite.com/2020/06/05/Docker安装ES及IK分词器/</id>
    <published>2020-06-05T12:38:04.000Z</published>
    <updated>2020-06-05T16:33:17.439Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装ElasticSearch"><a href="#安装ElasticSearch" class="headerlink" title="安装ElasticSearch"></a>安装ElasticSearch</h2><h4 id="镜像拉取"><a href="#镜像拉取" class="headerlink" title="镜像拉取"></a>镜像拉取</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull docker.elastic.co/elasticsearch/elasticsearch:7.1.1</span><br></pre></td></tr></table></figure><h4 id="启动容器"><a href="#启动容器" class="headerlink" title="启动容器"></a>启动容器</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name es -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" -e ES_JAVA_OPTS="-Xms256m -Xmx256m" docker.elastic.co/elasticsearch/elasticsearch:7.1.1</span><br></pre></td></tr></table></figure><h4 id="相关配置"><a href="#相关配置" class="headerlink" title="相关配置"></a>相关配置</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it es /bin/bash</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 显示文件</span><br><span class="line">ls</span><br><span class="line">结果如下：</span><br><span class="line">LICENSE.txt  README.textile  config  lib   modules</span><br><span class="line">NOTICE.txt   bin             data    logs  plugins</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 进入配置文件夹</span><br><span class="line">cd config</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 显示文件</span><br><span class="line">ls</span><br><span class="line">结果如下：</span><br><span class="line">elasticsearch.keystore  ingest-geoip  log4j2.properties  roles.yml  users_roles</span><br><span class="line">elasticsearch.yml       jvm.options   role_mapping.yml   users</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 修改配置文件</span><br><span class="line">vi elasticsearch.yml</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 加入跨域配置</span><br><span class="line">http.cors.enabled: true</span><br><span class="line">http.cors.allow-origin: "*"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 退出容器</span><br><span class="line">exit</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart es</span><br></pre></td></tr></table></figure><h4 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl localhost:9200</span><br></pre></td></tr></table></figure><h2 id="安装ik分词器"><a href="#安装ik分词器" class="headerlink" title="安装ik分词器"></a>安装ik分词器</h2><h4 id="准备分词器压缩包"><a href="#准备分词器压缩包" class="headerlink" title="准备分词器压缩包"></a>准备分词器压缩包</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it es /bin/bash</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir /usr/share/elasticsearch/plugins/ik</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exit</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker cp elasticsearch-analysis-ik-7.1.1.zip es:/usr/share/elasticsearch/plugins/ik/</span><br></pre></td></tr></table></figure><p>附：<a href="https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.1.1/elasticsearch-analysis-ik-7.1.1.zip" target="_blank" rel="noopener">https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.1.1/elasticsearch-analysis-ik-7.1.1.zip</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -i ~/.ssh/xxx.pem -C elasticsearch-analysis-ik-7.1.1.zip &#123;user&#125;@&#123;ip&#125;:/root</span><br></pre></td></tr></table></figure><h4 id="解压安装"><a href="#解压安装" class="headerlink" title="解压安装"></a>解压安装</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it es /bin/bash</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/share/elasticsearch/plugins/ik</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unzip elasticsearch-analysis-ik-7.1.1.zip</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf elasticsearch-analysis-ik-7.1.0.zip</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exit</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart es</span><br></pre></td></tr></table></figure><h2 id="基于Docker使用elasticsearch-dump"><a href="#基于Docker使用elasticsearch-dump" class="headerlink" title="基于Docker使用elasticsearch-dump"></a>基于Docker使用elasticsearch-dump</h2><h4 id="镜像拉取-1"><a href="#镜像拉取-1" class="headerlink" title="镜像拉取"></a>镜像拉取</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull taskrabbit/elasticsearch-dump</span><br></pre></td></tr></table></figure><h4 id="创建文件存放路径"><a href="#创建文件存放路径" class="headerlink" title="创建文件存放路径"></a>创建文件存放路径</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /data/</span><br></pre></td></tr></table></figure><h4 id="用例"><a href="#用例" class="headerlink" title="用例"></a>用例</h4><ul><li>运用 <code>docker run --rm -ti taskrabbit/elasticsearch-dump</code> 调用能力</li><li><code>-v &lt;your dumps dir&gt;:&lt;your mount point&gt;</code> 指定外部挂载到 docker 中的目录</li><li>三种导出方式：（实际使用方式三选一，三个文件都要导出）</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 将analyzer分词从es复制到另一个es</span><br><span class="line">docker run --rm -ti elasticdump/elasticsearch-dump --input=http://ip1:9200/index1 --output=http://ip2:9200/index2 --type=analyzer</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 将mapping从index复制到另一个index</span><br><span class="line">docker run --rm -ti elasticdump/elasticsearch-dump --input=http://ip1:9200/index1 --output=http://ip1:9200/my_index --type=mapping</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span> 将data复制到文件</span><br><span class="line">docker run --rm -ti -v /data:/tmp elasticdump/elasticsearch-dump --input=http://ip:9200/my_index --output=/tmp/my_index_data.json --type=data</span><br></pre></td></tr></table></figure><ul><li>从文件恢复数据到es：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 从文件中恢复data</span><br><span class="line">docker run --rm -ti -v /data:/tmp elasticdump/elasticsearch-dump --input=/tmp/my_index_data.json --output=http://ip:9200/my_index --type=data</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> mapping和analyzer略</span><br></pre></td></tr></table></figure><ul><li>常见错误</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error: connect ECONNREFUSED 127.0.0.1:9200</span><br></pre></td></tr></table></figure><p>访问 localhost 时 docker 要添加 <code>--net=host</code>，表示宿主和容器同网络，如不添加访问的是容器内的网络。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --net=host --rm -ti -v /data:/tmp elasticdump/elasticsearch-dump --input=/tmp/my_index_data.json --output=http://localhost:9200/my_index --type=data</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      使用 Docker 搭建 ElasticSearch 及相关组件。
    
    </summary>
    
      <category term="web" scheme="http://yoursite.com/categories/web/"/>
    
      <category term="docker" scheme="http://yoursite.com/categories/web/docker/"/>
    
    
      <category term="ElasticSearch" scheme="http://yoursite.com/tags/ElasticSearch/"/>
    
  </entry>
  
  <entry>
    <title>Go 数组、字符串和切片</title>
    <link href="http://yoursite.com/2020/06/03/Go-%E6%95%B0%E7%BB%84%E5%92%8C%E5%88%87%E7%89%87/"/>
    <id>http://yoursite.com/2020/06/03/Go-数组和切片/</id>
    <published>2020-06-03T08:39:16.000Z</published>
    <updated>2020-06-30T07:40:57.333Z</updated>
    
    <content type="html"><![CDATA[<h2 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h2><h4 id="定义方式"><a href="#定义方式" class="headerlink" title="定义方式"></a>定义方式</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a [<span class="number">3</span>]<span class="keyword">int</span>                    <span class="comment">// 定义长度为3的int型数组, 元素全部为0</span></span><br><span class="line"><span class="keyword">var</span> b = [...]<span class="keyword">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;       <span class="comment">// 定义长度为3的int型数组, 元素为 1, 2, 3</span></span><br><span class="line"><span class="keyword">var</span> c = [...]<span class="keyword">int</span>&#123;<span class="number">2</span>: <span class="number">3</span>, <span class="number">1</span>: <span class="number">2</span>&#125;    <span class="comment">// 定义长度为3的int型数组, 元素为 0, 2, 3</span></span><br><span class="line"><span class="keyword">var</span> d = [...]<span class="keyword">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>: <span class="number">5</span>, <span class="number">6</span>&#125; <span class="comment">// 定义长度为6的int型数组, 元素为 1, 2, 0, 0, 5, 6</span></span><br></pre></td></tr></table></figure><ul><li>方式a：长度确定，数组中每个元素都以零值初始化</li><li>方式b：顺序指定全部元素的初始化值，数组的长度根据元素个数自动计算</li><li>方式c：以索引的方式来指定数组初始化元素，数组长度为最大指定索引，没有明确值的元素用零值初始化</li><li>方式d：混合了方式b和方式c</li></ul><h4 id="访问数组"><a href="#访问数组" class="headerlink" title="访问数组"></a>访问数组</h4><p>Go 中数组是值语义，一个数组变量就是整个数组，并不是隐式的指向第一个元素的指针（C语言）。所以当数组变量被赋值或者被传递的时候，实际上会复制整个数组。大数组会造成大的开销，为了避免复制数组带来的开销，可以传递一个指向数组的指针，但是数组指针并不是数组。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a = [...]<span class="keyword">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125; <span class="comment">// a 是一个数组</span></span><br><span class="line"><span class="keyword">var</span> b = &amp;a                <span class="comment">// b 是指向数组的指针</span></span><br><span class="line"></span><br><span class="line">fmt.Println(a[<span class="number">0</span>], a[<span class="number">1</span>])   <span class="comment">// 打印数组的前2个元素</span></span><br><span class="line">fmt.Println(b[<span class="number">0</span>], b[<span class="number">1</span>])   <span class="comment">// 通过数组指针访问数组元素的方式和数组类似</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, v := <span class="keyword">range</span> b &#123;     <span class="comment">// 通过数组指针迭代数组的元素</span></span><br><span class="line">    fmt.Println(i, v)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是数组指针类型依然不够灵活，因为数组的长度是数组类型的组成部分，指向不同长度数组的数组指针类型也是完全不同的。<strong>可以将数组看作一个特殊的结构体，结构的字段名对应数组的索引，同时结构体成员的数目是固定的。</strong>内置函数 <code>len</code> 返回数组长度，<code>cap</code> 返回数组容量。不过对于数组来说，这两个的返回结果是一样的。</p><p>我们还可以用 for 循环来遍历数组：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i := <span class="keyword">range</span> a &#123;</span><br><span class="line">    fmt.Printf(<span class="string">"a[%d]: %d\n"</span>, i, a[i])</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> i, v := <span class="keyword">range</span> b &#123;</span><br><span class="line">    fmt.Printf(<span class="string">"b[%d]: %d\n"</span>, i, v)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="built_in">len</span>(c); i++ &#123;</span><br><span class="line">    fmt.Printf(<span class="string">"c[%d]: %d\n"</span>, i, c[i])</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>for range</code> 的性能会好一些，因为这种迭代保证不会出现数组越界的情况，每轮迭代对数组元素的访问可以省去对下标越界的判断。另外 <code>for range</code> 可以忽略迭代时的下标：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> times [<span class="number">5</span>][<span class="number">0</span>]<span class="keyword">int</span></span><br><span class="line"><span class="keyword">for</span> <span class="keyword">range</span> times &#123;</span><br><span class="line">    fmt.Println(<span class="string">"hello"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上述使用中，尽管数组第一维有长度，但是 <code>[0]int</code> 大小是0，因此整个数组占用内存大小依然是0。没有额外的内存代价，我们就通过 <code>for range</code> 实现了 <code>times</code> 次快速迭代。</p><h4 id="数组类型"><a href="#数组类型" class="headerlink" title="数组类型"></a>数组类型</h4><p>除了数值型数组，还可以定义字符串数组、结构体数组、函数数组、接口数组、管道数组等等。另外还有不常用的空数组，因为一般我们更倾向于去使用空结构体来用于管道同步。</p><h2 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h2><p>字符串是一个<strong>不可改变</strong>的字节序列，和数组不同，字符串的元素不可修改，是一个只读的字节数组，且长度固定。由于 Go 的源代码要求 UTF8 编码，导致 Go 源代码中出现的字符串字面量常量一般也是 UTF8 编码（对于转义字符，则没有这个限制）。源代码中的文本字符串通常被解释为采用 UTF8 编码的 Unicode 码点（rune）序列。字符串是只读的字节序列，可以包含包括byte值0的任意数据。我们也可以用字符串表示 GBK 等非 UTF8 编码的数据，但此时字符串可以看做是一个只读的二进制数组，因为 <code>for range</code> 等语法并不能支持非 UTF8 编码的字符串的遍历。</p><p>Go 语言字符串的底层结构在 <code>reflect.StringHeader</code> 中定义：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> StringHeader <span class="keyword">struct</span> &#123;</span><br><span class="line">    Data <span class="keyword">uintptr</span></span><br><span class="line">    Len  <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>字符串结构包括了字符串指向的底层数组和字符串的字节长度。字符串其实就是一个结构体，因此字符串的赋值操作也就是 <code>reflect.StringHeader</code> 结构体的复制过程，并不会涉及底层字节数组的复制。<code>[2]string</code> 字符串数组对应的底层结构和 <code>[2]reflect.StringHeader</code> 对应的底层结构是一样的，可以将字符串数组看作一个结构体数组。举例来说 “Hello, world” 字符串底层数据和以下数组是完全一致的：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> data = [...]<span class="keyword">byte</span>&#123;</span><br><span class="line">    <span class="string">'h'</span>, <span class="string">'e'</span>, <span class="string">'l'</span>, <span class="string">'l'</span>, <span class="string">'o'</span>, <span class="string">','</span>, <span class="string">' '</span>, <span class="string">'w'</span>, <span class="string">'o'</span>, <span class="string">'r'</span>, <span class="string">'l'</span>, <span class="string">'d'</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>字符串虽然不是切片，但是支持切片操作，不同位置的切片底层也访问的同一块内存数据（因为字符串是只读的，相同的字符串面值常量通常是对应同一个字符串常量）:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">s := <span class="string">"hello, world"</span></span><br><span class="line">hello := s[:<span class="number">5</span>]</span><br><span class="line">world := s[<span class="number">7</span>:]</span><br><span class="line"></span><br><span class="line">s1 := <span class="string">"hello, world"</span>[:<span class="number">5</span>]</span><br><span class="line">s2 := <span class="string">"hello, world"</span>[<span class="number">7</span>:]</span><br></pre></td></tr></table></figure><p>字符串和数组类似，内置的<code>len</code>函数返回字符串的长度。或通过 <code>reflect.StringHeader</code> 结构访问字符串的长度（不推荐）。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">len</span>(s)</span><br><span class="line">fmt.Println(<span class="string">"len(s):"</span>, (*reflect.StringHeader)(unsafe.Pointer(&amp;s)).Len)</span><br></pre></td></tr></table></figure><p>提到 Go 字符串时，我们一般都会假设字符串对应的是一个合法的 UTF8 编码的字符序列。可以用内置的 <code>print</code> 调试函数或 <code>fmt.Print</code> 函数直接打印，也可以用 <code>for range</code> 循环直接遍历 UTF8 解码后的 Unicode 码点值。我们也可以在字符串面值中直指定UTF8编码后的值（源文件中全部是ASCII码，可以避免出现多字节的字符）：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fmt.Println(<span class="string">"\xe4\xb8\x96"</span>) <span class="comment">// 打印: 世</span></span><br><span class="line">fmt.Println(<span class="string">"\xe7\x95\x8c"</span>) <span class="comment">// 打印: 界</span></span><br></pre></td></tr></table></figure><p>Go 语言的字符串中可以存放任意的二进制字节序列，而且即使是 UTF8 字符序列也可能会遇到坏的编码。如果遇到一个错误的 UTF8 编码输入，将生成一个特别的 Unicode 字符 ‘\uFFFD’，通常显示为 ‘�’ 。错误编码不会向后扩散是 UTF8 编码的优秀特性之一：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fmt.Println(<span class="string">"\xe4\x00\x00\xe7\x95\x8cabc"</span>) <span class="comment">// �界abc</span></span><br></pre></td></tr></table></figure><p>不过在 <code>for range</code> 迭代这个含有损坏的UTF8字符串时，第一字符的第二和第三字节依然会被单独迭代到，此时迭代的值是损坏后的0：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, c := <span class="keyword">range</span> <span class="string">"\xe4\x00\x00\xe7\x95\x8cabc"</span> &#123;</span><br><span class="line">    fmt.Println(i, c)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 0 65533  // \uFFFD, 对应 �</span></span><br><span class="line"><span class="comment">// 1 0      // 空字符</span></span><br><span class="line"><span class="comment">// 2 0      // 空字符</span></span><br><span class="line"><span class="comment">// 3 30028  // 界</span></span><br><span class="line"><span class="comment">// 6 97     // a</span></span><br><span class="line"><span class="comment">// 7 98     // b</span></span><br><span class="line"><span class="comment">// 8 99     // c</span></span><br></pre></td></tr></table></figure><p>Go 语言除了 <code>for range</code> 语法对 UTF8 字符串提供了特殊支持外，还对字符串和 <code>[]rune</code> 类型的相互转换提供了特殊的支持。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fmt.Printf(<span class="string">"%#v\n"</span>, []<span class="keyword">rune</span>(<span class="string">"世界"</span>))              <span class="comment">// []int32&#123;19990, 30028&#125;</span></span><br><span class="line">fmt.Printf(<span class="string">"%#v\n"</span>, <span class="keyword">string</span>([]<span class="keyword">rune</span>&#123;<span class="string">'世'</span>, <span class="string">'界'</span>&#125;))  <span class="comment">// 世界</span></span><br></pre></td></tr></table></figure><p>上面可以看出 <code>rune</code> 只是 <code>int32</code> 的别名，用于表示每个 Unicode 码点，目前只使用了21个 bit 位。</p><p>字符串的强制类型转换涉及 <code>[]byte</code> 和 <code>[]rune</code> 两种类型。在将字符串转为 <code>[]byte</code> 时，如果转换后的变量并没有被修改的情形，编译器可能会直接返回原始的字符串对应的底层数据。而在将字符串转为 <code>[]rune</code> 时，由于字符串底层的 <code>[]byte</code> 和 <code>[]int32</code> 类型的内部布局完全不同，所以这种转换可能隐含重新分配内存的操作（重构字符串），最差的情况是时间复杂度达到 O(n)。</p><h2 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h2><p>切片简单来说就是一种简化版的动态数组，实际使用中，切片比数组的使用范围广泛很多。下面是切片的结构定义，<code>reflect.SliceHeader</code>：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> SliceHeader <span class="keyword">struct</span> &#123;</span><br><span class="line">    Data <span class="keyword">uintptr</span></span><br><span class="line">    Len  <span class="keyword">int</span></span><br><span class="line">    Cap  <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>切片的开头部分和 Go 字符串是一样的，但是切片多了一个 <code>Cap</code> 成员表示切片指向的内存空间的最大容量（对应元素的个数，而不是字节数）。和数组一样，内置的 <code>len</code> 函数返回切片中有效元素的长度，内置的 <code>cap</code> 函数返回切片容量大小，<strong>容量必须大于或等于切片的长度</strong>。切片可以和 <code>nil</code> 进行比较，<strong>只有当切片底层数据指针为空时切片本身为 <code>nil</code></strong>，这时候切片的长度和容量信息将是无效的。如果有切片的底层数据指针为空，但是长度和容量不为0的情况，那么说明切片本身已经被损坏了（比如直接通过 <code>reflect.SliceHeader</code> 或 <code>unsafe</code> 包对切片作了不正确的修改）。</p><p>切片的定义方式如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> (</span><br><span class="line">    a []<span class="keyword">int</span>               <span class="comment">// nil切片, 和 nil 相等, 一般用来表示一个不存在的切片</span></span><br><span class="line">    b = []<span class="keyword">int</span>&#123;&#125;           <span class="comment">// 空切片, 和 nil 不相等, 一般用来表示一个空的集合</span></span><br><span class="line">    c = []<span class="keyword">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;    <span class="comment">// 有3个元素的切片, len和cap都为3</span></span><br><span class="line">    d = c[:<span class="number">2</span>]             <span class="comment">// 有2个元素的切片, len为2, cap为3</span></span><br><span class="line">    e = c[<span class="number">0</span>:<span class="number">2</span>:<span class="built_in">cap</span>(c)]     <span class="comment">// 有2个元素的切片, len为2, cap为3</span></span><br><span class="line">    f = c[:<span class="number">0</span>]             <span class="comment">// 有0个元素的切片, len为0, cap为3</span></span><br><span class="line">    g = <span class="built_in">make</span>([]<span class="keyword">int</span>, <span class="number">3</span>)    <span class="comment">// 有3个元素的切片, len和cap都为3</span></span><br><span class="line">    h = <span class="built_in">make</span>([]<span class="keyword">int</span>, <span class="number">2</span>, <span class="number">3</span>) <span class="comment">// 有2个元素的切片, len为2, cap为3</span></span><br><span class="line">    i = <span class="built_in">make</span>([]<span class="keyword">int</span>, <span class="number">0</span>, <span class="number">3</span>) <span class="comment">// 有0个元素的切片, len为0, cap为3</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>切片的遍历、读取和修改都和数组一致。在对切片本身赋值或参数传递时，和数组指针的操作方式类似，只是复制切片头信息（<code>reflect.SliceHeader</code>），并不会复制底层的数据。<strong>对于类型，和数组的最大不同是，切片的类型和长度信息无关，只要是相同类型元素构成的切片均对应相同的切片类型。</strong></p><p>如前所说，切片是一种简化版的动态数组，这是切片类型的灵魂。除了构造切片和遍历切片之外，添加切片元素、删除切片元素都是切片处理中经常遇到的问题。</p><h4 id="添加切片元素"><a href="#添加切片元素" class="headerlink" title="添加切片元素"></a>添加切片元素</h4><p>内置的泛型函数 <code>append</code> 可以在切片的尾部追加 <code>N</code> 个元素：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a []<span class="keyword">int</span></span><br><span class="line">a = <span class="built_in">append</span>(a, <span class="number">1</span>)               <span class="comment">// 追加1个元素</span></span><br><span class="line">a = <span class="built_in">append</span>(a, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)         <span class="comment">// 追加多个元素, 手写解包方式</span></span><br><span class="line">a = <span class="built_in">append</span>(a, []<span class="keyword">int</span>&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;...) <span class="comment">// 追加一个切片, 切片需要解包</span></span><br></pre></td></tr></table></figure><p>不过要注意的是，在容量不足的情况下，<code>append</code> 的操作会导致重新分配内存，可能导致巨大的内存分配和复制数据代价。即使容量足够，依然需要用 <code>append</code> 函数的返回值来更新切片本身，因为新切片的长度已经发生了变化。</p><p>除了在切片的尾部追加，我们还可以在切片的开头添加元素：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a = []<span class="keyword">int</span>&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;</span><br><span class="line">a = <span class="built_in">append</span>([]<span class="keyword">int</span>&#123;<span class="number">0</span>&#125;, a...)        <span class="comment">// 在开头添加1个元素</span></span><br><span class="line">a = <span class="built_in">append</span>([]<span class="keyword">int</span>&#123;<span class="number">-3</span>,<span class="number">-2</span>,<span class="number">-1</span>&#125;, a...) <span class="comment">// 在开头添加1个切片</span></span><br></pre></td></tr></table></figure><p>在开头一般都会导致内存的重新分配，而且会导致已有的元素全部复制1次。因此，从切片的开头添加元素的性能一般要比从尾部追加元素的性能差很多。</p><p>由于 <code>append</code> 函数返回新的切片，也就是它支持链式操作：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a []<span class="keyword">int</span></span><br><span class="line">a = <span class="built_in">append</span>(a[:i], <span class="built_in">append</span>([]<span class="keyword">int</span>&#123;x&#125;, a[i:]...)...)     <span class="comment">// 在第i个位置插入x</span></span><br><span class="line">a = <span class="built_in">append</span>(a[:i], <span class="built_in">append</span>([]<span class="keyword">int</span>&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;, a[i:]...)...) <span class="comment">// 在第i个位置插入切片</span></span><br></pre></td></tr></table></figure><p>或者用 <code>copy</code> 和 <code>append</code> 组合可以避免创建中间的临时切片：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//在第i个位置添加一个元素</span></span><br><span class="line">a = <span class="built_in">append</span>(a, <span class="number">0</span>)     <span class="comment">// 切片扩展1个空间</span></span><br><span class="line"><span class="built_in">copy</span>(a[i+<span class="number">1</span>:], a[i:]) <span class="comment">// a[i:]向后移动1个位置</span></span><br><span class="line">a[i] = x             <span class="comment">// 设置新添加的元素</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//在第i个位置添加多个元素(切片)</span></span><br><span class="line">a = <span class="built_in">append</span>(a, x...)       <span class="comment">// 为x切片扩展足够的空间</span></span><br><span class="line"><span class="built_in">copy</span>(a[i+<span class="built_in">len</span>(x):], a[i:]) <span class="comment">// a[i:]向后移动len(x)个位置</span></span><br><span class="line"><span class="built_in">copy</span>(a[i:], x)            <span class="comment">// 复制新添加的切片</span></span><br></pre></td></tr></table></figure><p>人为扩容属于副作用，有违切片本身的设计思想。</p><h4 id="删除切片元素"><a href="#删除切片元素" class="headerlink" title="删除切片元素"></a>删除切片元素</h4><p>删除尾部元素：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = []<span class="keyword">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br><span class="line">a = a[:<span class="built_in">len</span>(a)<span class="number">-1</span>]   <span class="comment">// 删除尾部1个元素</span></span><br><span class="line">a = a[:<span class="built_in">len</span>(a)-N]   <span class="comment">// 删除尾部N个元素</span></span><br></pre></td></tr></table></figure><p>删除头部元素：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//移动指针</span></span><br><span class="line">a = []<span class="keyword">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br><span class="line">a = a[<span class="number">1</span>:] <span class="comment">// 删除开头1个元素</span></span><br><span class="line">a = a[N:] <span class="comment">// 删除开头N个元素</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//不移动指针原地完成</span></span><br><span class="line">a = []<span class="keyword">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br><span class="line">a = <span class="built_in">append</span>(a[:<span class="number">0</span>], a[<span class="number">1</span>:]...) <span class="comment">// 删除开头1个元素</span></span><br><span class="line">a = <span class="built_in">append</span>(a[:<span class="number">0</span>], a[N:]...) <span class="comment">// 删除开头N个元素</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//使用copy删除开头</span></span><br><span class="line">a = []<span class="keyword">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br><span class="line">a = a[:<span class="built_in">copy</span>(a, a[<span class="number">1</span>:])] <span class="comment">// 删除开头1个元素</span></span><br><span class="line">a = a[:<span class="built_in">copy</span>(a, a[N:])] <span class="comment">// 删除开头N个元素</span></span><br></pre></td></tr></table></figure><p>删除中间元素：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//使用copy和append组合原地完成</span></span><br><span class="line">a = []<span class="keyword">int</span>&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, ...&#125;</span><br><span class="line">a = <span class="built_in">append</span>(a[:i], a[i+<span class="number">1</span>:]...) <span class="comment">// 删除中间1个元素</span></span><br><span class="line">a = <span class="built_in">append</span>(a[:i], a[i+N:]...) <span class="comment">// 删除中间N个元素</span></span><br><span class="line">a = a[:i+<span class="built_in">copy</span>(a[i:], a[i+<span class="number">1</span>:])]  <span class="comment">// 删除中间1个元素</span></span><br><span class="line">a = a[:i+<span class="built_in">copy</span>(a[i:], a[i+N:])]  <span class="comment">// 删除中间N个元素</span></span><br></pre></td></tr></table></figure><p>删除开头的元素和删除尾部的元素都可以认为是删除中间元素操作的特殊情况。</p><h4 id="切片内存技巧"><a href="#切片内存技巧" class="headerlink" title="切片内存技巧"></a>切片内存技巧</h4><p>对于切片来说， <code>len</code> 为0但是 <code>cap</code> 容量不为<code>0</code>的切片则是非常有用的特性。当然，如果 <code>len</code> 和 <code>cap</code> 都为 0 的话，则变成一个真正的空切片，虽然它并不是一个 <code>nil</code> 值的切片。<strong>在判断一个切片是否为空时，一般通过 <code>len</code> 获取切片的长度来判断，一般很少将切片和 <code>nil</code> 值做直接的比较。</strong></p><p>0长切片特性使用案例：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//删除[]byte中的空格</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TrimSpace</span><span class="params">(s []<span class="keyword">byte</span>)</span> []<span class="title">byte</span></span> &#123;</span><br><span class="line">    <span class="comment">//len为0但是cap为s的长度，删除操作中append肯定不会超出cap</span></span><br><span class="line">    b := s[:<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> _, x := <span class="keyword">range</span> s &#123;</span><br><span class="line">        <span class="keyword">if</span> x != <span class="string">' '</span> &#123;</span><br><span class="line">            b = <span class="built_in">append</span>(b, x)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> b</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//普适到所有过滤删除需求</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Filter</span><span class="params">(s []<span class="keyword">byte</span>, fn <span class="keyword">func</span>(x <span class="keyword">byte</span>)</span> <span class="title">bool</span>) []<span class="title">byte</span></span> &#123;</span><br><span class="line">    b := s[:<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">for</span> _, x := <span class="keyword">range</span> s &#123;</span><br><span class="line">        <span class="keyword">if</span> !fn(x) &#123;</span><br><span class="line">            b = <span class="built_in">append</span>(b, x)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> b</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>切片高效操作的要点是要降低内存分配的次数，尽量保证 <code>append</code> 操作不会超出 <code>cap</code> 的容量，降低触发内存分配的次数和每次分配内存大小。</p><h4 id="避免切片内存泄露"><a href="#避免切片内存泄露" class="headerlink" title="避免切片内存泄露"></a>避免切片内存泄露</h4><p>如前面所说，切片操作并不会复制底层的数据。底层的数组会被保存在内存中，直到它不再被引用。但是有时候可能会因为一个小的内存引用而导致底层整个数组处于被使用的状态，这会延迟自动内存回收器对底层数组的回收。</p><p>例如，<code>FindPhoneNumber</code> 函数加载整个文件到内存，然后搜索第一个出现的电话号码，最后结果以切片方式返回。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">FindPhoneNumber</span><span class="params">(filename <span class="keyword">string</span>)</span> []<span class="title">byte</span></span> &#123;</span><br><span class="line">    b, _ := ioutil.ReadFile(filename)</span><br><span class="line">    <span class="keyword">return</span> regexp.MustCompile(<span class="string">"[0-9]+"</span>).Find(b)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码返回的 <code>[]byte</code> 指向保存整个文件的数组。因为切片引用了整个原始数组，导致自动垃圾回收器不能及时释放底层数组的空间。一个小的需求可能导致需要长时间保存整个文件数据。这虽然这并不是传统意义上的内存泄漏，但是可能会拖慢系统的整体性能。</p><p>要修复这个问题，可以将感兴趣的数据复制到一个新的切片中（<strong>数据的传值是Go语言编程的一个哲学，虽然传值有一定的代价，但是换取的好处是切断了对原始数据的依赖</strong>）：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">FindPhoneNumber</span><span class="params">(filename <span class="keyword">string</span>)</span> []<span class="title">byte</span></span> &#123;</span><br><span class="line">    b, _ := ioutil.ReadFile(filename)</span><br><span class="line">    b = regexp.MustCompile(<span class="string">"[0-9]+"</span>).Find(b)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">append</span>([]<span class="keyword">byte</span>&#123;&#125;, b...)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>类似的问题，在删除切片元素时可能会遇到。假设切片里存放的是指针对象，那么下面删除末尾的元素后，被删除的元素依然被切片底层数组引用，从而导致不能及时被自动垃圾回收器回收（这要依赖回收器的实现方式）：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a []*<span class="keyword">int</span>&#123; ... &#125;</span><br><span class="line">a = a[:<span class="built_in">len</span>(a)<span class="number">-1</span>]    <span class="comment">// 被删除的最后一个元素依然被引用, 可能导致GC操作被阻碍</span></span><br></pre></td></tr></table></figure><p>保险的方式是先将需要自动内存回收的元素设置为 <code>nil</code>，保证自动回收器可以发现需要回收的对象，然后再进行切片的删除操作：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> a []*<span class="keyword">int</span>&#123; ... &#125;</span><br><span class="line">a[<span class="built_in">len</span>(a)<span class="number">-1</span>] = <span class="literal">nil</span> <span class="comment">// GC回收最后一个元素内存</span></span><br><span class="line">a = a[:<span class="built_in">len</span>(a)<span class="number">-1</span>]  <span class="comment">// 从切片删除最后一个元素</span></span><br></pre></td></tr></table></figure><p>当然，如果切片本身生命周期短的话完全不需要这样，等待整个切片被 GC 回收即可。</p><h4 id="切片强制类型转换"><a href="#切片强制类型转换" class="headerlink" title="切片强制类型转换"></a>切片强制类型转换</h4><p>为了安全，当两个切片类型 <code>[]T</code> 和 <code>[]Y</code> 的底层原始切片类型不同时，Go语言是无法直接转换类型的。但是有时候转换有简化编码或者提升性能的价值，比如在64位系统上，需要对一个 <code>[]float64</code> 切片进行高速排序，我们可以将它强制转为 <code>[]int</code> 整数切片，然后以整数的方式进行排序（因为 <code>float64</code> 遵循 IEEE754 浮点数标准特性，当浮点数有序时对应的整数也必然是有序的）。下面的代码通过两种方法将 <code>[]float64</code> 类型的切片转换为 <code>[]int</code> 类型的切片：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// +build amd64 arm64</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">"sort"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> a = []<span class="keyword">float64</span>&#123;<span class="number">4</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">88</span>, <span class="number">1</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">SortFloat64FastV1</span><span class="params">(a []<span class="keyword">float64</span>)</span></span> &#123;</span><br><span class="line">    <span class="comment">// 强制类型转换</span></span><br><span class="line">    <span class="keyword">var</span> b []<span class="keyword">int</span> = ((*[<span class="number">1</span> &lt;&lt; <span class="number">20</span>]<span class="keyword">int</span>)(unsafe.Pointer(&amp;a[<span class="number">0</span>])))[:<span class="built_in">len</span>(a):<span class="built_in">cap</span>(a)]</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 以int方式给float64排序</span></span><br><span class="line">    sort.Ints(b)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">SortFloat64FastV2</span><span class="params">(a []<span class="keyword">float64</span>)</span></span> &#123;</span><br><span class="line">    <span class="comment">// 通过 reflect.SliceHeader 更新切片头部信息实现转换</span></span><br><span class="line">    <span class="keyword">var</span> c []<span class="keyword">int</span></span><br><span class="line">    aHdr := (*reflect.SliceHeader)(unsafe.Pointer(&amp;a))</span><br><span class="line">    cHdr := (*reflect.SliceHeader)(unsafe.Pointer(&amp;c))</span><br><span class="line">    *cHdr = *aHdr</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 以int方式给float64排序</span></span><br><span class="line">    sort.Ints(c)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>第一种强制转换是先将切片数据的开始地址转换为一个较大的数组的指针，然后对数组指针对应的数组重新做切片操作。中间需要 <code>unsafe.Pointer</code> 来连接两个不同类型的指针传递。需要注意的是，Go 语言实现中非0大小数组的长度不得超过2GB，因此需要针对数组元素的类型大小计算数组的最大长度范围（<code>[]uint8</code> 最大2GB，<code>[]uint16</code> 最大1GB，以此类推，但是 <code>[]struct{}</code> 数组的长度可以超过2GB）。</p><p>第二种转换操作是分别取到两个不同类型的切片头信息指针，任何类型的切片头部信息底层都是对应 <code>reflect.SliceHeader</code> 结构，然后通过更新结构体方式来更新切片信息，从而实现 <code>a</code> 对应的 <code>[]float64</code> 切片到 <code>c</code> 对应的 <code>[]int</code> 类型切片的转换。</p><p>不过需要注意的是，这个方法可行的前提是要保证 <code>[]float64</code> 中没有 NaN 和 Inf 等非规范的浮点数（因为浮点数中 NaN 不可排序，正0和负0相等，但是整数中没有这类情形）。</p><h2 id="Other"><a href="#Other" class="headerlink" title="Other"></a>Other</h2><h4 id="数组和切片在传参上的差异"><a href="#数组和切片在传参上的差异" class="headerlink" title="数组和切片在传参上的差异"></a>数组和切片在传参上的差异</h4><p>直接看例子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">test</span><span class="params">()</span></span> &#123;</span><br><span class="line">arr := [...]<span class="keyword">int</span>&#123;<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>&#125;</span><br><span class="line">fmt.Printf(<span class="string">"%v\n"</span>, arr)</span><br><span class="line"></span><br><span class="line">slice := []<span class="keyword">int</span>&#123;<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;</span><br><span class="line">fmt.Printf(<span class="string">"%v\n"</span>, slice)</span><br><span class="line"></span><br><span class="line">changeArrayItem(arr)</span><br><span class="line">changeSliceItem(slice)</span><br><span class="line"></span><br><span class="line">fmt.Printf(<span class="string">"%v\n"</span>, arr)</span><br><span class="line">fmt.Printf(<span class="string">"%v\n"</span>, slice)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">changeArrayItem</span><span class="params">(base [3]<span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">base[<span class="number">0</span>] = <span class="number">10</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">changeSliceItem</span><span class="params">(base []<span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">base[<span class="number">0</span>] = <span class="number">10</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//output</span></span><br><span class="line">[<span class="number">0</span> <span class="number">1</span> <span class="number">2</span>]</span><br><span class="line">[<span class="number">3</span> <span class="number">4</span> <span class="number">5</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">1</span> <span class="number">2</span>]</span><br><span class="line">[<span class="number">10</span> <span class="number">4</span> <span class="number">5</span>]</span><br></pre></td></tr></table></figure><p>可以看出数组是值传递，切片是引用传递，而且数组形参在定义时必须准确定义长度。</p><p>切片在传参上还有一个坑，就是 <code>append</code> 操作造成的引用丢失：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">appendTest</span><span class="params">()</span></span> &#123;</span><br><span class="line">slice := []<span class="keyword">int</span>&#123;<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;</span><br><span class="line">fmt.Printf(<span class="string">"before: %v\n"</span>, slice)</span><br><span class="line"></span><br><span class="line">appendSliceItem(slice)</span><br><span class="line">fmt.Printf(<span class="string">"after: %v\n"</span>, slice)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">appendSliceItem</span><span class="params">(slice []<span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">slice = <span class="built_in">append</span>(slice, <span class="number">100</span>)</span><br><span class="line">fmt.Printf(<span class="string">"func: %v\n"</span>, slice)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//output</span></span><br><span class="line">before: [<span class="number">3</span> <span class="number">4</span> <span class="number">5</span>]</span><br><span class="line"><span class="function"><span class="keyword">func</span>: [3 4 5 100]</span></span><br><span class="line"><span class="function"><span class="title">after</span>: [3 4 5]</span></span><br></pre></td></tr></table></figure><p>由于 <code>append</code> 返回的是一个新的切片引用，因此在函数内的添加变更只体现在新切片引用上。除非函数返回新的切片引用，否则原上下文无法让旧引用重新赋值为新切片的引用。要解决这个问题除了直接用函数返回值更新外，还可以用引用的引用来解决：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">appendTest</span><span class="params">()</span></span> &#123;</span><br><span class="line">slice := []<span class="keyword">int</span>&#123;<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;</span><br><span class="line">fmt.Printf(<span class="string">"before: %v\n"</span>, slice)</span><br><span class="line"></span><br><span class="line">appendSliceItem(&amp;slice)</span><br><span class="line">fmt.Printf(<span class="string">"after: %v\n"</span>, slice)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">appendSliceItem</span><span class="params">(slice *[]<span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">*slice = <span class="built_in">append</span>(*slice, <span class="number">100</span>)</span><br><span class="line">fmt.Printf(<span class="string">"func: %v\n"</span>, *slice)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//output</span></span><br><span class="line">before: [<span class="number">3</span> <span class="number">4</span> <span class="number">5</span>]</span><br><span class="line"><span class="function"><span class="keyword">func</span>: [3 4 5 100]</span></span><br><span class="line"><span class="function"><span class="title">after</span>: [3 4 5 100]</span></span><br></pre></td></tr></table></figure><p>下面用一个递归例子在展示两种方式：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">recursiveTest</span><span class="params">()</span></span> &#123;</span><br><span class="line">arr1 := []<span class="keyword">int</span>&#123;&#125;</span><br><span class="line">insertTo10(&amp;arr1)</span><br><span class="line">fmt.Println(arr1)</span><br><span class="line"></span><br><span class="line">arr2 := []<span class="keyword">int</span>&#123;&#125;</span><br><span class="line">arr2 = insertTo10V2(arr2)</span><br><span class="line">fmt.Println(arr2)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">insertTo10</span><span class="params">(arr *[]<span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">length := <span class="built_in">len</span>(*arr)</span><br><span class="line"><span class="keyword">if</span> length == <span class="number">10</span> &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line">*arr = <span class="built_in">append</span>(*arr, length)</span><br><span class="line">insertTo10(arr)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">insertTo10V2</span><span class="params">(arr []<span class="keyword">int</span>)</span> []<span class="title">int</span></span> &#123;</span><br><span class="line">length := <span class="built_in">len</span>(arr)</span><br><span class="line"><span class="keyword">if</span> length == <span class="number">10</span> &#123;</span><br><span class="line"><span class="keyword">return</span> arr</span><br><span class="line">&#125;</span><br><span class="line">arr = <span class="built_in">append</span>(arr, length)</span><br><span class="line"><span class="keyword">return</span> insertTo10V2(arr)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//output</span></span><br><span class="line">[<span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span> <span class="number">9</span>]</span><br><span class="line">[<span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span> <span class="number">9</span>]</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      探究 Go 的数组、字符串和切片
    
    </summary>
    
      <category term="go" scheme="http://yoursite.com/categories/go/"/>
    
    
      <category term="go" scheme="http://yoursite.com/tags/go/"/>
    
  </entry>
  
  <entry>
    <title>Go struct{}类型Channel</title>
    <link href="http://yoursite.com/2020/06/02/Go-struct-%E7%B1%BB%E5%9E%8BChannel/"/>
    <id>http://yoursite.com/2020/06/02/Go-struct-类型Channel/</id>
    <published>2020-06-02T14:23:34.000Z</published>
    <updated>2020-06-02T16:09:38.143Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Go 中的 Channel 除了通信功能，往往还会扮演信号量或阻塞控制的角色。后者往往只需要 Channel 的语言特性，并不关注 Channel 传输的内容。在此背景下就有了 <code>struct{}</code> 类型 Channel 的使用场景，该类型 Channel 不占用任何内存。该 Channel 只可以写入 <code>struct{}{}</code> ，即空结构体。</p><h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><h4 id="1-等待任务结束"><a href="#1-等待任务结束" class="headerlink" title="1. 等待任务结束"></a>1. 等待任务结束</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">done := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;)</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; </span><br><span class="line">  doLongRunningThing()</span><br><span class="line">  <span class="built_in">close</span>(done)</span><br><span class="line">&#125;()</span><br><span class="line"><span class="comment">// do some other things</span></span><br><span class="line"><span class="comment">// wait for that long running thing to finish</span></span><br><span class="line">&lt;-done</span><br></pre></td></tr></table></figure><h4 id="2-多任务同时开始"><a href="#2-多任务同时开始" class="headerlink" title="2. 多任务同时开始"></a>2. 多任务同时开始</h4><p>实现类似并行而非并发的效果</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">start := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;)</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++ &#123;</span><br><span class="line">  <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">    &lt;-start <span class="comment">// wait for the start channel to be closed</span></span><br><span class="line">    doWork(i) <span class="comment">// do something</span></span><br><span class="line"> &#125;()</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// at this point, all goroutines are ready to go</span></span><br><span class="line"><span class="comment">// we just need to tell them to start by closing the start channel</span></span><br><span class="line"><span class="built_in">close</span>(start)</span><br></pre></td></tr></table></figure><h4 id="3-事件中断"><a href="#3-事件中断" class="headerlink" title="3. 事件中断"></a>3. 事件中断</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">  <span class="keyword">select</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> m := &lt;-email:</span><br><span class="line">    sendEmail(m)</span><br><span class="line">  <span class="keyword">case</span> &lt;-stop: <span class="comment">// triggered when the stop channel is closed</span></span><br><span class="line">    <span class="keyword">break</span>      <span class="comment">// (or return) exit</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      空类型Channel的妙用
    
    </summary>
    
      <category term="go" scheme="http://yoursite.com/categories/go/"/>
    
    
      <category term="go" scheme="http://yoursite.com/tags/go/"/>
    
  </entry>
  
  <entry>
    <title>Concurrency in Go</title>
    <link href="http://yoursite.com/2020/05/16/Concurrency-in-Go/"/>
    <id>http://yoursite.com/2020/05/16/Concurrency-in-Go/</id>
    <published>2020-05-16T08:35:30.000Z</published>
    <updated>2020-07-03T17:21:09.138Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Why-Use-Concurrency？"><a href="#1-Why-Use-Concurrency？" class="headerlink" title="1. Why Use Concurrency？"></a>1. Why Use Concurrency？</h2><h3 id="1-1-Parallel-Execution"><a href="#1-1-Parallel-Execution" class="headerlink" title="1.1 Parallel Execution"></a>1.1 Parallel Execution</h3><ul><li>Two programs execute in parallel if they <strong>execute at exactly the same time</strong></li><li>At time t, an instruction is being performed for both P1 and P2</li><li>Need replicated hardware</li><li>Why Use Parallel Execution？<ul><li>Tasks may complete more quickly</li><li>Some tasks must be performed sequentially</li><li>But some tasks are parallelizable and some are not</li></ul></li></ul><h3 id="1-2-Von-Neumann-Bottleneck"><a href="#1-2-Von-Neumann-Bottleneck" class="headerlink" title="1.2 Von Neumann Bottleneck"></a>1.2 Von Neumann Bottleneck</h3><h5 id="Speedup-without-Parallelism"><a href="#Speedup-without-Parallelism" class="headerlink" title="Speedup without Parallelism"></a>Speedup without Parallelism</h5><ul><li>Can we achieve speedup without Parallelism？</li><li>Design faster processors<ul><li>Get speedup without changing software</li></ul></li><li>Design processor with more memory<ul><li>Reduces the Von Neumann Bottleneck</li><li>Cache access time = 1 clock cycle</li><li>Main memory access time = ~100 clock cycles</li><li>Increasing on-chip cache improves performance</li></ul></li></ul><h5 id="Moore’s-Law"><a href="#Moore’s-Law" class="headerlink" title="Moore’s Law"></a>Moore’s Law</h5><ul><li>Predicted that transistor density would double every two years</li><li>Smaller transistors switch faster</li><li>Not a physical law, just an observation</li><li>Exponential increase in density would lead to exponential increase in speed</li></ul><h3 id="1-3-Power-wall"><a href="#1-3-Power-wall" class="headerlink" title="1.3 Power wall"></a>1.3 Power wall</h3><h5 id="Power-Temperature-Problem"><a href="#Power-Temperature-Problem" class="headerlink" title="Power/Temperature Problem"></a>Power/Temperature Problem</h5><ul><li>Transistors consume power when they switch</li><li>Increasing transistor density leads to increased power consumption<ul><li>Smaller transistors use less power, but density scaling is much faster</li></ul></li><li>High power leads to high temperature</li><li>Air cooling(fans) can only remove so much heat</li></ul><h5 id="Dynamic-Power"><a href="#Dynamic-Power" class="headerlink" title="Dynamic Power"></a>Dynamic Power</h5><ul><li>P = α * CFV<sup>2</sup></li><li>α is percent of time switching</li><li>C is capacitance(related to size)</li><li>F is the clock frequency</li><li>V is voltage swing（from low to high）<ul><li>Voltage is important</li><li>0 to 5V uses much more power than 0 to 1.3V</li></ul></li></ul><h5 id="Dennard-Scaling"><a href="#Dennard-Scaling" class="headerlink" title="Dennard Scaling"></a>Dennard Scaling</h5><ul><li><p><strong>Voltage should scale</strong> with transistor size</p></li><li><p>Keeps power consumption and temperature low</p></li><li>Problem: Voltage can’t go too low<ul><li>Must stay above threshold voltage </li><li>Noise problems occur</li></ul></li><li>Problem: Doesn’t consider leakage power</li><li>Dennard scaling must stop</li></ul><h5 id="Multi-Core-Systems"><a href="#Multi-Core-Systems" class="headerlink" title="Multi-Core Systems"></a>Multi-Core Systems</h5><ul><li>P = α * CFV<sup>2</sup></li><li>Cannot increase frequency</li><li>Can still add processor cores, without increasing frequency<ul><li>Trend is apparent today</li></ul></li><li>Parallel execution is needed to exploit multi-core systems</li><li>Code made to execute on multiple cores</li><li>Different programs on different cores</li></ul><h3 id="1-4-Concurrent-vs-Parallel"><a href="#1-4-Concurrent-vs-Parallel" class="headerlink" title="1.4 Concurrent vs Parallel"></a>1.4 Concurrent vs Parallel</h3><h5 id="Concurrent-execution"><a href="#Concurrent-execution" class="headerlink" title="Concurrent execution"></a>Concurrent execution</h5><ul><li>Concurrent execution is not necessarily the same as parallel execution</li><li><strong>Concurrent: start and end times overlap</strong></li><li><strong>Parallel: execute at exactly the same time</strong></li></ul><p><img src="http://qnya.pomo16.club/285.png" style="zoom:50%;"></p><ul><li>Parallel tasks must be executed on different hardware</li><li>Concurrent tasks may be executed on the same hardware<ul><li>Only one task actually executed at a time</li></ul></li><li>Mapping from tasks to hardware is not directly controlled by the programmer<ul><li>At least not in go</li></ul></li></ul><h3 id="1-5-Concurrent-Programming"><a href="#1-5-Concurrent-Programming" class="headerlink" title="1.5 Concurrent Programming"></a>1.5 Concurrent Programming</h3><ul><li>Programmer determines which tasks can be executed in parallel</li><li>Mapping tasks to hardware<ul><li>Operating system</li><li>Go runtime schedule</li></ul></li></ul><h5 id="Benefit-1-Hiding-Latency"><a href="#Benefit-1-Hiding-Latency" class="headerlink" title="Benefit 1: Hiding Latency"></a>Benefit 1: Hiding Latency</h5><ul><li>Concurrency improves performance, even without parallelism</li><li>Tasks must <strong>periodically wait</strong> for something<ul><li>i.e. wait for memory</li><li>X = Y + Z  read Y, Z from memory</li><li>May wait 100+ clock cycles</li></ul></li><li>Other concurrent tasks can operate while one task is waiting</li></ul><h5 id="Benefit-2-Hardware-Mapping"><a href="#Benefit-2-Hardware-Mapping" class="headerlink" title="Benefit 2: Hardware Mapping"></a>Benefit 2: Hardware Mapping</h5><p><img src="http://qnya.pomo16.club/286.png" style="zoom: 25%;"></p><p><strong>Hardware Mapping in Go:</strong></p><ul><li>Programmer does not determine the hardware mapping</li><li>Programmer makes parallelism possible</li><li>Hardware mapping depends on many factors<ul><li>Where is the data?</li><li>What are the communication costs?</li></ul></li></ul><p><img src="http://qnya.pomo16.club/287.png" style="zoom: 33%;"></p><h2 id="2-Concurrency-Basics"><a href="#2-Concurrency-Basics" class="headerlink" title="2. Concurrency Basics"></a>2. Concurrency Basics</h2><h3 id="2-1-Processes"><a href="#2-1-Processes" class="headerlink" title="2.1 Processes"></a>2.1 Processes</h3><ul><li>An instance of a running program</li><li>Things unique to a process<ul><li>Memory<ul><li>Virtual address space</li><li>Code, stack, heap, shared libraries</li></ul></li><li>Registers<ul><li>Program counter, data regs, stack ptr, …</li></ul></li></ul></li></ul><h5 id="Operating-Systems"><a href="#Operating-Systems" class="headerlink" title="Operating Systems"></a>Operating Systems</h5><ul><li>Allows many processes to execute concurrently</li><li>Processes are switched quickly (20ms)</li><li>User has the impression of parallelism </li><li>Operating system must give processes fair access to resources</li></ul><h3 id="2-2-Scheduling"><a href="#2-2-Scheduling" class="headerlink" title="2.2 Scheduling"></a>2.2 Scheduling</h3><h5 id="Scheduling-Processes"><a href="#Scheduling-Processes" class="headerlink" title="Scheduling Processes"></a>Scheduling Processes</h5><ul><li>Operating system schedules processes for execution</li><li>Gives the illusion of parallel execution</li></ul><p><img src="http://qnya.pomo16.club/288.png" style="zoom: 33%;"></p><ul><li>OS gives fair access to CPU, memory, etc.</li></ul><h5 id="Context-Switch"><a href="#Context-Switch" class="headerlink" title="Context Switch"></a>Context Switch</h5><ul><li><p>Control flow changes from one process to another</p><p><img src="http://qnya.pomo16.club/289.png" style="zoom: 50%;"></p></li><li><p>Process “context” must be swapped</p></li></ul><h3 id="2-3-Threads-and-Goroutines"><a href="#2-3-Threads-and-Goroutines" class="headerlink" title="2.3 Threads and Goroutines"></a>2.3 Threads and Goroutines</h3><h5 id="Threads-vs-Processes"><a href="#Threads-vs-Processes" class="headerlink" title="Threads vs Processes"></a>Threads vs Processes</h5><ul><li>Threads share some context</li><li>Many threads can exist in one process</li><li>OS schedules threads rather than proccesses </li></ul><p><img src="http://qnya.pomo16.club/290.png" style="zoom: 33%;"></p><h5 id="Goroutines"><a href="#Goroutines" class="headerlink" title="Goroutines"></a>Goroutines</h5><ul><li>Like a thread in Go</li><li>Many Goroutines execute  within a single OS thread</li></ul><p><img src="http://qnya.pomo16.club/291.png" style="zoom: 33%;"></p><h5 id="Go-Runtime-Scheduler"><a href="#Go-Runtime-Scheduler" class="headerlink" title="Go Runtime Scheduler"></a>Go Runtime Scheduler</h5><ul><li>Schedules goroutines inside an OS thread</li><li>Like a little OS inside a single OS thread</li><li><strong>Logical processor</strong> is mapped to a thread</li></ul><p><img src="http://qnya.pomo16.club/292.png" style="zoom:33%;"></p><h3 id="2-4-Interleavings"><a href="#2-4-Interleavings" class="headerlink" title="2.4 Interleavings"></a>2.4 Interleavings</h3><ul><li>Order of executive within a task is known</li><li>Order of executive between concurrent tasks is unknown</li><li><p>Interleaving of instructions between tasks is unknown</p></li><li><p>Many interleavings are possible</p></li><li>Must consider all possibilities</li><li>Ordering is <strong>non-deterministic</strong></li></ul><h3 id="2-5-Race-Conditions"><a href="#2-5-Race-Conditions" class="headerlink" title="2.5 Race Conditions"></a>2.5 Race Conditions</h3><ul><li>Outcome depends on non-deterministic ordering</li><li>Races occur due to <strong>communication</strong></li></ul><h3 id="2-6-Communication-Between-Tasks"><a href="#2-6-Communication-Between-Tasks" class="headerlink" title="2.6 Communication Between Tasks"></a>2.6 Communication Between Tasks</h3><ul><li>Threads are largely independent but not completely independent</li><li>Web server, one thread per client</li></ul><p><img src="http://qnya.pomo16.club/293.png" style="zoom: 50%;"></p><ul><li>Image processing, 1 thread per pixel block</li></ul><p><img src="http://qnya.pomo16.club/294.png" style="zoom: 33%;"></p><h2 id="3-Threads-in-Go"><a href="#3-Threads-in-Go" class="headerlink" title="3. Threads in Go"></a>3. Threads in Go</h2><h3 id="3-1-Goroutines"><a href="#3-1-Goroutines" class="headerlink" title="3.1 Goroutines"></a>3.1 Goroutines</h3><h5 id="Creating-a-Goroutine"><a href="#Creating-a-Goroutine" class="headerlink" title="Creating a Goroutine"></a>Creating a Goroutine</h5><ul><li>One goroutine is created automatically to execute the main()</li><li>Other goroutines are created using the <strong>go</strong> keyword</li></ul><p><img src="http://qnya.pomo16.club/295.png" style="zoom: 25%;"></p><h5 id="Exiting-a-Goroutine"><a href="#Exiting-a-Goroutine" class="headerlink" title="Exiting a Goroutine"></a>Exiting a Goroutine</h5><ul><li>A goroutine exits <strong>when its code is complete</strong></li><li><strong>When the main goroutine is complete</strong>, all other goroutines exit</li><li><p>A goroutine may not complete its execution because main completes early</p></li><li><p>Adding a delay to wait for a goroutine is <strong>bad</strong>, because timing assumptions may be wrong and timing is nondeterministic</p></li><li>Need formal <strong>synchronization</strong> constructs</li></ul><h3 id="3-2-Basic-Synchronization"><a href="#3-2-Basic-Synchronization" class="headerlink" title="3.2 Basic Synchronization"></a>3.2 Basic Synchronization</h3><ul><li><p>Using <strong>global events</strong> whose execution is viewed by all threads, simultaneously</p></li><li><p>Example:</p><p><img src="http://qnya.pomo16.club/296.png" style="zoom:50%;"></p><ul><li>Global event is viewed by all tasks at the same time</li><li>Print must occur after update of x</li><li>Synchronization is used to restrict bad interleavings</li><li>In this case, synchronization reduces performance and efficiency. It’s bad, but it’s necessary here.</li></ul></li></ul><h3 id="3-3-Wait-Groups"><a href="#3-3-Wait-Groups" class="headerlink" title="3.3 Wait Groups"></a>3.3 Wait Groups</h3><h5 id="Sync-WaitGroup"><a href="#Sync-WaitGroup" class="headerlink" title="Sync WaitGroup"></a>Sync WaitGroup</h5><ul><li>Sync package contains functions to synchronize between goroutines</li><li><p><strong>sync.WaitGroup</strong> forces a goroutine to wait for other goroutines</p></li><li><p>Contains an internal counter</p><ul><li>Increment counter for each goroutine to wait for</li><li>Decrement counter when each goroutine completes</li><li>Waiting goroutine cannot continue until counter is 0</li></ul></li></ul><h5 id="Using-WaitGroup"><a href="#Using-WaitGroup" class="headerlink" title="Using WaitGroup"></a>Using WaitGroup</h5><p><img src="http://qnya.pomo16.club/297.png" style="zoom: 50%;"></p><ul><li><code>Add()</code>  increments the counter</li><li><code>Done()</code> decrements the counter</li><li><code>Wait()</code> blocks until counter == 0</li></ul><h5 id="WaitGroup-Example"><a href="#WaitGroup-Example" class="headerlink" title="WaitGroup Example"></a>WaitGroup Example</h5><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">foo</span><span class="params">(wg *sync.WaitGroup)</span></span> &#123;</span><br><span class="line">  fmt.Printf(<span class="string">"New routine"</span>)</span><br><span class="line">  wg.Done()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">  wg.Add(<span class="number">1</span>)</span><br><span class="line">  <span class="keyword">go</span> foo(&amp;wg)</span><br><span class="line">  wg.Wait()</span><br><span class="line">  fmt.Printf(<span class="string">"Main routine"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-4-Communication"><a href="#3-4-Communication" class="headerlink" title="3.4 Communication"></a>3.4 Communication</h3><h5 id="Goroutine-Communication"><a href="#Goroutine-Communication" class="headerlink" title="Goroutine Communication"></a>Goroutine Communication</h5><ul><li>Goroutines usually work together to perform a bigger task</li><li>Often need to send data to collaborate</li><li>Example: Find the product of 4 integers<ul><li>Make 2 goroutines, each multiplies a pair</li><li>Main goroutine multiplies the 2 results</li><li>Need to send ints from main routine to the two sub-routines</li><li>Need to send results from sub-routines back to main routine</li></ul></li></ul><h5 id="Channels"><a href="#Channels" class="headerlink" title="Channels"></a>Channels</h5><ul><li>Transfer data between goroutines</li><li>Channels are typed</li><li>Use <code>make()</code> to create a channel</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br></pre></td></tr></table></figure><ul><li>Send and  receive data using the <code>&lt;-</code> operator</li><li>Send data on a channel</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c &lt;- <span class="number">3</span></span><br></pre></td></tr></table></figure><ul><li>Receive data from a channel</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x := &lt;- c</span><br></pre></td></tr></table></figure><ul><li>Channel example:</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">prod</span><span class="params">(v1 <span class="keyword">int</span>, v2 <span class="keyword">int</span>, c <span class="keyword">chan</span> <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">  c &lt;- v1 * v2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line">  <span class="keyword">go</span> prod(<span class="number">1</span>, <span class="number">2</span>, c)</span><br><span class="line">  <span class="keyword">go</span> prod(<span class="number">3</span>, <span class="number">4</span>, c)</span><br><span class="line">  a := &lt;- c</span><br><span class="line">  b := &lt;- c</span><br><span class="line">  fmt.Println(a * b)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-5-Blocking-in-Channels"><a href="#3-5-Blocking-in-Channels" class="headerlink" title="3.5 Blocking in Channels"></a>3.5 Blocking in Channels</h3><h5 id="Unbuffered-Channel"><a href="#Unbuffered-Channel" class="headerlink" title="Unbuffered Channel"></a>Unbuffered Channel</h5><ul><li>Unbuffered channels cannot hold data in transit<ul><li>Default is unbuffered</li></ul></li><li>Sending blocks until data is received</li><li>Receiving blocks until data is sent</li></ul><h5 id="Blocking-and-Synchronization"><a href="#Blocking-and-Synchronization" class="headerlink" title="Blocking and Synchronization"></a>Blocking and Synchronization</h5><ul><li>Channel communication is synchronous</li><li>Blocking is the same as waiting for communication</li><li>Receiving and ignoring the result is the same as a <code>Wait()</code></li></ul><h3 id="3-6-Buffered-Channels"><a href="#3-6-Buffered-Channels" class="headerlink" title="3.6 Buffered Channels"></a>3.6 Buffered Channels</h3><h5 id="Channel-Capacity"><a href="#Channel-Capacity" class="headerlink" title="Channel Capacity"></a>Channel Capacity</h5><ul><li>Channels can contain a limited number of objects<ul><li>Default size 0(unbuffered)</li></ul></li><li>Capacity is the number of objects it can hold in transit</li><li>Optional argument to <code>make()</code> defines channel capacity</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure><ul><li>Sending only blocks if <strong>buffer is full</strong></li><li>Receiving only blocks if <strong>buffer is empty</strong></li></ul><h5 id="Channel-Blocking-Receive"><a href="#Channel-Blocking-Receive" class="headerlink" title="Channel Blocking, Receive"></a>Channel Blocking, Receive</h5><ul><li>Channel with capacity 1</li></ul><p><img src="http://qnya.pomo16.club/298.png" style="zoom: 33%;"></p><ul><li>First receive blocks until send occurs</li><li>Second receive blocks forever</li></ul><h5 id="Channel-Blocking-Send"><a href="#Channel-Blocking-Send" class="headerlink" title="Channel Blocking, Send"></a>Channel Blocking, Send</h5><p><img src="http://qnya.pomo16.club/299.png" style="zoom: 33%;"></p><ul><li>Second send blocks until receive is done</li><li>Receive can block until first send is done</li></ul><h5 id="Use-of-Buffering"><a href="#Use-of-Buffering" class="headerlink" title="Use of Buffering"></a>Use of Buffering</h5><ul><li>Sender and receiver do not need to operate at exactly the same speed</li></ul><p><img src="http://qnya.pomo16.club/300.png" style="zoom: 33%;"></p><ul><li>Speed mismatch is acceptable</li></ul><h2 id="4-Synchronized-Communication"><a href="#4-Synchronized-Communication" class="headerlink" title="4. Synchronized Communication"></a>4. Synchronized Communication</h2><h3 id="4-1-Blocking-on-Channels"><a href="#4-1-Blocking-on-Channels" class="headerlink" title="4.1 Blocking on Channels"></a>4.1 Blocking on Channels</h3><h5 id="Iterating-Through-a-Channel"><a href="#Iterating-Through-a-Channel" class="headerlink" title="Iterating Through a Channel"></a>Iterating Through a Channel</h5><ul><li>Common to iteratively read from a channel</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i := <span class="keyword">range</span> c &#123;</span><br><span class="line">  fmt.Println(i)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>Continues to read from channel c</li><li>One iteration each time a new value is received</li><li>i is assigned to the read value</li><li>Iterates when sender calls <code>close(c)</code></li></ul><h5 id="Receiving-from-Multiple-Goroutines"><a href="#Receiving-from-Multiple-Goroutines" class="headerlink" title="Receiving from Multiple Goroutines"></a>Receiving from Multiple Goroutines</h5><ul><li>Multiple channels may be used to receive from multiple sources</li></ul><p><img src="http://qnya.pomo16.club/301.png" style="zoom: 33%;"></p><ul><li>Data from both sources may be needed</li><li>Read sequentially</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a := &lt;- c1</span><br><span class="line">b := &lt;- c2</span><br><span class="line">fmt.Println(a*b)</span><br></pre></td></tr></table></figure><h5 id="Select-Statement"><a href="#Select-Statement" class="headerlink" title="Select Statement"></a>Select Statement</h5><ul><li>May have a choice of which data to use<ul><li>i.e. First-come first-served</li></ul></li><li>Use the <code>select</code> statement to wait on the first data from a set of channels</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> a = &lt;- c1:</span><br><span class="line">  fmt.Println(a)</span><br><span class="line">  <span class="keyword">case</span> b = &lt;- c2:</span><br><span class="line">  fmt.Println(b)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-2-Select"><a href="#4-2-Select" class="headerlink" title="4.2 Select"></a>4.2 Select</h3><h5 id="Select-Send-or-Receive"><a href="#Select-Send-or-Receive" class="headerlink" title="Select Send or Receive"></a>Select Send or Receive</h5><ul><li>May select either send or receive operations</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> a = &lt;- inchan:</span><br><span class="line">  fmt.Println(<span class="string">"Received a"</span>)</span><br><span class="line">  <span class="keyword">case</span> outchan &lt;- b:</span><br><span class="line">  fmt.Println(<span class="string">"Sent b"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="Select-with-an-Abort-channel"><a href="#Select-with-an-Abort-channel" class="headerlink" title="Select with an Abort channel"></a>Select with an Abort channel</h5><ul><li>Use select with a <strong>separate abort channel</strong></li><li>May want to receive data until an <strong>abort signal</strong> is received</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">  <span class="keyword">select</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> a = &lt;- c:</span><br><span class="line">    fmt.Println(a)</span><br><span class="line">    <span class="keyword">case</span> &lt;-abort:</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="Default-Select"><a href="#Default-Select" class="headerlink" title="Default Select"></a>Default Select</h5><ul><li>May want a default operation to avoid blocking</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> a = &lt;- c1:</span><br><span class="line">  fmt.Println(a)</span><br><span class="line">  <span class="keyword">case</span> b = &lt;- c2:</span><br><span class="line">  fmt.Println(b)</span><br><span class="line">  <span class="keyword">default</span>:</span><br><span class="line">  fmt.Println(<span class="string">"nop"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-3-Mutual-Exclution"><a href="#4-3-Mutual-Exclution" class="headerlink" title="4.3 Mutual Exclution"></a>4.3 Mutual Exclution</h3><h5 id="Goroutines-Sharing-Variables"><a href="#Goroutines-Sharing-Variables" class="headerlink" title="Goroutines Sharing Variables"></a>Goroutines Sharing Variables</h5><ul><li>Sharing variables concurrently can cause problems</li><li><p>Two goroutines writing to a shared variable can interfere with each other</p></li><li><p>Function can be invoked concurrently without interfering with other goroutines(<strong>Concurrency-Safe</strong>)</p></li></ul><h5 id="Variable-Sharing-Example"><a href="#Variable-Sharing-Example" class="headerlink" title="Variable Sharing Example"></a>Variable Sharing Example</h5><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> i <span class="keyword">int</span> = <span class="number">0</span></span><br><span class="line"><span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">inc</span><span class="params">()</span></span> &#123;</span><br><span class="line">  i = i + <span class="number">1</span></span><br><span class="line">  wg.Done()</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  wg.Add(<span class="number">2</span>)</span><br><span class="line">  <span class="keyword">go</span> inc()</span><br><span class="line">  <span class="keyword">go</span> inc()</span><br><span class="line">  wg.Wait()</span><br><span class="line">  fmt.Println(i)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>Two goroutines write to i</li><li>i should equal 2, but this doesn’t always happen. Because there are some possible interleavings</li></ul><h5 id="Granularity-of-Concurrency"><a href="#Granularity-of-Concurrency" class="headerlink" title="Granularity of Concurrency"></a>Granularity of Concurrency</h5><ul><li>Concurrency is at the machine code level</li><li>i = i + 1 might be three machine instructions</li></ul><p><img src="http://qnya.pomo16.club/302.png" style="zoom: 50%;"></p><ul><li><p>Interleaving machine instructions causes unexpected problems</p></li><li><p>Interleaving machine instructions</p><ul><li><p>Both tasks read 0 for 1 value</p><p><img src="http://qnya.pomo16.club/303.png" style="zoom: 25%;"></p></li></ul></li></ul><h3 id="4-4-Mutex"><a href="#4-4-Mutex" class="headerlink" title="4.4 Mutex"></a>4.4 Mutex</h3><h5 id="Correct-Sharing"><a href="#Correct-Sharing" class="headerlink" title="Correct Sharing"></a>Correct Sharing</h5><ul><li>Don‘t let 2 goroutines write to a shared variable at the same time!</li><li>Need to restrict possible interleavings</li><li>Access to shared variables cannot be interleaved</li><li>Code segements in different goroutines which cannot execute concurrently(<strong>Mutual Exclusion</strong>)</li><li>Writing to shared variables should be mutually exclusive</li></ul><h5 id="Sync-Mutex"><a href="#Sync-Mutex" class="headerlink" title="Sync.Mutex"></a>Sync.Mutex</h5><ul><li>A Mutex ensures mutual exclusion</li><li>Uses a <strong>binary semaphore</strong></li></ul><p><img src="http://qnya.pomo16.club/304.png" style="zoom: 33%;"></p><ul><li>Flag up - shared variable is in use</li><li>Flag down - shared variable is available</li></ul><h3 id="4-5-Mutex-Methods"><a href="#4-5-Mutex-Methods" class="headerlink" title="4.5 Mutex Methods"></a>4.5 Mutex Methods</h3><p>#####Sync.Mutex Methods</p><ul><li><code>Lock()</code> method puts the flag up<ul><li>Shared variable in use</li></ul></li><li><p>If lock is already taken by a goroutine, <code>Lock()</code> blocks until the flag is put down</p></li><li><p><code>Unlock()</code> method puts the flag down</p><ul><li>Done using shared variable</li></ul></li><li>When <code>Unlock()</code> is called, a blocked <code>Lock()</code> can proceed</li></ul><h5 id="Using-Sync-Mutex"><a href="#Using-Sync-Mutex" class="headerlink" title="Using Sync.Mutex"></a>Using Sync.Mutex</h5><ul><li>Increment operation is now mutually exclutive</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> i <span class="keyword">int</span> = <span class="number">0</span></span><br><span class="line"><span class="keyword">var</span> mut sync.Mutex</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">inc</span><span class="params">()</span></span> &#123;</span><br><span class="line">  mut.Lock()</span><br><span class="line">  i = i + <span class="number">1</span></span><br><span class="line">  mut.Unlock()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-6-Once-Synchronization"><a href="#4-6-Once-Synchronization" class="headerlink" title="4.6 Once Synchronization"></a>4.6 Once Synchronization</h3><h5 id="Synchronous-Initialization"><a href="#Synchronous-Initialization" class="headerlink" title="Synchronous Initialization"></a>Synchronous Initialization</h5><ul><li>Initialization<ul><li>must happen once</li><li>must happen before everything else</li></ul></li><li>How do you perform initialization with multiple goroutines?</li><li>Could perform initialization before starting the goroutines?</li></ul><h5 id="Sync-Once"><a href="#Sync-Once" class="headerlink" title="Sync.Once"></a>Sync.Once</h5><ul><li>Has one method, <code>once.Do(f)</code></li><li>Function if is executed only one time<ul><li>Even if it is called in multiple goroutines</li></ul></li><li>All calls to <code>once.Do()</code> block until the first returns<ul><li>Ensures that initialization executes first</li></ul></li></ul><p>#####Sync.Once  Example</p><ul><li>Make two goroutines, initialization only once</li><li>Each goroutine executes <code>dostuff()</code></li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  wg.Add(<span class="number">2</span>)</span><br><span class="line">  <span class="keyword">go</span> dostuff()</span><br><span class="line">  <span class="keyword">go</span> dostuff()</span><br><span class="line">  wg.Wait()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>Using Sync.Once</p><ul><li><p><code>setup()</code> should execute only once</p></li><li><p>“hello” should not print until <code>setup()</code> returns</p></li><li><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> on sync.Once</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">setup</span><span class="params">()</span></span> &#123;</span><br><span class="line">  fmt.Println(<span class="string">"Init"</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">dostuff</span><span class="params">()</span></span> &#123;</span><br><span class="line">  on.Do(setup)</span><br><span class="line">  fmt.Println(<span class="string">"hello"</span>)</span><br><span class="line">  wg.Done()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>Execution Result</p><ul><li><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Init        <span class="comment">//Result of setup()</span></span><br><span class="line">hello       <span class="comment">//Result of one goroutine</span></span><br><span class="line">hello       <span class="comment">//Result of the other goroutine</span></span><br></pre></td></tr></table></figure></li><li><p><code>Init</code> appears only once</p></li><li><p><code>Init</code> appears before <code>hello</code> is printed</p></li></ul></li></ul><h3 id="4-7-Deadlock"><a href="#4-7-Deadlock" class="headerlink" title="4.7 Deadlock"></a>4.7 Deadlock</h3><h5 id="Synchronization-Dependencies"><a href="#Synchronization-Dependencies" class="headerlink" title="Synchronization Dependencies"></a>Synchronization Dependencies</h5><ul><li>Synchronization causes the execution of different goroutines to depend on each other</li></ul><p><img src="http://qnya.pomo16.club/305.png" style="zoom: 33%;"></p><ul><li>G2 cannot continue until G1 does something</li></ul><h5 id="Deadlock"><a href="#Deadlock" class="headerlink" title="Deadlock"></a>Deadlock</h5><ul><li><strong>Circular dependencies</strong> cause all involved goroutines to block<ul><li>G1 waits for G2</li><li>G2 waits for G1</li></ul></li><li>Can be caused by waiting on channels</li></ul><h5 id="Deadlock-Example"><a href="#Deadlock-Example" class="headerlink" title="Deadlock Example"></a>Deadlock Example</h5><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">dostuff</span><span class="params">(c1 <span class="keyword">chan</span> <span class="keyword">int</span>, c2 <span class="keyword">chan</span> <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">  &lt;- c1</span><br><span class="line">  c2 &lt;- <span class="number">1</span></span><br><span class="line">  wg.Done()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>Read from first channel<ul><li>Wait for write onto first channel</li></ul></li><li>Write to second channel<ul><li>Wait for read from second channel</li></ul></li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  ch1 := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line">  ch2 := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line">  wg.Add(<span class="number">2</span>)</span><br><span class="line">  <span class="keyword">go</span> dostuff(ch1, ch2)</span><br><span class="line">  <span class="keyword">go</span> dostuff(ch2, ch1)</span><br><span class="line">  wg.Wait()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><code>dostuff()</code> argument order is swapped</li><li>Each goroutine blocked on channel read</li></ul><h5 id="Deadlock-Detection"><a href="#Deadlock-Detection" class="headerlink" title="Deadlock Detection"></a>Deadlock Detection</h5><ul><li>Golang runtime automatically detects when all goroutines are deadlocked</li></ul><p><img src="http://qnya.pomo16.club/306.png" style="zoom: 50%;"></p><ul><li>Cannot detect when a subset of goroutines are deadlocked</li></ul><h3 id="4-8-Dining-Philosophers"><a href="#4-8-Dining-Philosophers" class="headerlink" title="4.8 Dining Philosophers"></a>4.8 Dining Philosophers</h3><h5 id="Dining-Philosophers-Problem"><a href="#Dining-Philosophers-Problem" class="headerlink" title="Dining Philosophers Problem"></a>Dining Philosophers Problem</h5><ul><li><p>Classical problem involvingconcurrency and synchronization</p></li><li><p>Problem:</p><ul><li>5 philosophers sitting at a round table</li><li>1 chopstick is placed between each adjacent pair</li><li>Want to eat rice from their plate, but needs two chopsticks</li><li>Only one philosopher can hold a chopstick at a time</li><li>Not enough chopsticks for everyone to eat at once</li></ul><p><img src="http://qnya.pomo16.club/307.png" style="zoom:50%;"></p></li><li><p>Each chopstick is a mutex</p></li><li><p>Each philosopher is associated with a goroutine and two chopsticks</p></li><li><p>Chopsticks and Philosophers</p><ul><li><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Chops <span class="keyword">struct</span> &#123;</span><br><span class="line">  sync.Mutex</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Philo <span class="keyword">struct</span> &#123;</span><br><span class="line">  leftCS, rightCS *Chops</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>Philosopher Eat Method</p><ul><li><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span><span class="params">(p Philo)</span> <span class="title">eat</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">for</span> &#123;</span><br><span class="line">    p.leftCS.Lock()</span><br><span class="line">    p.rightCS.Lock()</span><br><span class="line">    </span><br><span class="line">    fmt.Println(<span class="string">"eating"</span>)</span><br><span class="line">    </span><br><span class="line">    p.rightCS.Unlock()</span><br><span class="line">    p.leftCS.Unlock()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>Initialization in Main</p><ul><li><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CSticks := <span class="built_in">make</span>([]*Chops, <span class="number">5</span>)</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ &#123;</span><br><span class="line">  CSticks[i] = <span class="built_in">new</span>(ChopS)</span><br><span class="line">&#125;</span><br><span class="line">philos := <span class="built_in">make</span>([]*Philo, <span class="number">5</span>)</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ &#123;</span><br><span class="line">  philos[i] = &amp;Philo&#123;Csticks[i], Csticks[(i + <span class="number">1</span>) % <span class="number">5</span>]&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Initialize chopsticks and philosophers</p></li><li><p>Notice <code>(i + 1) % 5]</code> </p></li></ul></li><li><p>Start the Dining in Main</p><ul><li><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ &#123;</span><br><span class="line">  <span class="keyword">go</span> philos[i].eat()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Start each philosopher eating</p></li><li><p>Would also need to wait in the main</p></li></ul></li><li><p>Deadlock Problem</p><ul><li><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">p.leftCS.Lock()</span><br><span class="line">p.rightCS.Lock()</span><br><span class="line">fmt.Println(<span class="string">"eating"</span>)</span><br><span class="line">p.leftCS.Unlock()</span><br><span class="line">p.rightCS.Unlock()</span><br></pre></td></tr></table></figure></li><li><p>All philosophers might lock their left chopsticks concurrently</p></li><li><p>All chopsticks would be locked</p></li><li><p>Noone can lock their right chopsticks</p></li></ul></li><li><p>Deadlock Solution</p><ul><li><p>Each philosopher <strong>picks up lowest numbered chopstick first</strong></p></li><li><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ &#123;</span><br><span class="line">  <span class="keyword">if</span> i &lt; (i + <span class="number">1</span>) % <span class="number">5</span> &#123;</span><br><span class="line">    philos[i] = &amp;Philo&#123;Csticks[i], Csticks[(i + <span class="number">1</span>) % <span class="number">5</span>]&#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    philos[i] = &amp;Philo&#123;Csticks[(i + <span class="number">1</span>) % <span class="number">5</span>], Csticks[i]&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>Philosopher 4 picks up chopstick 0 before chopstick 4</p></li><li><p>Philosopher 4 blocks allowing philosopher 3 to eat</p></li><li><p>No deadlock, but philosopher 4 may starve</p></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      Explore golang concurrency
    
    </summary>
    
      <category term="go" scheme="http://yoursite.com/categories/go/"/>
    
    
      <category term="go" scheme="http://yoursite.com/tags/go/"/>
    
  </entry>
  
  <entry>
    <title>Docker搭建FTP</title>
    <link href="http://yoursite.com/2020/04/22/Docker%E6%90%AD%E5%BB%BAFTP/"/>
    <id>http://yoursite.com/2020/04/22/Docker搭建FTP/</id>
    <published>2020-04-22T07:39:39.000Z</published>
    <updated>2020-06-05T12:39:52.863Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Docker-镜像拉取"><a href="#Docker-镜像拉取" class="headerlink" title="Docker 镜像拉取"></a>Docker 镜像拉取</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull fauria/vsftpd</span><br></pre></td></tr></table></figure><h2 id="创建容器"><a href="#创建容器" class="headerlink" title="创建容器"></a>创建容器</h2><p>直接添加用户名和密码创建容器，需要修改用户名、密码、宿主机IP：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 20:20 -p 21:21 -p 21100-21110:21100-21110 -v /Ftpfile:/home/vsftpd -e FTP_USER=user -e FTP_PASS=userpwd -e PASV_ADDRESS=&lt;宿主机ip&gt; -e PASV_MIN_PORT=21100 -e PASV_MAX_PORT=21110 --name vsftpd --restart=always fauria/vsftpd</span><br></pre></td></tr></table></figure><p>或创建容器后再设置用户名和密码：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 20:20 -p 21:21 -p 21100-21110:21100-21110 -v /Ftpfile:/home/vsftpd -e PASV_ADDRESS=&lt;宿主机ip&gt; -e PASV_MIN_PORT=21100 -e PASV_MAX_PORT=21110 --name vsftpd --restart=always fauria/vsftpd</span><br></pre></td></tr></table></figure><h2 id="进入容器并修改账号密码"><a href="#进入容器并修改账号密码" class="headerlink" title="进入容器并修改账号密码"></a>进入容器并修改账号密码</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -i -t vsftpd bash</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/vsftpd/virtual_users.txt</span><br></pre></td></tr></table></figure><p>奇数行为用户名，偶数行为密码</p><h2 id="创建用户文件夹"><a href="#创建用户文件夹" class="headerlink" title="创建用户文件夹"></a>创建用户文件夹</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /home/vsftpd/&lt;新用户名&gt;</span><br></pre></td></tr></table></figure><h2 id="刷新用户配置"><a href="#刷新用户配置" class="headerlink" title="刷新用户配置"></a>刷新用户配置</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/bin/db_load -T -t hash -f /etc/vsftpd/virtual_users.txt /etc/vsftpd/virtual_users.db</span><br></pre></td></tr></table></figure><h2 id="退出容器并重启"><a href="#退出容器并重启" class="headerlink" title="退出容器并重启"></a>退出容器并重启</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exit</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart vsftpd</span><br></pre></td></tr></table></figure><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>访问 <code>ftp://&lt;宿主机ip&gt;</code></p><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><ul><li>支持中文字符集</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -i -t vsftpd bash</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/profile</span><br></pre></td></tr></table></figure><p>添加 <figure class="highlight plain"><figcaption><span>LANG</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">```source /etc/profile</span><br></pre></td></tr></table></figure></p><p>退出并重启容器</p>]]></content>
    
    <summary type="html">
    
      使用 Docker 搭建 FTP 服务器。
    
    </summary>
    
      <category term="web" scheme="http://yoursite.com/categories/web/"/>
    
      <category term="docker" scheme="http://yoursite.com/categories/web/docker/"/>
    
    
      <category term="ftp" scheme="http://yoursite.com/tags/ftp/"/>
    
  </entry>
  
  <entry>
    <title>Go Garbage Collection</title>
    <link href="http://yoursite.com/2019/10/30/Go-Garbage-Collection/"/>
    <id>http://yoursite.com/2019/10/30/Go-Garbage-Collection/</id>
    <published>2019-10-30T15:12:01.000Z</published>
    <updated>2019-10-30T15:16:06.677Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>go 语言的 GC 代码可以在源码文件 <a href="https://golang.org/src/runtime/mgc.go" target="_blank" rel="noopener">src/runtime/mgc.go</a> 看到，其注释看门见山地概括了 go 的 GC：</p><blockquote><p>The GC runs concurrently with mutator threads, is type accurate (aka precise), allows multiple GC thread to run in parallel. It is a concurrent mark and sweep that uses a write barrier. It is non-generational and non-compacting. Allocation is done using size segregated per P allocation areas to minimize fragmentation while eliminating locks in the common case.</p></blockquote><p>总结为一句话就是：go 的 GC 算法是非分代、非紧缩、写屏障的三色并发标记清理算法。</p><ul><li>非分代：go GC 并没有像 Java 一样分新生代和老年代，所以也不存在 minor gc 和 full gc 之分</li><li>非紧缩：go GC 之后不会整理内存，清理内存碎片</li><li>写屏障：类似于 Java 的 G1(Garbage-First) 垃圾收集器中的并发标记，写屏障保证了 GC 期间用户线程 (mutator) 进行的内存更改能被监视，避免了标记遗漏和错误标记</li></ul><h2 id="标记清除-Mark-And-Sweep-算法"><a href="#标记清除-Mark-And-Sweep-算法" class="headerlink" title="标记清除(Mark And Sweep)算法"></a>标记清除(Mark And Sweep)算法</h2><p>该算法主要有两个步骤：标记和清除。标记阶段对对象进行可达性分析，并进行标记。清除阶段则回收未被标记的对象。</p><p><img src="http://qnya.pomo16.club/279.png" alt="image-20191030164145042" style="zoom:50%;"></p><p>图片所示就是标记清除的全过程，标记清除虽然简单，但是这也带来了很多问题：</p><ol><li>STW(stop the world): 标记清除在执行1之前要停止程序，并在4之后恢复运行，执行 GC 期间需要暂停用户线程，造成程序卡顿</li><li>标记对象时需要扫描整个 heap，费时费力</li><li>清除数据后会产生不连续的 heap 碎片</li></ol><p>三个问题中，STW 是首要问题，于是 go 使用了三色并发标记法来解决。</p><h2 id="三色并发标记法：基本步骤"><a href="#三色并发标记法：基本步骤" class="headerlink" title="三色并发标记法：基本步骤"></a>三色并发标记法：基本步骤</h2><p>三色并发标记法为对象定义了三种颜色(状态)：</p><ol><li>黑色：对象在这次 GC 中已标记，且这个对象包含的子对象也已标记</li><li>灰色：对象在这次 GC 中已标记， 但这个对象包含的子对象未标记</li><li>白色：对象在这次 GC 中未标记</li></ol><p><img src="http://qnya.pomo16.club/280.png" alt="image-20191030170547670" style="zoom:50%;"></p><p>步骤解析：</p><ol><li>程序创建的对象都标记为白色</li><li>gc 开始：扫描所有可到达的对象，标记为灰色</li><li>从灰色对象中找到其引用对象标记为灰色，把灰色对象本身标记为黑色</li><li>监视对象中的内存修改，并持续上一步的操作，直到灰色标记的对象不存在</li><li>gc 回收白色对象</li><li>最后，将所有黑色对象变为白色，并重复以上所有过程</li></ol><h2 id="三色并发标记法：GC-和用户线程的并行"><a href="#三色并发标记法：GC-和用户线程的并行" class="headerlink" title="三色并发标记法：GC 和用户线程的并行"></a>三色并发标记法：GC 和用户线程的并行</h2><p>mark and sweep 的 STW 操作，就是 runtime 把所有的线程全部冻结掉，所有的线程全部冻结意味着用户逻辑是暂停的。这样所有的对象都不会被修改了，这时候去扫描是绝对安全的。</p><p>go 如何减短这个过程呢？mark and sweep 包含两部分逻辑：标记和清除。 我们知道三色标记法中最后只剩下的黑白两种对象，黑色对象是程序恢复后接着使用的对象，如果不碰触黑色对象，只清除白色的对象，肯定不会影响程序逻辑。所以清除操作和用户逻辑可以并发。</p><p>但是标记操作和用户逻辑也是并发的，用户逻辑会时常生成对象或者改变对象的引用，那么标记和用户逻辑如何并发呢？</p><h4 id="并发问题一：process-新生成对象的时候，GC-该如何操作呢？"><a href="#并发问题一：process-新生成对象的时候，GC-该如何操作呢？" class="headerlink" title="并发问题一：process 新生成对象的时候，GC 该如何操作呢？"></a>并发问题一：process 新生成对象的时候，GC 该如何操作呢？</h4><p>如下图，process 在标记阶段生成一个新对象，我们可能会这么认为：</p><p><img src="http://qnya.pomo16.club/281.png" alt="image-20191030171908778" style="zoom:50%;"></p><p>但是这样显然是不对的，因为按照三色标记法的步骤，这样新生成的对象 A 最后会被清除掉，这样会影响程序逻辑。Golang 为了解决这个问题，引入了<strong>写屏障</strong>这个机制。 </p><p>写屏障：该屏障之前的写操作和之后的写操作相比，先被系统其它组件感知。 通俗的讲：就是在 gc 跑的过程中，可以监控对象的内存修改，并对对象进行重新标记。(实际上也是超短暂的 STW，然后对对象进行标记)</p><p>在上述情况中，新生成的对象，一律都标为灰色！ 即下图：</p><p><img src="http://qnya.pomo16.club/282.png" alt="image-20191030172200747" style="zoom:50%;"></p><h4 id="并发问题二：灰色或者黑色对象的引用改为白色对象的时候，Golang-是该如何操作？"><a href="#并发问题二：灰色或者黑色对象的引用改为白色对象的时候，Golang-是该如何操作？" class="headerlink" title="并发问题二：灰色或者黑色对象的引用改为白色对象的时候，Golang 是该如何操作？"></a>并发问题二：灰色或者黑色对象的引用改为白色对象的时候，Golang 是该如何操作？</h4><p>看如下图，一个黑色对象引用了曾经标记的白色对象。</p><p><img src="http://qnya.pomo16.club/283.png" alt="image-20191030172355846" style="zoom:50%;"></p><p>这时候，写屏障机制被触发，向 GC 发送信号，GC 重新扫描对象并标位灰色。</p><p><img src="http://qnya.pomo16.club/284.png" alt="image-20191030172522998" style="zoom:50%;"></p><p>因此，GC 一旦开始，无论是创建对象还是对象的引用改变，都会先变为灰色。</p><h2 id="Go-GC-的未来"><a href="#Go-GC-的未来" class="headerlink" title="Go GC 的未来"></a>Go GC 的未来</h2><p>尽管目前 go GC 相比以往版本已经大有改进，效率也今非昔比，但是仍存在一些痛点，所以 go 团队有意在未来的版本尝试 Java 上比较先进的分代思想。</p><p>分代思想主要是能解决当前 go 的 GC 频繁问题，在标记阶段 go 需要一定的 CPU 资源来 Mark Scan 所有对象，导致 GC 的 CPU 消耗比较高。</p><p>另外，相对于增加 CPU 消耗(比如写屏障)的方案， Go 团队会更倾向于占用内存多一些方案。因为 Go 团队认为，CPU 的摩尔定律发展已经减缓，18个月翻倍减缓为2年，4年…而内存容量和价格的摩尔定律仍在继续。一个稍微更占用内存的解决方案比更占用 CPU 的解决方案拥有更好的扩展性。</p>]]></content>
    
    <summary type="html">
    
      分析go的垃圾回收机制
    
    </summary>
    
      <category term="go" scheme="http://yoursite.com/categories/go/"/>
    
    
      <category term="go" scheme="http://yoursite.com/tags/go/"/>
    
  </entry>
  
  <entry>
    <title>git</title>
    <link href="http://yoursite.com/2019/10/20/git/"/>
    <id>http://yoursite.com/2019/10/20/git/</id>
    <published>2019-10-20T03:22:55.000Z</published>
    <updated>2019-10-22T02:08:51.218Z</updated>
    
    <content type="html"><![CDATA[<h2 id="First-Step"><a href="#First-Step" class="headerlink" title="First Step"></a>First Step</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name "xxx"</span><br><span class="line">git config --global user.email "xxx@gmail.com"</span><br><span class="line"></span><br><span class="line">git config --global color.ui true</span><br></pre></td></tr></table></figure><h2 id="Create-repo"><a href="#Create-repo" class="headerlink" title="Create repo"></a>Create repo</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git init</span><br><span class="line">git add .</span><br></pre></td></tr></table></figure><p>.git 目录说明：</p><p>hooks：记录一些校验用的 goal 值</p><p>info：配置，如 .gitignore</p><p>objects：主要目录，只要这个不丢所有信息都可以还原</p><p>refs：记录分支</p><p>remotes：远端分支</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -m ’first commit‘</span><br></pre></td></tr></table></figure><p>此时 objects 和 refs 会略有变化</p><h2 id="Clone-One"><a href="#Clone-One" class="headerlink" title="Clone One"></a>Clone One</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone repourl</span><br></pre></td></tr></table></figure><h2 id="A-Basic-Workflow"><a href="#A-Basic-Workflow" class="headerlink" title="A Basic Workflow"></a>A Basic Workflow</h2><ol><li>Edit file：<code>vim / emacs / etc</code></li><li>Stage the changes：<code>git add (file)</code></li><li>Review your changes：<code>git status / git diff</code></li><li>Commit the changes：<code>git commit</code></li></ol><h2 id="Branching-and-Merging"><a href="#Branching-and-Merging" class="headerlink" title="Branching and Merging"></a>Branching and Merging</h2><h4 id="Branching"><a href="#Branching" class="headerlink" title="Branching"></a>Branching</h4><p>创建分支</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch xxx</span><br></pre></td></tr></table></figure><p>查看分支状态</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch</span><br></pre></td></tr></table></figure><p>切换分支</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout xxx(分支号)</span><br></pre></td></tr></table></figure><p>删除分支（-d 只可删除已被 merge 的空指针，-D 强制删除分支指针）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git branch -d xxx</span><br><span class="line">git branch -D xxx</span><br></pre></td></tr></table></figure><h4 id="Merging"><a href="#Merging" class="headerlink" title="Merging"></a>Merging</h4><p>合并分支</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git merge xxx</span><br></pre></td></tr></table></figure><p>可视化解决冲突</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git mergetool</span><br></pre></td></tr></table></figure><h2 id="Collaboration"><a href="#Collaboration" class="headerlink" title="Collaboration"></a>Collaboration</h2><p>拉取远端代码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone xxx</span><br></pre></td></tr></table></figure><p>提交代码到远端，如果远端被别人修改了，此时会 push 失败</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push origin master</span><br></pre></td></tr></table></figure><p>失败的话就要先把远端的新版代码 fetch 下来</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git fetch</span><br></pre></td></tr></table></figure><p>然后把 fetch 下来的新代码和自己改的代码 merge 之后就可以 push 了，或者直接 pull，不建议使用，git pull = git fetch + git merge</p><p>或者用 rebase 保证线性历史（下图等价于 git pull –rebase = git fetch + git rebase）</p><p><img style="height:300px" src="http://qnya.pomo16.club/263.png"></p><h2 id="查看"><a href="#查看" class="headerlink" title="查看"></a>查看</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git log xxx(默认 HEAD)</span><br></pre></td></tr></table></figure><p>–oneline：简单参数展示</p><p>–graph：简易图像</p><p>–all：把所有分支展示</p><p>–decorate：把分支名也展示</p><p>返回两图差集：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git log A ^B</span><br></pre></td></tr></table></figure><h2 id="多人协作常用流程"><a href="#多人协作常用流程" class="headerlink" title="多人协作常用流程"></a>多人协作常用流程</h2><ol><li>新建远程分支</li><li>git clone</li><li>git branch -avv</li><li>fit checkout -b dev origin/…</li><li>git push origin &lt;本地分支名&gt;:&lt;远程分支名&gt;</li></ol><p>others:</p><ol><li><p>与远程代码同步</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git pull origin &lt;分支名&gt;</span><br></pre></td></tr></table></figure></li><li><p>更新远程路径列表</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote update origin --prune xxx</span><br></pre></td></tr></table></figure></li></ol><ol start="3"><li><p>添加远程路径</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote add origin xxx</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      总结git的一些常用指令和底层运转
    
    </summary>
    
      <category term="git" scheme="http://yoursite.com/categories/git/"/>
    
    
      <category term="git" scheme="http://yoursite.com/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch</title>
    <link href="http://yoursite.com/2019/10/18/ElasticSearch/"/>
    <id>http://yoursite.com/2019/10/18/ElasticSearch/</id>
    <published>2019-10-18T12:48:29.000Z</published>
    <updated>2019-10-20T03:21:35.634Z</updated>
    
    <content type="html"><![CDATA[<h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>”一个便于检索的数据库“</p><p>基于 Lucene 的开源搜索引擎，分布式、可扩展、每个字段都能被索引。</p><h2 id="能做什么？"><a href="#能做什么？" class="headerlink" title="能做什么？"></a>能做什么？</h2><ul><li>海量搜索</li><li>NoSQL 数据库</li><li>对海量数据进行进实时的处理</li><li>日志数据分析，ELK 技术，ES 进行复杂的数据分析</li></ul><h2 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h2><p>设计目标：为了更好的写入（索引）和查询（搜索）</p><p><img style="height:400px" src="http://qnya.pomo16.club/265.png"></p><p>自底向上：</p><ol><li>网关，es 索引的持久化存储方式</li><li>Lucene，为 es 提供 api 工具包</li><li>索引模块，搜索模块，字段映射，river 数据同步</li><li>自动发现，es 的自动发现节点机制</li><li>通信层，es 和客户端的交互方式</li><li>Restful api，封装的一些 crud 操作</li></ol><h5 id="Restful-api"><a href="#Restful-api" class="headerlink" title="Restful api"></a>Restful api</h5><p>对于向 es 插入数据、检索数据、删除数据等操作，es 提供了 Java api 和 RESTful api 两种方式来与之通信。</p><h5 id="transport"><a href="#transport" class="headerlink" title="transport"></a>transport</h5><p>通信模块，节点间数据传输都依赖于该模块，它有两种实现，一种是基于 netty 实现的 nettytransport，主要用于节点间的通信。另一种是 localtransport，主要是用于同一个 jvm 上的节点通信。</p><h5 id="discovery-script"><a href="#discovery-script" class="headerlink" title="discovery script"></a>discovery script</h5><p>自动发现模块，集群中节点的自动发现和 Master 节点的选举。p2p 通信。</p><p>Master 节点维护集群的全局状态（比如节点加入和离开时进行 shard 的重新分配）</p><p>Master 节点选取，bully 算法+延迟选举+半数选票</p><p>故障检测：主节点-&gt;其他节点，其他节点-&gt;主节点</p><h5 id="重要模块"><a href="#重要模块" class="headerlink" title="重要模块"></a>重要模块</h5><p>Index 模块：对写入数据的管理和组织</p><p>Search 模块：用来提供信息搜索</p><p>Mapping映射模块：类似于数据库表字段的定义，并且它决定了各个字段能否被搜索，以及搜索方式</p><p>River 模块：es 的一个数据源，向 es 同步数据。river data -&gt; es</p><h5 id="Lucene"><a href="#Lucene" class="headerlink" title="Lucene"></a>Lucene</h5><p>一个全文检索引擎框架，java 类库，提供底层 api，每个 es 节点上都有一个 Lucene 引擎支持。</p><h5 id="gateway"><a href="#gateway" class="headerlink" title="gateway"></a>gateway</h5><p>存储索引的文件系统，支持多种文件类型</p><h2 id="核心原理"><a href="#核心原理" class="headerlink" title="核心原理"></a>核心原理</h2><h4 id="几个重要概念"><a href="#几个重要概念" class="headerlink" title="几个重要概念"></a>几个重要概念</h4><table><thead><tr><th>index</th><th>type</th><th>document</th><th>mapping</th><th>node</th><th>shard</th><th>segment</th><th>serach</th></tr></thead><tbody><tr><td>索引</td><td>类型</td><td>文档</td><td>映射</td><td>节点</td><td>分片</td><td>段</td><td>倒排索引</td></tr></tbody></table><h4 id="从数据库角度来看"><a href="#从数据库角度来看" class="headerlink" title="从数据库角度来看"></a>从数据库角度来看</h4><table><thead><tr><th>Relational database</th><th>Elasticsearch</th></tr></thead><tbody><tr><td>Database</td><td>Index</td></tr><tr><td>Table</td><td>Type</td></tr><tr><td>Row</td><td>Document</td></tr><tr><td>Column</td><td>Field</td></tr><tr><td>Schema</td><td>Mapping</td></tr><tr><td>Index</td><td>Everything can index</td></tr><tr><td>SQL</td><td>Query DSL</td></tr><tr><td>SELECT * FROM table …</td><td>GET http://…</td></tr><tr><td>UPDATE table SET …</td><td>PUT http://…</td></tr></tbody></table><h4 id="索引-index"><a href="#索引-index" class="headerlink" title="索引 index"></a>索引 index</h4><p>es 将数据存储于一个或多个索引中，索引是具有类似特性的<strong>文档的集合</strong>。类比传统的关系型数据库领域来说，索引相当于 SQL 中的一个<strong>数据库</strong>。</p><h4 id="类型-type"><a href="#类型-type" class="headerlink" title="类型 type"></a>类型 type</h4><p>类型是索引内部的逻辑分类或分区（category/partition），一个索引内部可定义一个或多个类型（type）。通常，会为具有一组共同字段的文档定义一个类型。</p><h4 id="文档-document"><a href="#文档-document" class="headerlink" title="文档 document"></a>文档 document</h4><p>文档是可被索引的基础信息单元，它是包含了一个或多个域的容器，基于 JSON 格式进行表示。</p><p><img style="height:200px" src="http://qnya.pomo16.club/266.png"></p><h4 id="映射-mapping"><a href="#映射-mapping" class="headerlink" title="映射 mapping"></a>映射 mapping</h4><p>用来定义一个文档以及其所包含的字段如何被存储和索引，可以在映射中事先定义字段的数据类型、分词器等属性。映射可以分为静态映射和动态映射。</p><p>静态映射：事先定义字段的数据类型、分词器等属性。</p><p>动态映射：根据写入的字段进行类型推测。</p><h4 id="节点-node"><a href="#节点-node" class="headerlink" title="节点 node"></a>节点 node</h4><p>运行了单个实例的 es 主机称为节点（一个 es 实例就是一个 node），可以存储数据、参与集群索引及搜索操作。</p><h4 id="分片-shard"><a href="#分片-shard" class="headerlink" title="分片 shard"></a>分片 shard</h4><p>es 提供了将<strong>索引划分</strong>成多少份的能力，这些份就叫做分片。相当于一桶水用了 N 个杯子装。每个分片其内部都是一个全功能且<strong>独立的索引</strong>（Lucene Index）。创建索引时，用户可指定其分片的数量，默认数量为5个，一个分片只能存放 2,147,483,519 个 docs。</p><p>主分片和备分片：主分片和备分片不会出现在同一个节点上（防止单点故障）</p><p>分片和节点的配合，让 es 的分布式愿望得以实现。</p><h5 id="node-shard-实现-es-的扩容"><a href="#node-shard-实现-es-的扩容" class="headerlink" title="node + shard 实现 es 的扩容"></a>node + shard 实现 es 的扩容</h5><p><img style="height:200px" src="http://qnya.pomo16.club/267.png"></p><p>Node 1 和 Node 2 上各有一个分片被迁移到了新的 Node 3 节点</p><p>整体负载降低。性能提升</p><p>我们这个拥有6个分片（3个主分片和3个副本分片）的索引可以最大扩容到6个节点，每个节点上存在一个分片，并且每个分片拥有所在节点的全部资源。</p><p><strong>那如何实现更多的扩容？如果我们想要扩容超多6个节点怎么办呢？</strong></p><p>主分片的数量是确定的，增加备分片的数量，实现更高的吞吐量。</p><h4 id="段-segment"><a href="#段-segment" class="headerlink" title="段 segment"></a>段 segment</h4><p>Elasticsearch 中的<strong>每个分片包含多个 segment</strong>，每一个 segment 都是一个<strong>倒排索引</strong>；在查询时，会把所有的 segment 查询结果汇总归并后作为最终的分片查询结果，然后返回。</p><h4 id="倒排索引"><a href="#倒排索引" class="headerlink" title="倒排索引"></a>倒排索引</h4><p>也常被称为反向索引，是一种索引方法，它是文档检索系统中最常用的数据结构。</p><p><img src="http://qnya.pomo16.club/268.png" alt="image-20190916162714323"></p><h2 id="索引原理"><a href="#索引原理" class="headerlink" title="索引原理"></a>索引原理</h2><p>es 索引本质：让数据安全快速写入，并且能快速搜索到。</p><p>es 的索引过程：对文档的增删改查，以及文档对应的倒排索引的更新。</p><h4 id="对原文档的操作（写、读、更新）"><a href="#对原文档的操作（写、读、更新）" class="headerlink" title="对原文档的操作（写、读、更新）"></a>对原文档的操作（写、读、更新）</h4><h5 id="写操作"><a href="#写操作" class="headerlink" title="写操作"></a>写操作</h5><p>写操作必须在 primary shard （主分片）完全成功后才能拷贝至其对应的 replicas （附属分片）上，默认情况下主分片等待所有备份完成索引后才返回客户端。</p><p><img style="height:300px" src="http://qnya.pomo16.club/269.png"></p><ol><li>客户端向 Node 1 发送索引文档请求。</li><li>Node 1 根据文档 ID (_id 字段) 计算(对 id 做哈希然后取模)出该文档应该属于 shard0，然后请求路由到 Node 3 的 P0 分片上。</li><li>Node 3 在 P0 上执行了请求。如果请求成功，则将请求并行的路由至 Node 1，Node 2 的 R0 上。当所有的 Replicas 报告成功后，Node 3 向请求的 Node (Node 1) 发送成功报告，Node 1 再报告至 Client。</li><li>当客户端收到执行成功后，操作已经在 Primary shard 和所有的 replicas shards 上执行成功了。</li></ol><h5 id="读操作"><a href="#读操作" class="headerlink" title="读操作"></a>读操作</h5><p>一个文档可以在 primary shard 和所有的 replica shards 上读取</p><p><img style="height:300px" src="http://qnya.pomo16.club/270.png"></p><ol><li>客户端发送 Get 请求到 Node 1。</li><li>Node 1 根据文档 ID (_id 字段) 计算出该文档应该属于 shard0，且 shard0 的所有拷贝存在于所有3个节点上。这次，他将路由至 Node 2。</li><li>Node 2 将文档返回给 Node 1，Node 1 将文档返回给客户端。对于读请求，请求节点 (Node 1) 将在每次请求到来时选择一个不同的 replica shard 来达到负载均衡。使用轮询策略轮询所有的 replica shards。</li></ol><h5 id="更新操作"><a href="#更新操作" class="headerlink" title="更新操作"></a>更新操作</h5><p>结合了以上的两个操作：读、写</p><p><img style="height:300px" src="http://qnya.pomo16.club/271.png"></p><ol><li>客户端发送更新操作请求至 Node 1。</li><li>Node 1 将请求路由至 Node 3，Primary shard 所在的位置。</li><li>Node 3 从 P0 读取文档，改变 source 字段的 JSON 内容，然后试图重新对修改后的数据在 P0 做索引。如果此时这个文档已经被其他的进程修改了，那么它将重新执行 3 步骤，这个过程如果超过了 retryon_conflict 设置的次数，就放弃。</li><li>如果 Node 3 成功更新了文档，它将并行地把新版本的文档同步到 Node 1 和 Node 2 的 replica shards 重新建立索引。一旦所有的 replica shards 报告成功，Node 3 向被请求的节点(Node 1)返回成功，然后 Node 1 向客户端返回成功。</li></ol><h4 id="生成倒排索引"><a href="#生成倒排索引" class="headerlink" title="生成倒排索引"></a>生成倒排索引</h4><p>如果仅仅只是生成文档，那么 es 的搜索性能会很低，所以，在建立索引时，会产生一个对应的倒排索引（Inverted Index）。</p><p>es 引擎把文档数据写入到倒排索引的数据结构中，建立起分词 (Term) -&gt; 文档 (Document) 的映射关系。</p><p>这些倒排索引会存放在段 (segment) 中，段的写入会落盘，缓存 buffer 会实时更新。</p><p><img src="http://qnya.pomo16.club/272.png" alt="image-20190916170640677"></p><p>倒排索引包括两个部分：</p><ol><li>有序的数据字典 Dictionary（包括单词 Term 和它出现的频率）</li><li>单词 Term 对应的 Postings（即存在这个单词的文件）</li></ol><p><img style="height:300px" src="http://qnya.pomo16.club/273.png"></p><p>为了优化搜索，segment 不仅只提供了倒排，还提供了 document values field cache，解决：排序、聚合等问题。</p><p>列式存储：将索引中某一个字段值全部读取到内存中进行操作，用空间换时间。</p><p><img style="height:300px" src="http://qnya.pomo16.club/274.png"></p><h2 id="es-的搜索机制"><a href="#es-的搜索机制" class="headerlink" title="es 的搜索机制"></a>es 的搜索机制</h2><h4 id="搜索过程"><a href="#搜索过程" class="headerlink" title="搜索过程"></a>搜索过程</h4><p><img src="http://qnya.pomo16.club/275.png" alt="image-20190916171659797"></p><p>搜索过程由两个阶段组成：查询阶段，获取阶段</p><p>查询阶段(Query Phase)：在此阶段，<strong>协调节点</strong>将搜索<strong>请求</strong>路由到索引(index)中的<strong>所有分片</strong>(shards)（包括：主要或副本）。分片独立执行搜索，并根据<strong>相关性分数</strong>创建一个优先级排序结果。所有分片将匹配的文档和相关分数的文档 ID 返回协调节点。协调节点创建一个新的<strong>优先级队列</strong>，并对全局结果进行排序。可以有很多文档匹配结果，但默认情况下，每个分片将前10个结果发送到协调节点，协调创建优先级队列。</p><p>获取阶段(Fetch Phase)：在协调节点对所有结果进行排序，并通过文档 id，从分片中得到<strong>原始文档</strong>，再返回到协调节点。</p><p><img src="http://qnya.pomo16.club/276.png" alt="image-20190916172347548"></p><p>搜索相关性：</p><ol><li>文档指定字段，与 query 相关性越强，文档的得分越高</li><li>评分默认算法：tf / idf（术语频率/逆文档频率）</li></ol><p><img src="http://qnya.pomo16.club/277.png" alt="image-20190916172838769"></p>]]></content>
    
    <summary type="html">
    
      简单介绍ElasticSearch
    
    </summary>
    
      <category term="ElasticSearch" scheme="http://yoursite.com/categories/ElasticSearch/"/>
    
    
      <category term="ElasticSearch" scheme="http://yoursite.com/tags/ElasticSearch/"/>
    
  </entry>
  
  <entry>
    <title>HTTP和RPC</title>
    <link href="http://yoursite.com/2019/09/19/HTTP%E5%92%8CRPC/"/>
    <id>http://yoursite.com/2019/09/19/HTTP和RPC/</id>
    <published>2019-09-18T16:41:38.000Z</published>
    <updated>2019-09-18T16:44:02.682Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Why-RPC？"><a href="#Why-RPC？" class="headerlink" title="Why RPC？"></a>Why RPC？</h2><p>在 HTTP 和 RPC 的选择上，可能有些人是迷惑的，主要是因为有些 RPC 框架配置复杂，如果走 HTTP 也能完成同样的功能，那么为什么要选择 RPC？</p><p>RPC，即 Remote Procedure Call，远程过程调用，主要是基于 TCP/IP 协议。而 HTTP 服务主要是基于 HTTP 协议的。我们都知道 HTTP 协议是在传输层协议 TCP 之上的，所以就效率来看的话，RPC 当然是要更胜一筹。另外， HTTP 的最大优势在于双端异构下的无障碍传输，但由于公司内部服务基本不存在异构的情况，所以这个优点微乎其微。所以，RPC 主要用于公司内部的服务调用，性能消耗低，传输效率高，服务治理方便。HTTP 主要用于对外的异构环境，浏览器接口调用，APP 接口调用，第三方接口调用等。</p><h2 id="与-HTTP-的异同"><a href="#与-HTTP-的异同" class="headerlink" title="与 HTTP 的异同"></a>与 HTTP 的异同</h2><h4 id="传输协议"><a href="#传输协议" class="headerlink" title="传输协议"></a>传输协议</h4><p>RPC：可基于 TCP 也可基于 HTTP</p><p>HTTP：HTTP协议</p><h4 id="传输效率"><a href="#传输效率" class="headerlink" title="传输效率"></a>传输效率</h4><p>RPC：使用自定义的 TCP 协议，可以让请求报文体积更小，或者使用 HTTP2 协议，也可以很好的减少报文的体积，提高传输效率</p><p>HTTP：如果是基于 HTTP1.1 的协议，请求中会包含很多无用的内容，如果是基于 HTTP2.0，那么简单的封装以下是可以作为一个 RPC 来使用的</p><h4 id="性能消耗（主要在于序列化和反序列化的耗时）"><a href="#性能消耗（主要在于序列化和反序列化的耗时）" class="headerlink" title="性能消耗（主要在于序列化和反序列化的耗时）"></a>性能消耗（主要在于序列化和反序列化的耗时）</h4><p>RPC：可以基于 thrift 实现高效的二进制传输</p><p>HTTP：超文本传输协议，大部分是通过 json 来实现的，字节大小和序列化耗时都比 thrift 要更消耗性能</p><h4 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h4><p>RPC：基本都自带了负载均衡策略</p><p>HTTP：需要配置 Nginx，HAProxy 来实现</p><h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p>rpc 框架一般还包含以下 HTTP 没有的高级功能：</p><ul><li>服务治理（下游服务新增，重启，下线时如何不影响上游调用者）</li><li>服务熔断/降级</li><li>流量监控等等</li></ul><h2 id="RPC-框架-——基于-Thrift-服务的-Kite"><a href="#RPC-框架-——基于-Thrift-服务的-Kite" class="headerlink" title="RPC 框架 ——基于 Thrift 服务的 Kite"></a>RPC 框架 ——基于 Thrift 服务的 Kite</h2><p>一个 rpc 调用，一般分为以下几步</p><ol><li>发送方将请求序列化</li><li>发送方通过网络发送</li><li>接收方通过网络接受</li><li>接收方反序列化得到请求</li></ol><p>当然在实际使用中还有很多额外的工作要做，服务端要监听端口，客户端要进行链接，服务端还要选择如何处理请求，多线程，线程通信等等一系列工作，需要处理有很多。</p><h4 id="Thrift"><a href="#Thrift" class="headerlink" title="Thrift"></a>Thrift</h4><p>Thrift 通过分层的方法，把整个过程分为四层，每一层解决一个问题，上下层之间提供服务。</p><ol><li>server：完成端口的监听，当有链接到来时为其创建 transport，protocol，并调用相应的 processor 处理</li><li>processor：对外提供一个统一的 process(in, out protocol) 接口</li><li>protocol：完成序列化</li><li>transport: 完成具体的传输功能（通过网络发送，写入磁盘等）</li></ol><p>一个大概的处理过程例子如下：（我觉得图里的序列化和反序列化写反了）</p><p><img src="http://qnya.pomo16.club/264.png" alt="image-20190903153604699"></p><p>因为 thrift 采用了分层，使得各层之间可以互相独立，所以如图中标注，虚线以下的代码是静态生成的，这部分代码，主要是通过传入的 TProtocol 完成反序列化，然后将得到的请求传递给用户注册进的 Handler 去处理，处理完以后，再通过 TProtocol 序列化应答发送回去。下面这部分，就是工具通过 idl 生成的，一般称为 stub。stub 通过传入的 TProtocol 完成读取数据，反序列化，调用 handler 处理，序列化应答，发送功能。</p><p>虚线以上，完成了链接的建立，在用链接创建 TTrannport，用 TTransport 创建 TProtocol。这部分决定了链接如何建立，序列化格式是什么。最后将封装了序列化/反序列化操作的 TProtocol 传递给 stub。</p><p>Thrift 这种分层的设计很好的将具体的序列化/反序列化操作与普通的服务端链接建立，数据读取，协议格式等进行了解藕，服务端可以专心在虚线以上部分的建设，其余的交给 stub。</p><h4 id="Kite"><a href="#Kite" class="headerlink" title="Kite"></a>Kite</h4><p>kite 框架，其实完成的就是上一节说的那幅图中的虚线以上部分。对照图，可以分为三部分：</p><ul><li><p>为新链接建立 TProtocol 对象</p></li><li><p>把用户的 Handler 注册到 TProcessor 中</p></li><li>把 TProcessor 注册到 kite 框架中</li></ul><h5 id="构造-TProtocol-对象"><a href="#构造-TProtocol-对象" class="headerlink" title="构造 TProtocol 对象"></a>构造 TProtocol 对象</h5><ol><li>kite 直接使用了 golang 标准库 net。net.Listen 监听，然后直接开启一个 for loop 开始 Accept。</li><li>Accept 完成链接建立以后得到 net.Conn 对象。</li><li>开启协程处理接下来的步骤。</li><li><p>用 net.Conn 构造 TTransport 对象，再构造 TProtocol 对象。</p><p>这几步和上图中描述的是差不多的。接下来是把 Handler 注册到 stub 中，并且把 stub 注册到 kite 框架中。stub 代码是工具已经生成的，对外提供了注册接口。Handler 代码是 kitool 工具生成的，注册操作也是 kitool 生成的代码中完成的。</p></li></ol><p>kitool 工具的角色其实有两个功能：</p><ul><li>为 thrift 生成的 stub 代码，生成 Handler</li><li>将 stub 注册到 kite 框架</li></ul><h5 id="Handler-注册"><a href="#Handler-注册" class="headerlink" title="Handler 注册"></a>Handler 注册</h5><p>kitool 默认生成了一个 Handler，然后调用了 stub 的注册完成注册，这一部分比较简单</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hello.NewHelloServiceProcessor(&amp;HelloServiceHandler&#123;&#125;)</span><br></pre></td></tr></table></figure><h5 id="stub-注册"><a href="#stub-注册" class="headerlink" title="stub 注册"></a>stub 注册</h5><p>stub 是通过工具从 idl 中生成的，独立于 kite 框架。框架中提供了接口将外部的 stub 注册进来。在 kite 框架中有一个 export 的全局变量 Processor thrift.TProcessor，给这个变量赋值就完成了 stub 的注册。</p><p>实际上这个操作是由 kitool 生成的代码完成的。通过 kitool 生成的项目在项目根目录下有一个 kite.go 文件，这个文件里就完成了 stub 的注册：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line">kite.Processor = Hello.NewHelloServiceProcessor(&amp;HelloServiceHandler&#123;&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后，把 TProtocol 交给 Processor 处理即可。</p><h4 id="Middleware"><a href="#Middleware" class="headerlink" title="Middleware"></a>Middleware</h4><p>可以发现，到目前位置，kite 框架看起来是比较“简单”的，但是似乎有很多 routine work 多没有提到，比如限流，日志记录，监控上报等等。这就要提到 middleware（中间件）了。kite 通过使用中间件将框架主体与这些 routine work 进行了解藕。kite框架主体，只关注底层请求的接入，routine work 全都集中在了 middleware 当中。这一部分是在 kitool 生成的 Handler 中完成的。</p><p>这里先引入两个类型：</p><ul><li>EndPoint</li><li>Middleware</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// EndPoint represent one method for calling from remote.</span></span><br><span class="line"><span class="keyword">type</span> EndPoint <span class="function"><span class="keyword">func</span><span class="params">(ctx context.Context, req <span class="keyword">interface</span>&#123;&#125;)</span> <span class="params">(resp <span class="keyword">interface</span>&#123;&#125;, err error)</span></span></span><br><span class="line"><span class="function">// <span class="title">Middleware</span> <span class="title">deal</span> <span class="title">with</span> <span class="title">input</span> <span class="title">EndPoint</span> <span class="title">and</span> <span class="title">output</span> <span class="title">EndPoint</span></span></span><br><span class="line"><span class="function"><span class="title">type</span> <span class="title">Middleware</span> <span class="title">func</span><span class="params">(EndPoint)</span> <span class="title">EndPoint</span></span></span><br></pre></td></tr></table></figure><p>可以发现，EndPoint 是一个函数类型，middleware 实际上是一个高级函数，入参是 EndPoint，返回值也是 EndPoint。有这两个类型就可以写出类似这样的代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">MyMW</span><span class="params">(next EndPoint)</span> <span class="title">EndPoint</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">(ctx contex.Context, req <span class="keyword">interface</span>&#123;&#125;)</span> <span class="params">(resp <span class="keyword">interface</span>&#123;&#125;, err error)</span></span> &#123;</span><br><span class="line">        <span class="comment">//do something before next</span></span><br><span class="line">        rsp, err := next(ctx, req)</span><br><span class="line">        <span class="comment">//do something after next</span></span><br><span class="line">        <span class="keyword">return</span> rsp, err</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的 MyMW 返回了一个新的 EndPoint，实际上是一个闭包，wrap 了 next。当执行下面的代码时，实际上执行的是 MyMW 返回的新 EndPoint，这个 EndPoint 可以在执行 next 之前/之后，执行一些 pre/after 操作。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">newNext := MyMW(next)</span><br></pre></td></tr></table></figure><p>并且，由于 middleware 的入参和返回值都是同一个类型，因此 middleware 还可以串联起来：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">n1 := MyMW1(next)</span><br><span class="line">n2 := MyMW2(n1)</span><br><span class="line">n3 := MyM3(n2)</span><br></pre></td></tr></table></figure><p>可以发现，使用中间件我们可以在原始的函数之外包上很多层的逻辑。回到框架，kite 就是使用这样的方法在最原始的业务处理函数之外包裹整个过程不需要侵入框架或则侵入业务处理函数中做任何的修改，以一种方便，可扩展，可维护的方式拓展了框架的功能。</p>]]></content>
    
    <summary type="html">
    
      本文结合 http 协议，来介绍一下红遍微服务的 rpc 是什么
    
    </summary>
    
      <category term="web" scheme="http://yoursite.com/categories/web/"/>
    
    
      <category term="http" scheme="http://yoursite.com/tags/http/"/>
    
      <category term="rpc" scheme="http://yoursite.com/tags/rpc/"/>
    
  </entry>
  
  <entry>
    <title>Spring Cloud</title>
    <link href="http://yoursite.com/2019/06/27/Spring-Cloud/"/>
    <id>http://yoursite.com/2019/06/27/Spring-Cloud/</id>
    <published>2019-06-27T08:38:23.000Z</published>
    <updated>2019-06-27T08:49:35.473Z</updated>
    
    <content type="html"><![CDATA[<p><a href="#一、Spring-Cloud-是什么">一、Spring Cloud 是什么</a></p><p><a href="#二、Eureka-服务注册与发现">二、Eureka 服务注册与发现</a></p><p><a href="#三、Feign-服务消费者">三、Feign 服务消费者</a></p><p><a href="#四、Ribbon-负载均衡">四、Ribbon 负载均衡</a></p><p><a href="#五、Hystrix-断路器">五、Hystrix 断路器</a></p><p><a href="#六、Zuul-路由网关">六、Zuul 路由网关</a></p><p><a href="#七、组件功能总结">七、组件功能总结</a></p><p><a href="#八、Spring-Cloud-Config-分布式配置中心">八、Spring Cloud Config 分布式配置中心</a></p><h2 id="一、Spring-Cloud-是什么"><a href="#一、Spring-Cloud-是什么" class="headerlink" title="一、Spring Cloud 是什么"></a>一、Spring Cloud 是什么</h2><p>Spring Cloud 是基于 Spring Boot 提供了一套微服务解决方案，包括服务注册与发现，配置中心，全链路监控，服务网关，负载均衡，熔断器等组件，除了基于 NetFlix 的开源组件做高度抽象封装之外，还有一些选型中立的开源组件。Spring Cloud = 分布式微服务架构下的一站式解决方案，是各个微服务架构落地技术的集合体，俗称微服务全家桶。</p><h4 id="微服务化"><a href="#微服务化" class="headerlink" title="微服务化"></a>微服务化</h4><p>微服务化的核心就是将传统的一站式应用，根据业务拆分成一个一个的服务，彻底地去耦合,每一个微服务提供单个业务功能的服务，一个服务做一件事，从技术角度看就是一种小而独立的处理过程，类似进程概念，能够自行单独启动或销毁，拥有自己独立的数据库。</p><h4 id="Spring-Boot-和-Spring-Cloud-的关系"><a href="#Spring-Boot-和-Spring-Cloud-的关系" class="headerlink" title="Spring Boot 和 Spring Cloud 的关系"></a>Spring Boot 和 Spring Cloud 的关系</h4><ul><li>Spring Boot 专注于快速方便的开发单个个体微服务。</li><li>Spring Cloud 是关注全局的微服务协调整理治理框架，它将 Spring Boot 开发的一个个单体微服务整合并管理起来，为各个微服务之间提供，配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等等集成服务。</li><li>Spring Boot 可以离开 Spring Cloud 独立使用开发项目，但是 Spring Cloud 离不开 Spring Boot，属于依赖的关系。</li></ul><h2 id="二、Eureka-服务注册与发现"><a href="#二、Eureka-服务注册与发现" class="headerlink" title="二、Eureka 服务注册与发现"></a>二、Eureka 服务注册与发现</h2><h3 id="Eureka-是什么"><a href="#Eureka-是什么" class="headerlink" title="Eureka 是什么"></a>Eureka 是什么</h3><p>Eureka 是 Netflix 的一个子模块，也是核心模块之一。Eureka 是一个基于 REST 的服务，用于定位服务，以实现云端中间层服务发现和故障转移。</p><p>服务注册与发现对于微服务架构来说是非常重要的，有了服务发现与注册，只需要使用服务的标识符，就可以访问到服务，而不需要修改服务调用的配置文件了。功能类似于 dubbo 的注册中心，比如 Zookeeper。</p><h5 id="抽象理解"><a href="#抽象理解" class="headerlink" title="抽象理解"></a>抽象理解</h5><p>Eureka 相当于一个商业中心，所有的微服务相当于入驻的商户，需要在 Eureka 注册。此外，商户之间通信是基于 REST  的，这就需要服务发现暴露接口（即对于注册进 Eureka 里面的微服务，可以通过服务发现来获取该服务的信息）。</p><h3 id="Eureka-实现原理"><a href="#Eureka-实现原理" class="headerlink" title="Eureka 实现原理"></a>Eureka 实现原理</h3><h5 id="基础架构"><a href="#基础架构" class="headerlink" title="基础架构"></a>基础架构</h5><p>Eureka 采用了 C-S 的设计架构。Eureka Server 作为服务注册功能的服务器，它是服务注册中心。而系统中的其他微服务使用 Eureka 的客户端连接到 Eureka Server 并维持心跳连接。这样系统的维护人员就可以通过 Eureka Server 来监控系统中各个微服务是否正常运行。Spring Cloud 的一些其他模块（比如Zuul）就可以通过 Eureka Server 来发现系统中的其他微服务，并执行相关的逻辑。</p><ul><li><p>Eureka Server</p><p>提供服务注册服务，各个节点启动后，会在 Eureka Server 中进行注册，这样 Eureka Server 中的服务注册表中将会存储所有可用服务节点的信息，服务节点的信息可以在界面中直观的看到。</p></li><li><p>Eureka Client</p><p>是一个 Java 客户端，用于简化 Eureka Server 的交互，客户端同时也具备一个内置的、使用轮询 (round-robin) 负载算法的负载均衡器。在应用启动后，将会向 Eureka Server 发送心跳(默认周期为30秒)。如果 Eureka Server 在多个心跳周期内没有接收到某个节点的心跳，Eureka Server 将会从服务注册表中把这个服务节点移除（默认90秒）。</p></li></ul><h5 id="三大角色"><a href="#三大角色" class="headerlink" title="三大角色"></a>三大角色</h5><p><img src="http://qnya.pomo16.club/255.png" style="height:300px;"></p><ul><li><p>Eureka Server 提供服务注册和发现。</p></li><li><p>Service Provider 服务提供方将自身服务注册到 Eureka，从而使服务消费方能够找到。</p></li><li><p>Service Consumer 服务消费方从 Eureka 获取注册服务列表，从而能够消费服务。</p></li></ul><h3 id="Eureka-自我保护"><a href="#Eureka-自我保护" class="headerlink" title="Eureka 自我保护"></a>Eureka 自我保护</h3><p>某时刻某一个微服务不可用了，Eureka 不会立刻清理，依旧会对该微服务的信息进行保存。</p><p>默认情况下，如果 Eureka Server 在一定时间内没有接收到某个微服务实例的心跳，Eureka Server 将会注销该实例（默认90秒）。但是当网络分区故障发生时，微服务与 Eureka Server 之间无法正常通信，以上行为可能变得非常危险了——因为微服务本身其实是健康的，此时本不应该注销这个微服务。Eureka 通过“自我保护模式”来解决这个问题：</p><p>当 Eureka Server 节点在短时间内丢失过多客户端时（可能发生了网络分区故障），那么这个节点就会进入自我保护模式。在自我保护模式中，Eureka Server 会保护服务注册表中的信息，不再注销任何服务实例。当它收到的心跳数重新恢复到阈值以上时，该 Eureka Server 节点就会自动退出自我保护模式。</p><p>综上，自我保护模式是一种应对网络异常的安全保护措施。它的架构哲学是宁可同时保留所有微服务（健康的微服务和不健康的微服务都会保留），也不盲目注销任何健康的微服务。使用自我保护模式，可以让 Eureka 集群更加的健壮、稳定。在 Spring Cloud 中，可以使用 <code>eureka.server.enable-self-preservation = false</code> 禁用自我保护模式。</p><h2 id="三、Feign-服务消费者"><a href="#三、Feign-服务消费者" class="headerlink" title="三、Feign 服务消费者"></a>三、Feign 服务消费者</h2><h3 id="Feign-是什么"><a href="#Feign-是什么" class="headerlink" title="Feign 是什么"></a>Feign 是什么</h3><p>Feign 是一个声明式 WebService 客户端。使用 Feign 能让编写 Web Service 客户端更加简单, 它的使用方法是<strong>定义一个接口，然后在上面添加注解</strong>，同时也支持 JAX-RS 标准的注解。Feign 也支持可拔插式的编码器和解码器。Spring Cloud 对 Feign 进行了封装，使其支持了 Spring MVC 标准注解和 HttpMessageConverters。Feign 可以与 Eureka 和 Ribbon 组合使用以支持负载均衡。</p><p>Feign 旨在使编写 Java Http 客户端变得更容易。如果只使用 Ribbon + RestTemplate，利用 RestTemplate 对 http 请求的封装处理，形成了一套模版化的调用方法。但是在实际开发中，由于对服务依赖的调用可能不止一处，往往一个接口会被多处调用，所以通常都会针对每个微服务自行封装一些客户端类来包装这些依赖服务的调用。所以，Feign 在此基础上做了进一步封装，由他来帮助我们定义和实现依赖服务接口的定义。在 Feign 的实现下，我们只需创建一个接口并使用注解的方式来配置它(以前是 Dao 接口上面标注 Mapper 注解,现在是一个微服务接口上面标注一个 Feign 注解即可)，即可完成对服务提供方的接口绑定，简化了使用 Spring Cloud Ribbon 时，自动封装服务调用客户端的开发量。</p><p>Feign 集成了 Ribbon。利用 Ribbon 维护了服务列表信息，并且通过轮询实现了客户端的负载均衡。而与 Ribbon 不同的是，通过 Feign 只需要定义服务绑定接口且以声明式的方法，优雅而简单的实现了服务调用。</p><h3 id="Feign-架构说明"><a href="#Feign-架构说明" class="headerlink" title="Feign 架构说明"></a>Feign 架构说明</h3><p>Feign 是如何做到这么神奇的呢？很简单，<strong>Feign 的一个关键机制就是使用了动态代理</strong>。</p><ul><li><p>首先，如果你对某个接口定义了 @FeignClient 注解，Feign 就会针对这个接口创建一个动态代理。</p></li><li><p>接着你要是调用那个接口，本质就是会调用 Feign 创建的动态代理，这是核心中的核心。</p></li><li><p>Feign 的动态代理会根据你在接口上的 @RequestMapping 等注解，来动态构造出你要请求的服务的地址。</p></li><li><p>最后针对这个地址，发起请求、解析响应。</p></li></ul><p><img src="http://qnya.pomo16.club/256.png" alt></p><h2 id="四、Ribbon-负载均衡"><a href="#四、Ribbon-负载均衡" class="headerlink" title="四、Ribbon 负载均衡"></a>四、Ribbon 负载均衡</h2><h3 id="Ribbon-是什么"><a href="#Ribbon-是什么" class="headerlink" title="Ribbon 是什么"></a>Ribbon 是什么</h3><p>Spring Cloud Ribbon 是基于 Netflix Ribbon 实现的一套<strong>客户端负载均衡</strong>的工具。</p><p>简单的说，Ribbon 是 Netflix 发布的开源项目，主要功能是提供客户端的软件负载均衡算法，将 Netflix 的中间层服务连接在一起。Ribbon 客户端组件提供一系列完善的配置项如连接超时，重试等。简单的说，就是在配置文件中列出 Load Balancer（简称LB）后面所有的机器，Ribbon 会自动的帮助你基于某种规则（如简单轮询，随机连接等）去连接这些机器。我们也很容易使用 Ribbon 实现自定义的负载均衡算法。</p><blockquote><p>LB，即负载均衡 (Load Balance)，在微服务或分布式集群中经常用的一种应用。负载均衡简单的说就是将用户的请求平摊的分配到多个服务上，从而达到系统的 HA。常见的负载均衡有软件 Nginx，LVS，硬件 F5 等。相应的在中间件，例如：dubbo 和 Spring Cloud 中均给我们提供了负载均衡，Spring Cloud 的负载均衡算法可以自定义。 </p><p>集中式 LB：即在服务的消费方和提供方之间使用独立的 LB 设施(可以是硬件，如 F5，也可以是软件，如 nginx)，由该设施负责把访问请求通过某种策略转发至服务的提供方。</p><p>进程内 LB：将 LB 逻辑集成到消费方，消费方从服务注册中心获知有哪些地址可用，然后自己再从这些地址中选择出一个合适的服务器。</p><p>Ribbon 就属于进程内 LB，它只是一个类库，集成于消费方进程，消费方通过它来获取到服务提供方的地址。</p></blockquote><h3 id="Ribbon-架构说明"><a href="#Ribbon-架构说明" class="headerlink" title="Ribbon 架构说明"></a>Ribbon 架构说明</h3><p><img src="http://qnya.pomo16.club/257.png" style="height:300px;"></p><p>Ribbon 在工作时分成两步：第一步先选择 Eureka Server ,它优先选择在同一个区域内负载较少的 server。第二步再根据用户指定的策略，在从 server 取到的服务注册列表中选择一个地址。其中 Ribbon 提供了多种策略：比如轮询、随机和根据响应时间加权。</p><p><img src="http://qnya.pomo16.club/258.png" alt></p><h2 id="五、Hystrix-断路器"><a href="#五、Hystrix-断路器" class="headerlink" title="五、Hystrix 断路器"></a>五、Hystrix 断路器</h2><h3 id="分布式面临问题：服务雪崩"><a href="#分布式面临问题：服务雪崩" class="headerlink" title="分布式面临问题：服务雪崩"></a>分布式面临问题：服务雪崩</h3><p>复杂分布式体系结构中的应用程序有数十个依赖关系，每个依赖关系在某些时候将不可避免地失败。</p><p>多个微服务之间调用的时候，假设微服务 A 调用微服务 B 和微服务 C，微服务 B 和微服务 C 又调用其它的微服务，这就是所谓的“扇出”。如果扇出的链路上某个微服务的调用响应时间过长或者不可用，对微服务 A 的调用就会占用越来越多的系统资源，进而引起系统崩溃，所谓的“雪崩效应”。</p><p>对于高流量的应用来说，单一的后端依赖可能会导致所有服务器上的所有资源都在几秒钟内饱和。比失败更糟糕的是，这些应用程序还可能导致服务之间的延迟增加，备份队列，线程和其他系统资源紧张，导致整个系统发生更多的级联故障。这些都表示需要对故障和延迟进行隔离和管理，以便单个依赖关系的失败，不能取消整个应用程序或系统。 </p><h3 id="Hystrix-是什么"><a href="#Hystrix-是什么" class="headerlink" title="Hystrix 是什么"></a>Hystrix 是什么</h3><p>Hystrix 是一个用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败，比如超时、异常等，Hystrix 能够保证在一个依赖出问题的情况下，不会导致整体服务失败，避免级联故障，以提高分布式系统的弹性。</p><p>“断路器”本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控（类似熔断保险丝），向调用方返回一个符合预期的、可处理的备选响应（FallBack），而不是长时间的等待或者抛出调用方无法处理的异常，这样就保证了服务调用方的线程不会被长时间、不必要地占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩。 </p><h3 id="Hystrix-功能"><a href="#Hystrix-功能" class="headerlink" title="Hystrix 功能"></a>Hystrix 功能</h3><h5 id="服务熔断"><a href="#服务熔断" class="headerlink" title="服务熔断"></a>服务熔断</h5><p>熔断机制是应对雪崩效应的一种微服务链路保护机制。当扇出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回”错误”的响应信息。当检测到该节点微服务调用响应正常后恢复调用链路。在 Spring Cloud 框架里熔断机制通过 Hystrix 实现。Hystrix 会监控微服务间调用的状况，当失败的调用到一定阈值，缺省是5秒内20次调用失败就会启动熔断机制。熔断机制的注解是 @HystrixCommand。一旦调用服务方法失败并抛出了错误信息后，会自动调用 @HystrixCommand 标注好的 fallbackMethod 调用类中的指定方法。</p><h5 id="服务降级"><a href="#服务降级" class="headerlink" title="服务降级"></a>服务降级</h5><p>整体资源快不够了，忍痛将某些服务先关掉，待渡过难关，再开启回来。服务降级处理是在客户端实现完成的，与服务端没有关系。</p><h5 id="服务实时监控"><a href="#服务实时监控" class="headerlink" title="服务实时监控"></a>服务实时监控</h5><p>除了隔离依赖服务的调用以外，Hystrix 还提供了准实时的调用监控（Hystrix Dashboard），Hystrix 会持续地记录所有通过 Hystrix 发起的请求的执行信息，并以统计报表和图形的形式展示给用户，包括每秒执行多少请求多少成功，多少失败等。Netflix 通过 hystrix-metrics-event-stream 项目实现了对以上指标的监控。Spring Cloud 也提供了 Hystrix Dashboard 的整合，对监控内容转化成可视化界面。</p><h3 id="Hystrix-实现原理"><a href="#Hystrix-实现原理" class="headerlink" title="Hystrix 实现原理"></a>Hystrix 实现原理</h3><p>如下图，Hystrix 会搞很多个小小的线程池，比如订单服务请求库存服务是一个线程池，请求仓储服务是一个线程池，请求积分服务是一个线程池。每个线程池里的线程就仅仅用于请求那个服务。</p><p><img src="http://qnya.pomo16.club/259.png" alt></p><h2 id="六、Zuul-路由网关"><a href="#六、Zuul-路由网关" class="headerlink" title="六、Zuul 路由网关"></a>六、Zuul 路由网关</h2><h3 id="Zuul-是什么"><a href="#Zuul-是什么" class="headerlink" title="Zuul 是什么"></a>Zuul 是什么</h3><p>Zuul 包含了对请求的<strong>路由和过滤</strong>两个最主要的功能：其中路由功能负责将外部请求转发到具体的微服务实例上，是实现外部访问统一入口的基础而过滤器功能则负责对请求的处理过程进行干预，是实现请求校验、服务聚合等功能的基础。</p><p>Zuul 和 Eureka 进行整合，将 Zuul 自身注册为 Eureka 服务治理下的应用，同时从 Eureka 中获得其他微服务的消息，也即以后的访问微服务都是通过 Zuul 跳转后获得。</p><p>注意：Zuul 服务最终还是会注册进 Eureka</p><p>Zuul = 代理 + 路由 + 过滤</p><p><img src="http://qnya.pomo16.club/260.png" alt></p><h2 id="七、组件功能总结"><a href="#七、组件功能总结" class="headerlink" title="七、组件功能总结"></a>七、组件功能总结</h2><p><strong>Eureka</strong>：各个服务启动时，Eureka Client 都会将服务注册到 Eureka Server，并且 Eureka Client 还可以反过来从 Eureka Server 拉取注册表，从而知道其他服务在哪里。</p><p><strong>Ribbon</strong>：服务间发起请求的时候，基于 Ribbon 做负载均衡，从一个服务的多台机器中选择一台。</p><p><strong>Feign</strong>：基于 Feign 的动态代理机制，根据注解和选择的机器，拼接请求 URL 地址，发起请求。</p><p><strong>Hystrix</strong>：发起请求是通过 Hystrix 的线程池来走的，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题。</p><p><strong>Zuul</strong>：如果前端、移动端要调用后端系统，统一从 Zuul 网关进入，由 Zuul 网关转发请求给对应的服务。</p><p><img src="http://qnya.pomo16.club/261.png" alt></p><h2 id="八、Spring-Cloud-Config-分布式配置中心"><a href="#八、Spring-Cloud-Config-分布式配置中心" class="headerlink" title="八、Spring Cloud Config 分布式配置中心"></a>八、Spring Cloud Config 分布式配置中心</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>微服务意味着要将单体应用中的业务拆分成一个个子服务，每个服务的粒度相对较小，因此系统中会出现大量的服务。由于每个服务都需要必要的配置信息才能运行，所以一套集中式的、动态的配置管理设施是必不可少的。</p><h3 id="Spring-Cloud-Config-是什么"><a href="#Spring-Cloud-Config-是什么" class="headerlink" title="Spring Cloud Config 是什么"></a>Spring Cloud Config 是什么</h3><p>Spring Cloud Config 为微服务架构中的微服务提供集中化的外部配置支持，配置服务器为各个不同微服务应用的所有环境提供了一个中心化的外部配置。作用如下：</p><ul><li>集中管理配置文件</li><li>不同环境不同配置，动态化的配置更新，分环境部署比如：dev/test/prod/beta/release</li><li>运行期间动态调整配置，不再需要每个服务部署的机器上编写配置文件，服务会向配置中心统一拉取配置自己的信息</li><li>当配置发生变动时，服务不需要重启即可感知到配置的变化并应用新的配置</li><li>将配置信息以 REST 接口的形式暴露</li></ul><h3 id="Spring-Cloud-Config-架构"><a href="#Spring-Cloud-Config-架构" class="headerlink" title="Spring Cloud Config 架构"></a>Spring Cloud Config 架构</h3><p>Spring Cloud Config 分为客户端和服务端两部分。</p><p>服务端也称为分布式配置中心，它是一个独立的微服务应用，用来连接配置服务器并为客户端提供获取配置信息，加密/解密信息等访问接口。</p><p>客户端则是通过指定的配置中心来管理应用资源，以及与业务相关的配置内容，并在启动的时候从配置中心获取和加载配置信息。</p><p>配置服务器默认使用 git 来存储配置信息，这样就有助于对环境配置进行版本管理，并且可以通过 git 客户端工具来方便地管理和访问配置内容。</p><p><img src="http://qnya.pomo16.club/262.png" alt></p>]]></content>
    
    <summary type="html">
    
      总结 Spring Cloud 的设计思想及各大组件。
    
    </summary>
    
      <category term="java" scheme="http://yoursite.com/categories/java/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="Spring" scheme="http://yoursite.com/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>Java线程池</title>
    <link href="http://yoursite.com/2019/06/23/Java%E7%BA%BF%E7%A8%8B%E6%B1%A0/"/>
    <id>http://yoursite.com/2019/06/23/Java线程池/</id>
    <published>2019-06-23T12:40:53.000Z</published>
    <updated>2019-06-23T12:47:30.604Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Executor-类图"><a href="#Executor-类图" class="headerlink" title="Executor 类图"></a>Executor 类图</h2><p><img src="http://qnya.pomo16.club/253.png" alt></p><h2 id="线程池原理"><a href="#线程池原理" class="headerlink" title="线程池原理"></a>线程池原理</h2><p>线程池中的核心线程数，当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于corePoolSize；如果当前线程数为 corePoolSize，继续提交的任务被保存到阻塞队列中，等待被执行；如果阻塞队列满了，那就创建新的线程执行当前任务；直到线程池中的线程数达到 maxPoolSize，这时再有任务来，只能执行 reject() 处理该任务。</p><p><img src="http://qnya.pomo16.club/254.png" alt></p><h2 id="线程池种类"><a href="#线程池种类" class="headerlink" title="线程池种类"></a>线程池种类</h2><ul><li><p>newFixedThreadPool()</p><p><strong>初始化一个指定线程数的线程池</strong>，其中 corePoolSize == maxiPoolSize，使用 LinkedBlockingQuene 作为阻塞队列 特点：即使当线程池没有可执行任务时，也不会释放线程。</p></li><li><p>newCachedThreadPool()</p><p><strong>初始化一个可以缓存线程的线程池</strong>，默认缓存 60s，线程池的线程数可达到 Integer.MAX_VALUE，即 2147483647，内部使用 SynchronousQueue 作为阻塞队列； 特点：在没有任务执行时，当线程的空闲时间超过 keepAliveTime，会自动释放线程资源；当提交新任务时，如果没有空闲线程，则创建新线程执行任务，会导致一定的系统开销； 因此，使用时要注意控制并发的任务数，防止因创建大量的线程导致而降低性能。</p></li><li><p>newSingleThreadExecutor()</p><p><strong>初始化只有一个线程的线程池</strong>，内部使用 LinkedBlockingQueue 作为阻塞队列。 特点：如果该线程异常结束，会重新创建一个新的线程继续执行任务，唯一的线程可以保证所提交任务的顺序执行。</p></li><li><p>newScheduledThreadPool()</p><p>特点：初始化的线程池可以在指定的时间内周期性的执行所提交的任务，在实际的业务场景中可以使用该线程池定期的同步数据。</p></li><li><p>ThreadPoolExecutor()</p><p>默认线程池，可控制参数比较多，实际上是前面四种的模板，自定义时只需传入自己想要的参数即可。</p></li></ul><p><strong>初始化示例</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 使用Executors静态方法进行初始化</span></span><br><span class="line">ExecutorService service = Executors.newSingleThreadExecutor();</span><br><span class="line"><span class="comment">// 常用方法</span></span><br><span class="line">service.execute(<span class="keyword">new</span> Thread());</span><br><span class="line">service.submit(<span class="keyword">new</span> Thread());</span><br><span class="line">service.shutDown();</span><br><span class="line">service.shutDownNow();</span><br></pre></td></tr></table></figure><p><strong>常用方法</strong></p><ol><li>execute 与 submit 的区别<ul><li>execute 只能提交 Runnable 类型的任务，而 submit 既能提交 Runnable 类型任务也能提交 Callable 类型任务。</li><li>execute 会直接抛出任务执行时的异常，submit 会吃掉异常，可通过 Future 的 get 方法将任务执行时的异常重新抛出。</li><li>submit 有返回值，而 execute 没有。</li></ul></li><li>shutDown 与 shutDownNow 的区别<ul><li>shutDown：当线程池调用该方法时,线程池的状态则立刻变成 SHUTDOWN 状态。此时，则不能再往线程池中添加任何任务，否则将会抛出 RejectedExecutionException异常。但是，此时线程池不会立刻退出，直到添加到线程池中的任务都已经处理完成，才会退出。 </li><li>shutDownNow：相当于调用每个线程的 interrupt() 方法。</li></ul></li><li>其他方法<ul><li>prestartAllCoreThreads()：提前创建并启动所有核心线程。</li><li>setCorePoolSize() 和 setMaximumPoolSize()：动态调整线程池容量大小。</li></ul></li></ol><h2 id="关键参数"><a href="#关键参数" class="headerlink" title="关键参数"></a>关键参数</h2><ul><li>corePoolSize：核心线程数</li><li>maximumPoolSize：最大线程数</li><li>keepAliveTime：线程存活时间（在 corePore &lt; * &lt; maxPoolSize 情况下有用）</li><li><p>workQueue：阻塞队列（用来保存等待被执行的任务）</p></li><li><p>handler：当拒绝处理任务时的策略</p></li></ul><h2 id="四大阻塞队列（workQueue）"><a href="#四大阻塞队列（workQueue）" class="headerlink" title="四大阻塞队列（workQueue）"></a>四大阻塞队列（workQueue）</h2><ul><li>ArrayBlockingQueue：基于数组结构的有界阻塞队列，按 FIFO 排序任务</li><li>LinkedBlockingQuene：基于链表结构的阻塞队列，按 FIFO 排序任务</li><li>SynchronousQuene：一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于 ArrayBlockingQuene</li><li>PriorityBlockingQuene：具有优先级的无界阻塞队列</li></ul><h2 id="四大拒绝策略（handler）"><a href="#四大拒绝策略（handler）" class="headerlink" title="四大拒绝策略（handler）"></a>四大拒绝策略（handler）</h2><ul><li>ThreadPoolExecutor.AbortPolicy：默认，队列满了丢弃任务并抛出 RejectedExecutionException 异常</li><li>ThreadPoolExecutor.DiscardPolicy：队列满了丢弃任务，但是不抛出异常</li><li>ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试加入队列（重复此过程）</li><li>ThreadPoolExecutor.CallerRunsPolicy：如果添加到线程池失败，那么主线程会自己去执行该任务</li></ul><h2 id="合理设置线程池大小"><a href="#合理设置线程池大小" class="headerlink" title="合理设置线程池大小"></a>合理设置线程池大小</h2><p>线程等待时间所占比例越高，需要越多线程。线程 CPU 时间所占比例越高，需要越少线程。</p><p>一般需要根据任务的类型来配置线程池大小： 如果是 CPU 密集型任务，就需要尽量压榨 CPU，参考值可以设为 NCPU+1；如果是 IO 密集型任务，参考值可以设置为 2*NCPU。</p><p>补充：CPU 密集型任务的特点是要进行大量的计算，消耗CPU资源，比如计算圆周率、对视频进行高清解码等等，全靠 CPU 的运算能力；涉及到网络、磁盘 IO 的任务都是 IO 密集型任务，这类任务的特点是 CPU 消耗很少，任务的大部分时间都在等待 IO 操作完成（因为 IO 的速度远远低于 CPU 和内存的速度）。</p>]]></content>
    
    <summary type="html">
    
      Java线程池的关键参数，阻塞队列和拒绝策略
    
    </summary>
    
      <category term="java" scheme="http://yoursite.com/categories/java/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>mysql</title>
    <link href="http://yoursite.com/2019/06/11/mysql/"/>
    <id>http://yoursite.com/2019/06/11/mysql/</id>
    <published>2019-06-11T06:48:33.000Z</published>
    <updated>2019-06-11T07:09:21.057Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="#一、事务">一、事务</a></li><li><a href="#二、范式">二、范式</a></li><li><a href="#三、存储引擎">三、存储引擎</a></li><li><a href="#四、数据类型">四、数据类型</a></li><li><a href="#五、索引">五、索引</a></li><li><a href="#六、查询性能优化">六、查询性能优化</a></li><li><a href="#七、分库分表">七、分库分表</a></li><li><a href="#八、主从复制与读写分离">八、主从复制与读写分离</a></li><li><a href="#九、锁">九、锁</a></li></ul><h2 id="一、事务"><a href="#一、事务" class="headerlink" title="一、事务"></a>一、事务</h2><h4 id="1-什么是事务？"><a href="#1-什么是事务？" class="headerlink" title="1.什么是事务？"></a>1.什么是事务？</h4><p>事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。MySQL 默认采用自动提交模式。也就是说，如果不显式使用 <code>START TRANSACTION</code> 语句来开始一个事务，那么每个查询都会被当做一个事务自动提交。事务简单来说：<strong>一个Session中所进行所有的操作，要么同时成功，要么同时失败。</strong></p><h4 id="2-ACID"><a href="#2-ACID" class="headerlink" title="2.ACID"></a>2.ACID</h4><ul><li><p>原子性（Atomicity）<br>原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。</p></li><li><p>一致性（Consistency）<br>事务前后数据的完整性必须保持一致。</p></li><li><p>隔离性（Isolation）<br>事务的隔离性是多个用户并发访问数据库时，数据库为每一个用户开启的事务，不能被其他事务的操作数据所干扰，多个并发事务之间要相互隔离。</p></li><li><p>持久性（Durability）</p><p>持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响。</p></li></ul><h4 id="3-事务隔离级别"><a href="#3-事务隔离级别" class="headerlink" title="3.事务隔离级别"></a>3.事务隔离级别</h4><p>数据库定义了4个隔离级别：</p><ol><li>序列化：Serializable【可避免脏读，不可重复读，虚读】</li><li>可重复读：Repeatable read【可避免脏读，不可重复读】</li><li>已提交读：Read committed【可避免脏读】</li><li>未提交读：Read uncommitted【级别最低，什么都避免不了】</li></ol><ul><li>分别对应Connection类中的4个常量<ul><li>TRANSACTION_READ_UNCOMMITTED</li><li>TRANSACTION_READ_COMMITTED</li><li>TRANSACTION_REPEATABLE_READ</li><li>TRANSACTION_SERIALIZABLE</li></ul></li><li>脏读：一个事务读取到另外一个事务未提交的数据。</li><li>不可重复读：一个事务读取到另外一个事务已经提交的数据，也就是说一个事务可以看到其他事务所做的修改。</li><li>虚读(幻读)：是指在一个事务内读取到了别的事务插入的数据，导致前后读取不一致。</li><li>简单总结：<strong>脏读是不可容忍的，不可重复读和虚读在一定的情况下是可以的【做统计的肯定就不行】</strong></li></ul><h2 id="二、范式"><a href="#二、范式" class="headerlink" title="二、范式"></a>二、范式</h2><p>数据库中的范式指的是数据库的设计规范，范式具有包含关系。一个数据库设计如果符合第二范式，一定也符合第一范式。如果符合第三范式，一定也符合第二范式…范式逐级加严，一般数据库只需满足 3NF 即可。</p><h4 id="1-第一范式：属性不可分"><a href="#1-第一范式：属性不可分" class="headerlink" title="1.第一范式：属性不可分"></a>1.第一范式：属性不可分</h4><p>当关系模式 R 的所有属性都不能在分解为更基本的数据单位时，称 R 是满足第一范式的，简记为 1NF。</p><p>1NF 是针对于数据表的列的规范，即<strong>数据表的每一列都是不可分割的原子数据项，而不能是数组，集合，记录等非原子数据项</strong>，说白了就是，不能把好几列的数据合在一起，且每一列的数据都是不可分割的。</p><h4 id="2-第二范式：每个非主属性完全函数依赖于键码"><a href="#2-第二范式：每个非主属性完全函数依赖于键码" class="headerlink" title="2.第二范式：每个非主属性完全函数依赖于键码"></a>2.第二范式：每个非主属性完全函数依赖于键码</h4><p>如果关系模式 R 满足第一范式，并且 R 的所有非主属性都完全依赖于 R 的每一个候选关键属性，称 R 满足第二范式，简记为 2NF。</p><p>2NF 基于第一范式，非码属性必须完全依赖码，即非主键数据必须依赖主键数据。“码”(主键)是数据表用来唯一区分实例或记录的数据项，若没有，可人为添加。对于第一范式针对列来说，第二范式则是针对于行的规范。<strong>第二范式需要确保数据库表中每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）</strong>。也就是说在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。</p><h4 id="3-第三范式：非主属性不传递函数依赖于键码"><a href="#3-第三范式：非主属性不传递函数依赖于键码" class="headerlink" title="3.第三范式：非主属性不传递函数依赖于键码"></a>3.第三范式：非主属性不传递函数依赖于键码</h4><p>设 R 是一个满足第一范式条件的关系模式，X 是 R 的任意属性集，如果 X 非传递依赖于 R 的任意一个候选关键字，称 R 满足第三范式，简记为 3NF。</p><p>3NF 需要确保数据表中的<strong>每一列数据都和主键直接相关，而不能间接相关。</strong></p><h2 id="三、存储引擎"><a href="#三、存储引擎" class="headerlink" title="三、存储引擎"></a>三、存储引擎</h2><p>这里主要介绍两个搜索引擎：InnoDB 和 MyISAM</p><h4 id="1-InnoDB"><a href="#1-InnoDB" class="headerlink" title="1.InnoDB"></a>1.InnoDB</h4><p>MySQL 5.5 及之后版本的默认存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎。</p><p><strong>特性</strong></p><ul><li>InnoDB为事务性存储引擎</li><li>完全支持事物的 ACID 特性</li><li>Redo log （实现事务的持久性） 和 Undo log（为了实现事务的原子性，存储未完成事务log，用于回滚）</li><li>InnoDB支持行级锁</li><li>行级锁可以最大程度的支持并发</li><li>行级锁是由存储引擎层实现的</li><li>实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLE READ）。在可重复读隔离级别下，通过多版本并发控制（MVCC）+ 间隙锁（Next-Key Locking）防止幻影读</li><li>主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升</li></ul><p><strong>应用场景</strong></p><ul><li>可靠性要求比较高，或者要求事务</li><li>表更新和查询都相当的频繁，并且行锁定的机会比较大的情况。</li></ul><h4 id="2-MyISAM"><a href="#2-MyISAM" class="headerlink" title="2.MyISAM"></a>2.MyISAM</h4><p>MySQL 5.5 版本之前的默认存储引擎，在 <code>5.0</code> 以前最大表存储空间最大 <code>4G</code>，<code>5.0</code> 以后最大 <code>256TB</code>。</p><p>MyISAM 存储引擎由 <code>.myd</code>（数据）和 <code>.myi</code>（索引文件）组成，<code>.frm</code>文件存储表结构（所有存储引擎都有）</p><p><strong>特性</strong></p><ul><li>并发性和锁级别 （对于读写混合的操作不好，为表级锁，写入和读互斥）</li><li>表损坏修复</li><li>MyISAM 表支持的索引类型（全文索引）</li><li>MyISAM 支持表压缩（压缩后，此表为只读，不可以写入。使用 myisampack 压缩）</li></ul><p><strong>应用场景</strong></p><ul><li>没有事务</li><li>只读类应用（插入不频繁，查询非常频繁）</li><li>空间类应用（唯一支持空间函数的引擎）</li><li>做很多 count 的计算</li></ul><h4 id="3-InnoDB-和-MyISAM-区别"><a href="#3-InnoDB-和-MyISAM-区别" class="headerlink" title="3.InnoDB 和 MyISAM 区别"></a>3.InnoDB 和 MyISAM 区别</h4><table><thead><tr><th>对比项</th><th>MyISAM</th><th>InnoDB</th></tr></thead><tbody><tr><td>主外键</td><td>不支持</td><td>支持</td></tr><tr><td>事务</td><td>不支持</td><td>支持</td></tr><tr><td>行表锁</td><td>表锁，即使操作一条记录也会锁住整个表，不适合高并发的操作</td><td>行锁，操作时只锁某一行，不对其他行有影响，适合高并发的操作</td></tr><tr><td>缓存</td><td>只缓存索引，不缓存真实数据</td><td>不仅缓存索引还要缓存真实数据，对内存要求较高，而且内存大小对性能有决定性的影响</td></tr><tr><td>表空间</td><td>小</td><td>大</td></tr><tr><td>关注点</td><td>性能</td><td>事务</td></tr><tr><td>其他</td><td>MyISAM 表是保存成文件的形式，在跨平台的数据转移中使用 MyISAM 存储会省去不少的麻烦。MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。</td><td>InnoDB 表比 MyISAM 表更安全，可以在保证数据不会丢失的情况下，切换非事务表到事务表（alter table tablename type=innodb）。InnoDB 支持在线热备份。</td></tr><tr><td>应用场景</td><td>MyISAM 管理非事务表。它提供高速存储和检索，以及全文搜索能力。如果应用中需要执行大量的 SELECT 查询，那么 MyISAM 是更好的选择。</td><td>InnoDB 用于事务处理应用程序，具有众多特性，包括 ACID 事务支持。如果应用中需要执行大量的 INSERT 或 UPDATE 操作，则应该使用 InnoDB，这样可以提高多用户并发操作的性能。</td></tr></tbody></table><h2 id="四、数据类型"><a href="#四、数据类型" class="headerlink" title="四、数据类型"></a>四、数据类型</h2><h4 id="1-整型"><a href="#1-整型" class="headerlink" title="1.整型"></a>1.整型</h4><p>TINYINT, SMALLINT, MEDIUMINT, INT, BIGINT 分别使用 8, 16, 24, 32, 64 位存储空间，一般情况下越小的列越好。INT(11) 中的数字只是规定了交互工具显示字符的个数，对于存储和计算来说是没有意义的。</p><h4 id="2-浮点型"><a href="#2-浮点型" class="headerlink" title="2.浮点型"></a>2.浮点型</h4><p>FLOAT 和 DOUBLE 为浮点类型，DECIMAL 为高精度小数类型。CPU 原生支持浮点运算，但是不支持 DECIMAl 类型的计算，因此 DECIMAL 的计算比浮点类型需要更高的代价。</p><p>FLOAT、DOUBLE 和 DECIMAL 都可以指定列宽，例如 DECIMAL(18, 9) 表示总共 18 位，取 9 位存储小数部分，剩下 9 位存储整数部分。</p><h4 id="3-字符串"><a href="#3-字符串" class="headerlink" title="3.字符串"></a>3.字符串</h4><p>主要有 CHAR 和 VARCHAR 两种类型，一种是定长的，一种是变长的。</p><p>VARCHAR 这种变长类型能够节省空间，因为只需要存储必要的内容。但是在执行 UPDATE 时可能会使行变得比原来长，当超出一个页所能容纳的大小时，就要执行额外的操作。MyISAM 会将行拆成不同的片段存储，而 InnoDB 则需要分裂页来使行放进页内。</p><p>VARCHAR 会保留字符串末尾的空格，而 CHAR 会删除。</p><h4 id="4-时间和日期"><a href="#4-时间和日期" class="headerlink" title="4.时间和日期"></a>4.时间和日期</h4><p>MySQL 提供了两种相似的日期时间类型：DATATIME 和 TIMESTAMP。</p><h5 id="DATATIME"><a href="#DATATIME" class="headerlink" title="DATATIME"></a>DATATIME</h5><p>能够保存从 1001 年到 9999 年的日期和时间，精度为秒，使用 8 字节的存储空间。</p><p>它与时区无关。</p><p>默认情况下，MySQL 以一种可排序的、无歧义的格式显示 DATATIME 值，例如“2008-01-16 22:37:08”，这是 ANSI 标准定义的日期和时间表示方法。</p><h5 id="TIMESTAMP"><a href="#TIMESTAMP" class="headerlink" title="TIMESTAMP"></a>TIMESTAMP</h5><p>和 UNIX 时间戳相同，保存从 1970 年 1 月 1 日午夜（格林威治时间）以来的秒数，使用 4 个字节，只能表示从 1970 年 到 2038 年。</p><p>它和时区有关，也就是说一个时间戳在不同的时区所代表的具体时间是不同的。</p><p>MySQL 提供了 FROM_UNIXTIME() 函数把 UNIX 时间戳转换为日期，并提供了 UNIX_TIMESTAMP() 函数把日期转换为 UNIX 时间戳。</p><p>默认情况下，如果插入时没有指定 TIMESTAMP 列的值，会将这个值设置为当前时间。</p><p>应该尽量使用 TIMESTAMP，因为它比 DATETIME 空间效率更高。</p><h2 id="五、索引"><a href="#五、索引" class="headerlink" title="五、索引"></a>五、索引</h2><h4 id="1-索引使用场景"><a href="#1-索引使用场景" class="headerlink" title="1.索引使用场景"></a>1.索引使用场景</h4><p>索引能够轻易将查询性能提升几个数量级。</p><ol><li>对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效。</li><li>对于中到大型的表，索引就非常有效。</li><li>但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。</li></ol><p>索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。</p><h4 id="2-B-树"><a href="#2-B-树" class="headerlink" title="2.B+ 树"></a>2.B+ 树</h4><p>B Tree 指的是 Balance Tree，也就是平衡树。平衡树是一颗查找树，并且所有叶子节点位于同一层。</p><p>B+ Tree 是基于 B Tree 和叶子节点顺序访问指针进行实现，它具有 B Tree 的平衡性，并且通过顺序访问指针来提高区间查询的性能。在 B+ Tree 中，一个节点中的 key 从左到右非递减排列，如果某个指针的左右相邻 key 分别是 keyi 和 keyi+1，且不为 null，则该指针指向节点的所有 key 大于等于 keyi 且小于等于 keyi+1。</p><p><img src="http://qnya.pomo16.club/246.png" alt></p><p>主要特点：<strong>内节点只存指针，叶子节点只存数据，有序</strong></p><h4 id="3-为什么选-B-树？"><a href="#3-为什么选-B-树？" class="headerlink" title="3.为什么选 B+ 树？"></a>3.为什么选 B+ 树？</h4><p>红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B Tree 作为索引结构，主要有以下两个原因：</p><ol><li><p><strong>更少的检索次数</strong></p><p>平衡树检索数据的时间复杂度等于树高 h，而树高大致为 O(h)=O(log<sub>d</sub>N)，其中 d 为每个节点的出度。</p><p>红黑树的出度为 2，而 B Tree 的出度一般都非常大。红黑树的树高 h 很明显比 B Tree 大非常多，因此检索的次数也就更多。</p><p>B+Tree 相比于 B-Tree 更适合外存索引，因为 B+Tree 内节点去掉了 data 域，因此可以拥有更大的出度，检索效率会更高。</p></li><li><p><strong>利用磁盘预读特性</strong></p><p>为了减少磁盘 I/O 操作，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的磁盘旋转时间，速度会非常快。</p><p>操作系统一般将内存和磁盘分割成固定大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点。并且可以利用预读特性，相邻的节点也能够被预先载入。</p></li></ol><h4 id="4-索引分类"><a href="#4-索引分类" class="headerlink" title="4.索引分类"></a>4.索引分类</h4><h5 id="B-树索引"><a href="#B-树索引" class="headerlink" title="B+ 树索引"></a>B+ 树索引</h5><ul><li>B+Tree 索引是大多数 MySQL 存储引擎的默认索引类型。</li><li>因为不再需要进行全表扫描，只需要对树进行搜索即可，因此查找速度快很多。除了用于查找，还可以用于排序和分组。</li><li>可以指定多个列作为索引列，多个索引列共同组成键。</li><li>适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。</li></ul><p>InnoDB 的 B+Tree 索引分为<strong>主索引</strong>和<strong>辅助索引</strong>。</p><p>主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。</p><p><img src="http://qnya.pomo16.club/247.png" alt></p><p>辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。</p><p><img src="http://qnya.pomo16.club/248.png" alt></p><h5 id="哈希索引"><a href="#哈希索引" class="headerlink" title="哈希索引"></a>哈希索引</h5><p>InnoDB 引擎有一个特殊的功能叫 “自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。</p><p>哈希索引能以 O(1) 时间进行查找，但是失去了有序性，它具有以下限制：</p><ul><li>无法用于排序与分组。</li><li>只支持精确查找，无法用于部分查找和范围查找。</li></ul><h5 id="全文索引"><a href="#全文索引" class="headerlink" title="全文索引"></a>全文索引</h5><p>MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。查找条件使用 MATCH AGAINST，而不是普通的 WHERE。</p><p>全文索引一般使用倒排索引实现，它记录着关键词到其所在文档的映射。</p><p>InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。</p><h5 id="空间数据索引（R-Tree）"><a href="#空间数据索引（R-Tree）" class="headerlink" title="空间数据索引（R-Tree）"></a>空间数据索引（R-Tree）</h5><p>MyISAM 存储引擎支持空间数据索引，可以用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。</p><p>必须使用 GIS 相关的函数来维护数据。</p><h4 id="5-索引种类"><a href="#5-索引种类" class="headerlink" title="5.索引种类"></a>5.索引种类</h4><ul><li><p>聚簇索引：数据行的物理顺序与列值（一般是主键的那一列）的逻辑顺序相同，一个表中只能拥有一个聚集索引。</p><ul><li><p>主键索引：加速查询 + 列值唯一（不可以有null）+ 表中只有一个</p><p>一种唯一性索引，必须指定为 primary key。一个表可以有多个唯一索引，但只能有一个主键。主键一定是唯一，唯一不一定是主键。且主键索引可以被其他表引用当外键，唯一索引不可以。</p></li></ul></li><li><p>非聚簇索引：该索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同，一个表中可以拥有多个非聚集索引。</p><ul><li>普通索引：仅加速查询</li><li>唯一索引：加速查询 + 列值唯一（可以有null）</li><li>组合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并</li><li>全文索引：对文本的内容进行分词，进行搜索，可以在char、varchar或text类型的列上创建。</li></ul></li></ul><h4 id="6-联合索引"><a href="#6-联合索引" class="headerlink" title="6.联合索引"></a>6.联合索引</h4><h5 id="什么是联合索引？"><a href="#什么是联合索引？" class="headerlink" title="什么是联合索引？"></a>什么是联合索引？</h5><p>两个或更多个列上的索引被称作联合索引，联合索引又叫复合索引。对于复合索引：Mysql 从左到右的使用索引中的字段，一个查询可以只使用索引中的一部份，但只能是最左侧部分。</p><p>例如索引是 key index (a,b,c)，可以支持[a]、[a,b]、[a,b,c] 3种组合进行查找，但不支 [b,c] 进行查找。当最左侧字段是常量引用时，索引就十分有效。</p><h5 id="命名规则"><a href="#命名规则" class="headerlink" title="命名规则"></a>命名规则</h5><ul><li>需要加索引的字段，要在 where 条件中</li><li>数据量少的字段不需要加索引</li><li>如果 where 条件中是OR关系，加索引不起作用</li><li>符合最左原则</li></ul><h4 id="7-索引的特点"><a href="#7-索引的特点" class="headerlink" title="7.索引的特点"></a>7.索引的特点</h4><ul><li>可以加快数据库的检索速度</li><li>降低数据库插入、修改、删除等维护的速度</li><li>只能创建在表上，不能创建到视图上</li><li>既可以直接创建又可以间接创建</li><li>可以在优化隐藏中使用索引</li><li>使用查询处理器执行SQL语句，在一个表上，一次只能使用一个索引</li></ul><p><strong>优点</strong></p><ul><li>创建唯一性索引，保证数据库表中每一行数据的唯一性</li><li>大大加快数据的检索速度，这是创建索引的最主要的原因</li><li>加速数据库表之间的连接，特别是在实现数据的参考完整性方面特别有意义</li><li>在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间</li><li>通过使用索引，可以在查询中使用优化隐藏器，提高系统的性能</li></ul><p><strong>缺点</strong></p><ul><li>创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加</li><li>索引需要占用物理空间，除了数据表占用数据空间之外，每一个索引还要占一定的物理空间，如果建立聚簇索引，那么需要的空间就会更大</li><li>当对表中的数据进行增加、删除和修改的时候，索引也需要维护，降低数据维护的速度</li></ul><h4 id="8-索引失效的情况"><a href="#8-索引失效的情况" class="headerlink" title="8.索引失效的情况"></a>8.索引失效的情况</h4><ul><li><p>如果MySQL估计使用<strong>全表扫秒比使用索引快</strong>，则不使用索引。</p><p>例：如果列 key 均匀分布在 1 和 100 之间，下面的查询使用索引就不是很好：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from table_name where key&gt;1 and key&lt;90;</span><br></pre></td></tr></table></figure></li><li><p>如果<strong>条件中有 or</strong>，即使其中有条件带索引也不会使用。</p><p>例：如果在 key1 上有索引而在 key2 上没有索引，则该查询也不会走索引：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from table_name where key1=&apos;a&apos; or key2=&apos;b&apos;;</span><br></pre></td></tr></table></figure></li><li><p>复合索引，如果索引列<strong>不是复合索引的第一部分</strong>，则不使用索引。（即不符合最左前缀）</p><p>例：复合索引为(key1,key2)，则下列查询将不会使用索引：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from table_name where key2=&apos;b&apos;;</span><br></pre></td></tr></table></figure></li><li><p>如果 <strong>like 是以 % 开始的</strong>，则该列上的索引不会被使用。</p><p>例：下列查询即使 key1 上存在索引，也不会被使用如果列类型是字符串，那一定要在条件中使用引号引起来，否则不会使用索引。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from table_name where key1 like &apos;%a&apos;;</span><br></pre></td></tr></table></figure></li><li><p>如果列为字符串，则 where 条件中必须将字符常量值加引号，否则即使该列上存在索引，也不会被使用。</p><p>例：如果key1列保存的是字符串，即使key1上有索引，也不会被使用。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from table_name where key1=1;</span><br></pre></td></tr></table></figure></li><li><p>如果使用 MEMORY/HEAP 表，并且 where 条件中不使用 “=” 进行索引列，那么不会用到索引，head 表只有在 “=” 的条件下才会使用索引。</p></li></ul><h4 id="9-在什么情况下适合建立索引？"><a href="#9-在什么情况下适合建立索引？" class="headerlink" title="9.在什么情况下适合建立索引？"></a>9.在什么情况下适合建立索引？</h4><ul><li>为经常出现在关键字 order by、group by、distinct 后面的字段，建立索引。</li><li>在 union 等集合操作的结果集字段上，建立索引。其建立索引的目的同上。</li><li>为经常用作查询选择 where 后的字段，建立索引。</li><li>在经常用作表连接 join 的属性上，建立索引。</li><li>考虑使用索引覆盖。对数据很少被更新的表，如果用户经常只查询其中的几个字段，可以考虑在这几个字段上建立索引，从而将表的扫描改变为索引的扫描。</li></ul><h4 id="10-主键、外键和索引的区别"><a href="#10-主键、外键和索引的区别" class="headerlink" title="10.主键、外键和索引的区别"></a>10.主键、外键和索引的区别</h4><table><thead><tr><th></th><th>定义</th><th>作用</th><th>个数</th></tr></thead><tbody><tr><td><strong>主键</strong></td><td>唯一标识一条记录，不能有重复的，不允许为空</td><td>用来保证数据完整性</td><td>主键只能有一个</td></tr><tr><td><strong>外键</strong></td><td>表的外键是另一表的主键，外键可以有重复的，可以是空值</td><td>用来和其他表建立联系用的</td><td>一个表可以有多个外键</td></tr><tr><td><strong>索引</strong></td><td>该字段没有重复值，但可以有一个空值</td><td>是提高查询排序的速度</td><td>一个表可以有多个惟一索引</td></tr></tbody></table><h4 id="11-SQL-约束有哪几种？"><a href="#11-SQL-约束有哪几种？" class="headerlink" title="11. SQL 约束有哪几种？"></a>11. SQL 约束有哪几种？</h4><ul><li>NOT NULL: 用于控制字段的内容一定不能为空（NULL）。</li><li>UNIQUE: 控件字段内容不能重复，一个表允许有多个 Unique 约束。</li><li>PRIMARY KEY: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。</li><li>FOREIGN KEY: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。</li><li>CHECK: 用于控制字段的值范围。</li></ul><h2 id="六、查询性能优化"><a href="#六、查询性能优化" class="headerlink" title="六、查询性能优化"></a>六、查询性能优化</h2><h4 id="1-用-Explain-进行分析"><a href="#1-用-Explain-进行分析" class="headerlink" title="1.用 Explain 进行分析"></a>1.用 Explain 进行分析</h4><p>Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。</p><p>比较重要的字段有：</p><ul><li>select_type : 查询类型，有简单查询、联合查询、子查询等</li><li>key : 使用的索引</li><li>rows : 扫描的行数</li></ul><h4 id="2-优化数据访问"><a href="#2-优化数据访问" class="headerlink" title="2.优化数据访问"></a>2.优化数据访问</h4><ul><li>减少请求的数据量<ul><li>只返回必要的列：最好不要使用 SELECT * 语句。</li><li>只返回必要的行：使用 LIMIT 语句来限制返回的数据。</li><li>缓存重复查询的数据：使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。</li></ul></li><li>减少服务器端扫描的行数<ul><li>最有效的方式是使用索引来覆盖查询。</li></ul></li></ul><h4 id="3-重构查询方式"><a href="#3-重构查询方式" class="headerlink" title="3.重构查询方式"></a>3.重构查询方式</h4><ul><li><p>切分大查询</p><p>一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELEFT FROM messages WHERE create &lt; DATE_SUB(NOW(), INTERVAL 3 MONTH);</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rows_affected = 0</span><br><span class="line">do &#123;</span><br><span class="line">    rows_affected = do_query(</span><br><span class="line">    &quot;DELETE FROM messages WHERE create  &lt; DATE_SUB(NOW(), INTERVAL 3 MONTH) LIMIT 10000&quot;)</span><br><span class="line">&#125; while rows_affected &gt; 0</span><br></pre></td></tr></table></figure></li><li><p>分解大连接查询</p><p>将一个大连接查询（JOIN）分解成对每一个表进行一次单表查询，然后将结果在应用程序中进行关联，这样做的好处有：</p><ul><li>让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。</li><li>分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。</li><li>减少锁竞争；</li><li>在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可扩展。</li><li>查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM tab</span><br><span class="line">JOIN tag_post ON tag_post.tag_id=tag.id</span><br><span class="line">JOIN post ON tag_post.post_id=post.id</span><br><span class="line">WHERE tag.tag=&apos;mysql&apos;;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM tag WHERE tag=&apos;mysql&apos;;</span><br><span class="line">SELECT * FROM tag_post WHERE tag_id=1234;</span><br><span class="line">SELECT * FROM post WHERE post.id IN (123,456,567,9098,8904);</span><br></pre></td></tr></table></figure></li></ul><h2 id="七、分库分表"><a href="#七、分库分表" class="headerlink" title="七、分库分表"></a>七、分库分表</h2><p>简单来说，数据的切分就是通过某种特定的条件，将我们存放在同一个数据库中的数据分散存放到多个数据库（主机）中，以达到分散单台设备负载的效果，即分库分表。</p><p>数据的切分根据其切分规则的类型，可以分为如下两种切分模式。</p><ul><li>垂直（纵向）切分：把单一的表拆分成多个表，并分散到不同的数据库（主机）上。</li><li>水平（横向）切分：根据表中数据的逻辑关系，将同一个表中的数据按照某种条件拆分到多台数据库（主机）上。</li></ul><h4 id="1-水平切分"><a href="#1-水平切分" class="headerlink" title="1.水平切分"></a>1.水平切分</h4><p>水平切分又称为 Sharding，它是将同一个表中的记录拆分到多个结构相同的表中。</p><p>当一个表的数据不断增多时，Sharding 是必然的选择，它可以将数据分布到集群的不同节点上，从而缓存单个数据库的压力。</p><p><img src="http://qnya.pomo16.club/249.png" alt></p><h5 id="Sharding-优点"><a href="#Sharding-优点" class="headerlink" title="Sharding 优点"></a>Sharding 优点</h5><ul><li>单库单表的数据保持在一定的量级，有助于性能的提高</li><li>切分的表的结构相同，应用层改造较少，只需要增加路由规则即可</li><li>提高了系统的稳定性和负载能力</li></ul><h5 id="Sharding-缺点"><a href="#Sharding-缺点" class="headerlink" title="Sharding 缺点"></a>Sharding 缺点</h5><ul><li>切分后，数据是分散的，很难利用数据库的 join 操作，跨库 join 性能较差</li><li>拆分规则难以抽象</li><li>分片事务的一致性难以解决</li><li>数据扩容的难度和维护量极大</li></ul><h5 id="Sharding-策略"><a href="#Sharding-策略" class="headerlink" title="Sharding 策略"></a>Sharding 策略</h5><ul><li>哈希取模：hash(key) % NUM_DB<ul><li>比如按照 userId mod 64，将数据分布在64个服务器上</li></ul></li><li>范围：可以是 ID 范围也可以是时间范围<ul><li>比如每台服务器计划存放一个亿的数据,先将数据写入服务器 A.一旦服务器 A 写满,则将数据写入服务器 B,以此类推. 这种方式的好处是扩展方便.数据在各个服务器上分布均匀</li></ul></li><li>映射表：使用单独的一个数据库来存储映射关系</li></ul><h5 id="Sharding-存在的问题及解决方案"><a href="#Sharding-存在的问题及解决方案" class="headerlink" title="Sharding 存在的问题及解决方案"></a>Sharding 存在的问题及解决方案</h5><ul><li>事务问题：使用分布式事务来解决，比如 XA 接口。</li><li>JOIN：可以将原来的 JOIN 查询分解成多个单表查询，然后在用户程序中进行 JOIN。</li><li>ID 唯一性<ul><li>使用全局唯一 ID：GUID。</li><li>为每个分片指定一个 ID 范围。</li><li>分布式 ID 生成器 (如 Twitter 的 Snowflake 算法)。</li></ul></li></ul><h4 id="2-垂直切分"><a href="#2-垂直切分" class="headerlink" title="2.垂直切分"></a>2.垂直切分</h4><p>垂直切分是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。</p><p>在数据库的层面使用垂直切分将按数据库中表的密集程度部署到不同的库中，例如将原来的电商数据库垂直切分成商品数据库、用户数据库等。</p><p><img src="http://qnya.pomo16.club/250.png" alt></p><h5 id="垂直切分的优点"><a href="#垂直切分的优点" class="headerlink" title="垂直切分的优点"></a>垂直切分的优点</h5><ul><li>拆分后业务清晰，拆分规则明确</li><li>系统之间进行整合或扩展很容易</li><li>按照成本、应用的等级、应用的类型等将表放到不同的机器上，便于管理</li><li>便于实现<strong>动静分离</strong>、<strong>冷热分离</strong>的数据库表的设计模式</li><li>数据维护简单</li></ul><h5 id="垂直切分的缺点"><a href="#垂直切分的缺点" class="headerlink" title="垂直切分的缺点"></a>垂直切分的缺点</h5><ul><li>部分业务表无法关联（Join），只能通过接口方式解决，提高了系统的复杂度</li><li>受每种业务的不同限制，存在单库性能瓶颈，不易进行数据扩展和提升性能</li><li>事务处理复杂</li></ul><h4 id="3-垂直切分和水平切分的共同点"><a href="#3-垂直切分和水平切分的共同点" class="headerlink" title="3.垂直切分和水平切分的共同点"></a>3.垂直切分和水平切分的共同点</h4><ul><li>存在分布式事务的问题</li><li>存在跨节点 Join 的问题</li><li>存在跨节点合并排序、分页的问题</li><li>存在多数据源管理的问题</li></ul><h2 id="八、主从复制与读写分离"><a href="#八、主从复制与读写分离" class="headerlink" title="八、主从复制与读写分离"></a>八、主从复制与读写分离</h2><h4 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h4><p>主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。</p><ul><li><strong>binlog 线程</strong> ：负责将主服务器上的数据更改写入二进制文件（binlog）中。</li><li><strong>I/O 线程</strong> ：负责从主服务器上读取二进制日志文件，并写入从服务器的中继日志中。</li><li><strong>SQL 线程</strong> ：负责读取中继日志并重放其中的 SQL 语句。</li></ul><p><img src="http://qnya.pomo16.club/251.png" alt></p><h4 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h4><p>主服务器用来处理写操作以及实时性要求比较高的读操作，而从服务器用来处理读操作。</p><p>读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。</p><p>MySQL 读写分离能提高性能的原因在于：</p><ul><li>主从服务器负责各自的读和写，极大程度缓解了锁的争用；</li><li>从服务器可以配置 MyISAM 引擎，提升查询性能以及节约系统开销；</li><li>增加冗余，提高可用性。</li></ul><p><img src="http://qnya.pomo16.club/252.png" alt></p><h2 id="九、锁"><a href="#九、锁" class="headerlink" title="九、锁"></a>九、锁</h2><p>MySQL/InnoDB 的加锁，一直是一个面试中常问的话题。例如，数据库如果有高并发请求，如何保证数据完整性？产生死锁问题如何排查并解决？在工作过程中，也会经常用到，乐观锁，排它锁等。</p><p>注：MySQL 是一个支持插件式存储引擎的数据库系统。下面的所有介绍，都是基于 InnoDB 存储引擎，其他引擎的表现，会有较大的区别。</p><p><strong>版本查看</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select version();</span><br></pre></td></tr></table></figure><p><strong>存储引擎查看</strong></p><p>MySQL 给开发者提供了查询存储引擎的功能，我这里使用的是 MySQL5.6.4，可以使用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SHOW ENGINES</span><br></pre></td></tr></table></figure><h4 id="1-乐观锁"><a href="#1-乐观锁" class="headerlink" title="1.乐观锁"></a>1.乐观锁</h4><p>假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。</p><p>用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。当读取数据时，将 version 字段的值一同读出，数据每更新一次，对此 version 值加1。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的 version 值进行比对，如果数据库表当前版本号与第一次取出来的 version 值相等，则予以更新，否则认为是过期数据。例：</p><p>a. 数据库表设计三个字段，分别是 id,value,version</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id,value,version from TABLE where id=#&#123;id&#125;</span><br></pre></td></tr></table></figure><p>b. 每次更新表中的value字段时，为了防止发生冲突，需要这样操作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">update TABLE</span><br><span class="line">set value=2,version=version+1</span><br><span class="line">where id=#&#123;id&#125; and version=#&#123;version&#125;;</span><br></pre></td></tr></table></figure><h4 id="2-悲观锁"><a href="#2-悲观锁" class="headerlink" title="2.悲观锁"></a>2.悲观锁</h4><p>假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。</p><p>悲观锁就是在操作数据时，认为此操作会出现数据冲突，所以在进行每次操作时都要通过获取锁才能进行对相同数据的操作，这点跟 Java 中的 synchronized 很相似，所以悲观锁需要耗费较多的时间。另外与乐观锁相对应的，悲观锁是由数据库自己实现了的，要用的时候，我们直接调用数据库的相关语句就可以了。</p><p>说到这里，由悲观锁涉及到的另外两个锁概念就出来了，它们就是<strong>共享锁</strong>与<strong>排它锁</strong>。<strong>共享锁和排它锁是悲观锁的不同的实现</strong>，它俩都属于悲观锁的范畴。以排它锁为例：</p><p>要使用悲观锁，我们必须关闭 mysql 数据库的自动提交属性，因为 MySQL 默认使用 autocommit 模式，也就是说，当你执行一个更新操作后，MySQL 会立刻将结果进行提交。我们可以使用命令设置 MySQL 为非 autocommit 模式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">set autocommit=0;</span><br><span class="line"># 设置完autocommit后，我们就可以执行我们的正常业务了。具体如下：</span><br><span class="line"></span><br><span class="line"># 1. 开始事务 (三者选一就可以)</span><br><span class="line">begin; / begin work; / start transaction;</span><br><span class="line"></span><br><span class="line"># 2. 查询表信息</span><br><span class="line">select status from TABLE where id=1 for update;</span><br><span class="line"></span><br><span class="line"># 3. 插入一条数据</span><br><span class="line">insert into TABLE (id,value) values (2,2);</span><br><span class="line"></span><br><span class="line"># 4. 修改数据为</span><br><span class="line">update TABLE set value=2 where id=1;</span><br><span class="line"></span><br><span class="line"># 5. 提交事务</span><br><span class="line">commit;/commit work;</span><br></pre></td></tr></table></figure><h4 id="3-共享锁"><a href="#3-共享锁" class="headerlink" title="3.共享锁"></a>3.共享锁</h4><p>共享锁又称<strong>读锁</strong>（read lock），是读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行修改（获取数据上的排他锁），直到已释放所有共享锁。</p><p>如果事务 T 对数据 A 加上共享锁后，则其他事务只能对 A 再加共享锁，不能加排他锁。获得共享锁的事务只能读数据，不能修改数据。</p><p>打开第一个查询窗口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#三者选一就可以</span><br><span class="line">begin; / begin work; / start transaction;</span><br><span class="line"></span><br><span class="line">SELECT * from TABLE where id = 1  lock in share mode;</span><br></pre></td></tr></table></figure><p>然后在另一个查询窗口中，对 id 为 1 的数据进行更新</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update TABLE set name=&quot;www.souyunku.com&quot; where id =1;</span><br></pre></td></tr></table></figure><p>此时，操作界面进入了卡顿状态，过了超时间，提示错误信息</p><p>如果在超时前，执行 <code>commit</code>，此更新语句就会成功。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[SQL]update  test_one set name=&quot;www.souyunku.com&quot; where id =1;</span><br><span class="line">[Err] 1205 - Lock wait timeout exceeded; try restarting transaction</span><br></pre></td></tr></table></figure><p>加上共享锁后，也提示错误信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">update test_one set name=&quot;www.souyunku.com&quot; where id =1 lock in share mode;</span><br><span class="line">[SQL]update  test_one set name=&quot;www.souyunku.com&quot; where id =1 lock in share mode;</span><br><span class="line">[Err] 1064 - You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &apos;lock in share mode&apos; at line 1</span><br></pre></td></tr></table></figure><p>在查询语句后面增加 <code>lock in share mode</code>，MySQL 会对查询结果中的每行都加共享锁，当没有其他线程对查询结果集中的任何一行使用排他锁时，可以成功申请共享锁，否则会被阻塞。其他线程也可以读取使用了共享锁的表，而且这些线程读取的是同一个版本的数据。</p><p>加上共享锁后，对于 <code>update,insert,delete</code> 语句会自动加排它锁。</p><h4 id="4-排它锁"><a href="#4-排它锁" class="headerlink" title="4.排它锁"></a>4.排它锁</h4><p>排他锁 exclusive lock（也叫 writer lock）又称<strong>写锁</strong>。</p><p><strong>排它锁是悲观锁的一种实现，在上面悲观锁也介绍过</strong>。</p><p>若事务 1 对数据对象 A 加上 X 锁，事务 1 可以读 A 也可以修改 A，其他事务不能再对 A 加任何锁，直到事物 1 释放 A 上的锁。这保证了其他事务在事物 1 释放 A 上的锁之前不能再读取和修改 A。排它锁会阻塞所有的排它锁和共享锁。</p><p>读取为什么要加读锁呢：防止数据在被读取的时候被别的线程加上写锁。</p><p>使用方式：在需要执行的语句后面加上 <code>for update</code> 就可以了。</p><h4 id="5-行锁"><a href="#5-行锁" class="headerlink" title="5.行锁"></a>5.行锁</h4><p>行锁又分<strong>共享锁</strong>和<strong>排他锁</strong>，由字面意思理解，就是给某一行加上锁，也就是一条记录加上锁。</p><p>注意：行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁。</p><p><strong>共享锁：</strong></p><p>名词解释：共享锁又叫做读锁，所有的事务只能对其进行读操作不能写操作，加上共享锁后在事务结束之前其他事务只能再加共享锁，除此之外其他任何类型的锁都不能再加了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#结果集的数据都会加共享锁</span><br><span class="line">SELECT * from TABLE where id = &quot;1&quot;  lock in share mode;</span><br></pre></td></tr></table></figure><p><strong>排他锁：</strong></p><p>名词解释：若某个事物对某一行加上了排他锁，只能这个事务对其进行读写，在此事务结束之前，其他事务不能对其进行加任何锁，其他进程可以读取，不能进行写操作，需等待其释放。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select status from TABLE where id=1 for update;</span><br></pre></td></tr></table></figure><p>可以参考之前演示的共享锁，排它锁语句</p><p>由于对于表中 id 字段为主键，就也相当于索引。执行加锁时，会将 id 这个索引为 1 的记录加上锁，那么这个锁就是行锁。</p><h4 id="6-表锁"><a href="#6-表锁" class="headerlink" title="6.表锁"></a>6.表锁</h4><p><strong>如何加表锁</strong></p><p>innodb 的行锁是在有索引的情况下,没有索引的表是锁定全表的。</p><p><strong>Innodb中的行锁与表锁</strong></p><p>前面提到过，在 Innodb 引擎中既支持行锁也支持表锁，那么什么时候会锁住整张表，什么时候或只锁住一行呢？ 只有通过索引条件检索数据，InnoDB 才使用行级锁，否则，InnoDB 将使用表锁！</p><p>在实际应用中，要特别注意 InnoDB 行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。</p><p>行级锁都是基于索引的，如果一条 SQL 语句用不到索引是不会使用行级锁的，会使用表级锁。行级锁的缺点是：由于需要请求大量的锁资源，所以速度慢，内存消耗大。</p><h4 id="7-死锁"><a href="#7-死锁" class="headerlink" title="7. 死锁"></a>7. 死锁</h4><p>死锁（Deadlock） 所谓死锁：是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。由于资源占用是互斥的，当某个进程提出申请资源后，使得有关进程在无外力协助下，永远分配不到必需的资源而无法继续运行，这就产生了一种特殊现象死锁。</p><p>解除正在死锁的状态有两种方法：</p><p><strong>第一种</strong>：</p><p>查询是否锁表</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show OPEN TABLES where In_use &gt; 0;</span><br></pre></td></tr></table></figure><p>查询进程（如果您有SUPER权限，您可以看到所有线程。否则，您只能看到您自己的线程）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show processlist</span><br></pre></td></tr></table></figure><p>杀死进程id（就是上面命令的id列）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kill id</span><br></pre></td></tr></table></figure><p><strong>第二种</strong>：</p><p>查看当前的事务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX;</span><br></pre></td></tr></table></figure><p>查看当前锁定的事务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;</span><br></pre></td></tr></table></figure><p>查看当前等锁的事务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS;</span><br></pre></td></tr></table></figure><p>杀死进程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kill 进程ID</span><br></pre></td></tr></table></figure><p>如果系统资源充足，进程的资源请求都能够得到满足，死锁出现的可能性就很低，否则就会因争夺有限的资源而陷入死锁。其次，进程运行推进顺序与速度不同，也可能产生死锁。 产生死锁的四个必要条件：</p><ol><li>互斥条件：一个资源每次只能被一个进程使用。</li><li>请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。</li><li>不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。</li><li>循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。</li></ol><p>虽然不能完全避免死锁，但可以使死锁的数量减至最少。将死锁减至最少可以增加事务的吞吐量并减少系统开销，因为只有很少的事务回滚，而回滚会取消事务执行的所有工作。由于死锁时回滚而由应用程序重新提交。</p><p><strong>下列方法有助于最大限度地降低死锁：</strong></p><ol><li>按同一顺序访问对象</li><li>避免事务中的用户交互</li><li>保持事务简短并在一个批处理中</li><li>使用低隔离级别</li><li>使用绑定连接</li></ol>]]></content>
    
    <summary type="html">
    
      总结 mysql 的基础知识和优化技巧。
    
    </summary>
    
      <category term="mysql" scheme="http://yoursite.com/categories/mysql/"/>
    
    
      <category term="mysql" scheme="http://yoursite.com/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>计算机网络基础</title>
    <link href="http://yoursite.com/2019/06/11/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/"/>
    <id>http://yoursite.com/2019/06/11/计算机网络基础/</id>
    <published>2019-06-11T02:36:39.000Z</published>
    <updated>2019-06-11T05:57:57.616Z</updated>
    
    <content type="html"><![CDATA[<p>总结自 <a href="https://juejin.im/post/5b7be0b2e51d4538db34a51e" target="_blank" rel="noopener">SnailClimb</a> 和 <a href="https://github.com/frank-lam/fullstack-tutorial/blob/master/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.md#5-tcp%E5%92%8Cudp%E5%8C%BA%E5%88%AB%E5%A6%82%E4%BD%95%E6%94%B9%E8%BF%9Btcp" target="_blank" rel="noopener">frank-lam</a> 的博文。</p><a id="more"></a><h2 id="一、OSI七层模型、TCP-IP四层模型和五层协议"><a href="#一、OSI七层模型、TCP-IP四层模型和五层协议" class="headerlink" title="一、OSI七层模型、TCP/IP四层模型和五层协议"></a>一、OSI七层模型、TCP/IP四层模型和五层协议</h2><p><img src="http://qnya.pomo16.club/236.png" alt></p><h3 id="1-五层协议"><a href="#1-五层协议" class="headerlink" title="1. 五层协议"></a>1. 五层协议</h3><h4 id="1-应用层"><a href="#1-应用层" class="headerlink" title="(1) 应用层"></a>(1) 应用层</h4><p>提供用户接口，特指能够发起网络流量的程序，比如客户端程序：QQ，MSN，浏览器等；服务器程序：web 服务器，邮件服务器，流媒体服务器等等。</p><p>在互联网中应用层协议很多，如域名系统 DNS，支持万维网应用的 HTTP 协议，支持电子邮件的 SMTP 协议等等。数据单位为报文。</p><p><strong>域名系统</strong></p><blockquote><p>域名系统 (Domain Name System 缩写 DNS，Domain Name 被译为域名)是因特网的一项核心服务，它作为可以将域名和 IP 地址相互映射的一个分布式数据库，能够使人更方便的访问互联网，而不用去记住能够被机器直接读取的 IP 数串。（百度百科）例如：一个公司的 Web  网站可看作是它在网上的门户，而域名就相当于其门牌地址，通常域名都使用该公司的名称或简称。例如上面提到的微软公司的域名，类似的还有：IBM 公司的域名是 <a href="https://link.juejin.im?target=http%3A%2F%2Fwww.ibm.com" target="_blank" rel="noopener">www.ibm.com</a>、Oracle 公司的域名是 <a href="https://link.juejin.im?target=http%3A%2F%2Fwww.oracle.com" target="_blank" rel="noopener">www.oracle.com</a>、Cisco公司的域名是 <a href="https://link.juejin.im?target=http%3A%2F%2Fwww.cisco.com" target="_blank" rel="noopener">www.cisco.com</a> 等。</p></blockquote><p><strong>HTTP 协议</strong></p><blockquote><p>超文本传输协议（HTTP，HyperText Transfer Protocol) 是互联网上应用最为广泛的一种网络协议。所有的 WWW（万维网） 文件都必须遵守这个标准。设计 HTTP 最初的目的是为了提供一种发布和接收 HTML 页面的方法。</p></blockquote><h4 id="2-传输层"><a href="#2-传输层" class="headerlink" title="(2) 传输层"></a>(2) 传输层</h4><p>负责向两台主机进程之间的通信提供通用的数据传输服务。由于应用层协议很多，定义通用的传输层协议就可以支持不断增多的应用层协议。传输层向用户提供可靠的端到端服务，透明地传送报文。</p><p><strong>传输层主要两种协议</strong></p><ul><li><strong>传输控制协议 TCP</strong>提供<strong>面向连接的，</strong>可靠的数据传输服务。</li><li><strong>用户数据协议 UDP</strong>提供<strong>无连接</strong>的，尽最大努力的数据传输服务（<strong>不保证数据传输的可靠性</strong>）。</li><li>TCP 主要提供完整性服务，UDP 主要提供及时性服务。</li></ul><p><strong>UDP 的主要特点</strong></p><ol><li>UDP 是无连接的；</li><li>UDP 使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态（这里面有许多参数）；</li><li>UDP 是面向报文的；</li><li>UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如直播，实时视频会议等）；</li><li>UDP 支持一对一、一对多、多对一和多对多的交互通信；</li><li>UDP 的首部开销小，只有8个字节，比 TCP 的20个字节的首部要短。</li></ol><p><strong>TCP 的主要特点</strong></p><ol><li>TCP 是面向连接的。（就好像打电话一样，通话前需要先拨号建立连接，通话结束后要挂机释放连接）；</li><li>每一条 TCP 连接只能有两个端点，每一条 TCP 连接只能是点对点的（一对一）；</li><li>TCP 提供可靠交付的服务。通过 TCP 连接传送的数据，无差错、不丢失、不重复、并且按序到达；</li><li>TCP 提供全双工通信。TCP 允许通信双方的应用进程在任何时候都能发送数据。TCP 连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据；</li><li>面向字节流。TCP 中的 “流”（Stream）指的是流入进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和 TCP 的交互是一次一个数据块（大小不等），但 TCP 把应用程序交下来的数据仅仅看成是一连串的无结构的字节流。</li></ol><h4 id="3-网络层"><a href="#3-网络层" class="headerlink" title="(3) 网络层"></a>(3) 网络层</h4><p>为主机间提供数据传输服务，而运输层协议是为主机中的进程提供服务。网络层把运输层传递下来的报文段或者用户数据报封装成分组和包进行传送。（负责选择最佳路径规划 IP 地址）</p><p>在 TCP/IP 体系结构中，由于网络层使用 <strong>IP 协议</strong>，因此分组也叫 <strong>IP 数据报</strong> ，简称<strong>数据报</strong>。</p><p>网络层的另一个任务就是选择合适的路由，使源主机运输层所传下来的分株，能通过网络层中的路由器找到目的主机。路由器查看数据包目标 IP 地址，根据路由表为数据包选择路径。路由表中的类目可以人工添加（静态路由）也可以动态生成（动态路由）。</p><h4 id="4-数据链路层"><a href="#4-数据链路层" class="headerlink" title="(4) 数据链路层"></a>(4) 数据链路层</h4><p>不同的网络类型，发送数据的机制不同，数据链路层就是将数据包封装成能够在不同的网络传输的帧。能够进行差错检验，但不纠错，监测出错误丢掉该帧。如果需要改正数据在链路层传输时出现差错（这就是说，数据链路层不仅要检错，而且还要纠错），那么就要采用可靠性传输协议来纠正出现的差错。这种方法会使链路层的协议复杂些。</p><h4 id="5-物理层"><a href="#5-物理层" class="headerlink" title="(5) 物理层"></a>(5) 物理层</h4><p>在物理层上所传送的数据单位是比特。物理层的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。 </p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>在互联网使用的各种协中最重要和最著名的就是 TCP/IP 两个协议。现在人们经常提到的 TCP/IP 并不一定单指 TCP 和 IP 这两个具体的协议，而往往表示互联网所使用的整个 TCP/IP 协议族。</p><h3 id="2-ISO-七层模型中表示层和会话层功能是什么？"><a href="#2-ISO-七层模型中表示层和会话层功能是什么？" class="headerlink" title="2. ISO 七层模型中表示层和会话层功能是什么？"></a>2. ISO 七层模型中表示层和会话层功能是什么？</h3><ul><li><strong>表示层</strong> ：数据压缩、加密以及数据描述。这使得应用程序不必担心在各台主机中表示/存储的内部格式（二进制、ASCII，比如乱码）不同的问题。</li><li><strong>会话层</strong> ：建立会话，如 session 认证、断点续传。通信的应用程序之间建立、维护和释放面向用户的连接。通信的应用程序之间建立会话，需要传输层建立1个或多个连接。</li><li>说明：五层协议没有表示层和会话层，而是将这些功能留给应用程序开发者处理。</li></ul><h4 id="3-数据在各层之间的传递过程"><a href="#3-数据在各层之间的传递过程" class="headerlink" title="3. 数据在各层之间的传递过程"></a>3. 数据在各层之间的传递过程</h4><p>在向下的过程中，需要添加下层协议所需要的首部或者尾部，而在向上的过程中不断拆开首部和尾部。</p><ol><li>路由器只有下面三层协议，因为路由器位于网络核心中，不需要为进程或者应用程序提供服务，因此也就不需要运输层和应用层。</li><li>交换机只有下面两层协议</li></ol><h2 id="二、TCP-三次握手和四次挥手"><a href="#二、TCP-三次握手和四次挥手" class="headerlink" title="二、TCP 三次握手和四次挥手"></a>二、TCP 三次握手和四次挥手</h2><h3 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h3><p><img src="http://qnya.pomo16.club/237.png" alt></p><p>为了准确无误地把数据送达目标处，TCP协议采用了三次握手策略。</p><ol><li>客户端–发送带有 SYN 标志的数据包</li><li>服务端–发送带有 SYN/ACK 标志的数据包</li><li>客户端–发送带有 ACK 标志的数据包</li></ol><h4 id="为什么要三次握手？"><a href="#为什么要三次握手？" class="headerlink" title="为什么要三次握手？"></a>为什么要三次握手？</h4><p>三次握手的目的是建立可靠的通信信道，说到通讯，简单来说就是数据的发送与接收，而三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的。</p><p>第一次握手：Client 什么都不能确认；Server 确认了对方发送正常</p><p>第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己接收正常，对方发送正常</p><p>第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送接收正常</p><p>所以三次握手就能确认双发收发功能都正常，缺一不可。</p><h4 id="为什么要传回-SYN？"><a href="#为什么要传回-SYN？" class="headerlink" title="为什么要传回 SYN？"></a>为什么要传回 SYN？</h4><p>接收端传回发送端所发送的 SYN 是为了告诉发送端，我接收到的信息确实就是你所发送的信号了。</p><h4 id="传了-SYN-为啥还要传-ACK？"><a href="#传了-SYN-为啥还要传-ACK？" class="headerlink" title="传了 SYN,为啥还要传 ACK？"></a>传了 SYN,为啥还要传 ACK？</h4><p>双方通信无误必须是两者互相发送信息都无误。传了 SYN，证明发送方到接收方的通道没有问题，但是接收方到发送方的通道还需要 ACK 信号来进行验证。</p><h3 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h3><p><img src="http://qnya.pomo16.club/238.png" alt></p><blockquote><p>MSL 是 Maximum Segment Lifetime 英文的缩写，中文可以译为 “报文最大生存时间”，他是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。2MSL = 2*2mins = 4mins</p></blockquote><p>断开一个 TCP 连接则需要“四次挥手”。</p><ol><li>客户端-发送一个 FIN，用来关闭客户端到服务器的数据传送</li><li>服务器-收到这个 FIN，它发回一 个 ACK，确认序号为收到的序号加1 。和 SYN 一样，一个 FIN 将占用一个序号</li><li>服务器-关闭与客户端的连接，发送一个 FIN 给客户端</li><li>客户端-发回 ACK 报文确认，并将确认序号设置为收到序号加1</li></ol><h4 id="为什么要四次挥手？"><a href="#为什么要四次挥手？" class="headerlink" title="为什么要四次挥手？"></a>为什么要四次挥手？</h4><p>客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。</p><h4 id="TIME-WAIT"><a href="#TIME-WAIT" class="headerlink" title="TIME_WAIT"></a>TIME_WAIT</h4><p>客户端接收到服务器端的 FIN 报文后进入此状态，此时并不是直接进入 CLOSED 状态，还需要等待一个时间计时器设置的时间 2MSL。这么做有两个理由：</p><ul><li>确保最后一个确认报文段能够到达。如果 B 没收到 A 发送来的确认报文段，那么就会重新发送连接释放请求报文段，A 等待一段时间就是为了处理这种情况的发生。</li><li>等待一段时间是为了让本连接持续时间内所产生的所有报文段都从网络中消失，使得下一个新的连接不会出现旧的连接请求报文段。</li></ul><h2 id="三、TCP-和-UDP-的区别"><a href="#三、TCP-和-UDP-的区别" class="headerlink" title="三、TCP 和 UDP 的区别"></a>三、TCP 和 UDP 的区别</h2><p><img src="http://qnya.pomo16.club/239.png" alt></p><p>UDP 在传送数据之前不需要先建立连接，远地主机在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 确是一种最有效的工作方式（一般用于即时通信），比如： QQ 语音、 QQ 视频 、直播等等。</p><p>TCP 提供面向连接的服务。在传送数据之前必须先建立连接，数据传送结束后要释放连接。 TCP 不提供广播或多播服务。由于 TCP 要提供可靠的，面向连接的运输服务（TCP 的可靠体现在 TCP 在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源），这一难以避免增加了许多开销，如确认，流量控制，计时器以及连接管理等。这不仅使协议数据单元的首部增大很多，还要占用许多处理机资源。TCP 一般用于文件传输、发送和接收邮件、远程登录等场景。</p><h2 id="四、TCP-协议如何保证可靠传输"><a href="#四、TCP-协议如何保证可靠传输" class="headerlink" title="四、TCP 协议如何保证可靠传输"></a>四、TCP 协议如何保证可靠传输</h2><ul><li>应用数据被分割成 TCP 认为最适合发送的数据块。 </li><li>TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。 </li><li>TCP的接收端会丢弃重复的数据。</li><li><strong>校验和：</strong> TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。</li><li><strong>拥塞控制</strong>：当网络拥塞时，减少数据的发送。</li><li><strong>停止等待协议</strong> 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。<strong>超时重传</strong>：当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。</li><li><strong>流量控制</strong>：TCP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。</li></ul><h3 id="停止等待协议"><a href="#停止等待协议" class="headerlink" title="停止等待协议"></a>停止等待协议</h3><ul><li>停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组；</li><li>在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认；</li></ul><p><strong>1. 无差错情况</strong></p><p><img src="http://qnya.pomo16.club/240.png" style="height:400px"></p><p><strong>2. 出现差错情况（超时重传）</strong></p><p><img src="http://qnya.pomo16.club/241.png" alt></p><p>停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重转时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为 <strong>自动重传请求 ARQ</strong> 。另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。<strong>连续 ARQ 协议</strong> 可提高信道利用率。发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。</p><p><strong>3. 确认丢失和确认迟到</strong></p><ul><li><strong>确认丢失</strong>：确认消息在传输过程丢失</li></ul><p><img src="http://qnya.pomo16.club/242.png" alt></p><p>当 A 发送 M1 消息，B 收到后，B 向 A 发送了一个 M1 确认消息，但却在传输过程中丢失。而A 并不知道，在超时计时过后，A 重传 M1 消息，B 再次收到该消息后采取以下两点措施：</p><ol><li>丢弃这个重复的M1消息，不向上层交付。</li><li>向A发送确认消息。（不会认为已经发送过了，就不再发送。A能重传，就证明B的确认消息丢失）。</li></ol><ul><li><strong>确认迟到</strong> ：确认消息在传输过程中迟到</li></ul><p><img src="http://qnya.pomo16.club/243.png" alt></p><p>A 发送 M1 消息，B 收到并发送确认。在超时时间内没有收到确认消息，A 重传 M1 消息，B 仍然收到并继续发送确认消息（B 收到了 2 份 M1）。此时 A 收到了 B 第二次发送的确认消息。接着发送其他数据。过了一会，A 收到了 B 第一次发送的对 M1 的确认消息（A 也收到了2份确认消息）。处理如下：</p><ol><li>A 收到重复的确认后，直接丢弃。</li><li>B 收到重复的 M1 后，也直接丢弃重复的 M1。</li></ol><h3 id="自动重传请求-ARQ-协议"><a href="#自动重传请求-ARQ-协议" class="headerlink" title="自动重传请求 ARQ 协议"></a>自动重传请求 ARQ 协议</h3><p>停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重转时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为自动重传请求 ARQ。</p><p><strong>优点</strong>：简单。</p><p><strong>缺点</strong>：信道利用率低。</p><h3 id="连续-ARQ-协议"><a href="#连续-ARQ-协议" class="headerlink" title="连续 ARQ 协议"></a>连续 ARQ 协议</h3><p>连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。</p><p><strong>优点：</strong> 信道利用率高，容易实现，即使确认丢失，也不必重传。</p><p><strong>缺点：</strong> 不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5条消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。</p><h3 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h3><ul><li>TCP 利用滑动窗口实现流量控制的机制。</li><li>滑动窗口（Sliding window）是一种流量控制技术。早期的网络通信中，通信双方不会考虑网络的拥挤情况直接发送数据。由于大家不知道网络拥塞状况，同时发送数据，导致中间节点阻塞掉包，谁也发不了数据，所以就有了滑动窗口机制来解决此问题。</li><li>TCP 中采用滑动窗口来进行传输控制，滑动窗口的大小意味着接收方还有多大的缓冲区可以用于接收数据。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为 0 时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据，例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个 1 字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。</li></ul><h3 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h3><ul><li>TCP 利用滑动窗口实现流量控制。</li><li>流量控制是为了控制发送方发送速率，保证接收方来得及接收。</li><li>接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。</li></ul><h3 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h3><ul><li>在某段时间，若对网络中某资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏——产生拥塞(congestion)。</li><li>出现资源拥塞的条件：对资源需求的总和 &gt; 可用资源</li><li>若网络中有许多资源同时产生拥塞，网络的性能就要明显变坏，整个网络的吞吐量将随输入负荷的增大而下降。</li><li>拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不致过载。</li><li>拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低网络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。</li></ul><p>为了进行拥塞控制，TCP 发送方要维持一个 <strong>拥塞窗口(cwnd)</strong> 的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。</p><p>TCP 的拥塞控制采用了四种算法，即 <strong>慢开始</strong> 、 <strong>拥塞避免</strong> 、<strong>快重传</strong> 和 <strong>快恢复</strong>。在网络层也可以使路由器采用适当的分组丢弃策略（如主动队列管理 AQM），以减少网络拥塞的发生。</p><ul><li><p>慢开始</p><p>慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么可能会引起网络阻塞，因为现在还不知道网络的符合情况。经验表明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是由小到大逐渐增大拥塞窗口数值。cwnd 初始值为1，每经过一个传播轮次，cwnd 加倍。 </p></li><li><p>拥塞避免</p><p>拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间 RTT 就把发送放的 cwnd 加1。</p></li><li><p>快重传和快恢复</p><p>在 TCP/IP 中，快速重传和恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了，TCP 将会使用定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到一个不按顺序的数据段，它会立即给发送机发送一个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并立即重传这些丢失的数据段。有了 FRR，就不会因为重传时要求的暂停被耽误。  当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地工作。当有多个数据信息包在某一段很短的时间内丢失时，它则不能很有效地工作。 </p></li></ul><h2 id="五、在浏览器中输入url地址-gt-显示主页的过程"><a href="#五、在浏览器中输入url地址-gt-显示主页的过程" class="headerlink" title="五、在浏览器中输入url地址 -&gt; 显示主页的过程"></a>五、在浏览器中输入url地址 -&gt; 显示主页的过程</h2><p><img src="http://qnya.pomo16.club/244.png" alt></p><h2 id="六、状态码"><a href="#六、状态码" class="headerlink" title="六、状态码"></a>六、状态码</h2><table><thead><tr><th></th><th>类别</th><th>原因短语</th></tr></thead><tbody><tr><td>1xx</td><td>Informational (信息性状态码)</td><td>接收的请求正在处理</td></tr><tr><td>2xx</td><td>Success (成功状态码)</td><td>请求正常处理完毕</td></tr><tr><td>3xx</td><td>Redirection (重定向状态码)</td><td>需要进行附加操作以完成请求</td></tr><tr><td>4xx</td><td>Client Error (客户端错误状态码)</td><td>服务器无法处理请求</td></tr><tr><td>5xx</td><td>Server Error (服务器错误状态码)</td><td>服务器处理请求出错</td></tr></tbody></table><p>详见博文 <a href="[https://pomo16.github.io/2018/11/19/HTTP%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E7%8A%B6%E6%80%81%E7%A0%81/](https://pomo16.github.io/2018/11/19/HTTP中常用的状态码/">HTTP中常用的状态码</a>)</p><h2 id="七、各协议与-HTTP-协议之间的关系"><a href="#七、各协议与-HTTP-协议之间的关系" class="headerlink" title="七、各协议与 HTTP 协议之间的关系"></a>七、各协议与 HTTP 协议之间的关系</h2><p><img src="http://qnya.pomo16.club/245.png" alt></p><h2 id="八、HTTP-的长连接和短连接"><a href="#八、HTTP-的长连接和短连接" class="headerlink" title="八、HTTP 的长连接和短连接"></a>八、HTTP 的长连接和短连接</h2><p>在 HTTP/1.0 中默认使用短连接。也就是说，客户端和服务器每进行一次 HTTP 操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个 HTML 或其他类型的 Web 页中包含有其他的 Web 资源（如 JavaScript 文件、图像文件、CSS 文件等），每遇到这样一个 Web 资源，浏览器就会重新建立一个 HTTP 会话。</p><p>而从 HTTP/1.1 起，默认使用长连接，用以保持连接特性。使用长连接的 HTTP 协议，会在响应头加入这行代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Connection:keep-alive</span><br></pre></td></tr></table></figure><p>在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输 HTTP 数据的 TCP 连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。 Keep-Alive 不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如 Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。</p><p><strong>HTTP 协议的长连接和短连接，实质上是 TCP 协议的长连接和短连接。</strong></p><h2 id="九、HTTP-和-HTTPS-的区别"><a href="#九、HTTP-和-HTTPS-的区别" class="headerlink" title="九、HTTP 和 HTTPS 的区别"></a>九、HTTP 和 HTTPS 的区别</h2><ul><li>https 协议需要到 ca 申请证书，一般免费证书较少，因而需要一定费用。</li><li>http 是超文本传输协议，信息是明文传输，https 则是具有安全性的 ssl 加密传输协议。</li><li>http 和 https 使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。</li><li>http 的连接很简单，是无状态的；https 协议是由 SSL + http 协议构建的可进行加密传输、身份认证的网络协议，比 http 协议安全。</li></ul><h2 id="十、SSL-的四次握手"><a href="#十、SSL-的四次握手" class="headerlink" title="十、SSL 的四次握手"></a>十、SSL 的四次握手</h2><ol><li><p>客户端请求建立 SSL 链接，并向服务端发送一个随机数（client random）和客户端支持的加密方法（比如 RSA），此时是明文传输的。 </p></li><li><p>服务端选择客户端支持的一种加密算法并生成另一个随机数（server random），并将授信的服务端证书和公钥下发给客户端。 </p></li><li><p>客户端收到服务端的回复，会校验服务端证书的合法性，若合法，则生成一个新的随机数 premaster secret 并通过服务端下发的公钥及加密方法进行加密，然后发送给服务端。 </p></li><li><p>服务端收到客户端的回复，利用已知的加解密方式进行解密，同时利用 client random、server random 和 premater secret 通过一定算法生成对称加密 key - session key。</p></li></ol><p>此后，数据传输即通过对称加密方式进行加密传输。 </p><p>从以上过程可以看到 https 实际上是用了对称加密技术和非对称加密技术，非对称加密解密速度慢，但安全性高，用来加密对称加密的密钥；而对称加密虽然安全性低，但解密速度快，可以用于传输数据的加密。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;总结自 &lt;a href=&quot;https://juejin.im/post/5b7be0b2e51d4538db34a51e&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SnailClimb&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/frank-lam/fullstack-tutorial/blob/master/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.md#5-tcp%E5%92%8Cudp%E5%8C%BA%E5%88%AB%E5%A6%82%E4%BD%95%E6%94%B9%E8%BF%9Btcp&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;frank-lam&lt;/a&gt; 的博文。&lt;/p&gt;
    
    </summary>
    
      <category term="web" scheme="http://yoursite.com/categories/web/"/>
    
    
      <category term="http" scheme="http://yoursite.com/tags/http/"/>
    
  </entry>
  
  <entry>
    <title>Spring 基础知识</title>
    <link href="http://yoursite.com/2019/06/09/Spring-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <id>http://yoursite.com/2019/06/09/Spring-基础知识/</id>
    <published>2019-06-09T15:59:52.000Z</published>
    <updated>2019-06-11T06:27:27.236Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Spring-IOC-和-AOP"><a href="#Spring-IOC-和-AOP" class="headerlink" title="Spring IOC 和 AOP"></a>Spring IOC 和 AOP</h2><p>Spring 的 IOC 容器是 Spring 的核心，Spring AOP 是 Spring 框架的重要组成部分。</p><h4 id="IOC"><a href="#IOC" class="headerlink" title="IOC"></a>IOC</h4><p><strong>1. IOC 是什么？</strong></p><ul><li>IOC (Inversion Of Control)控制反转，包含了两个方面：控制和反转<ul><li>控制：当前对象对内部成员的控制权。</li><li>反转：这种控制权不由当前对象管理了，由其他(类,第三方容器)来管理。</li></ul></li><li>IOC 的意思是控件反转也就是由容器控制程序之间的关系，这也是 Spring 的优点所在，把控件权交给了外部容器，之前的写法，由程序代码直接操控，而现在控制权由应用代码中转到了外部容器，控制权的转移是所谓反转。换句话说之前用 new 的方式获取对象，现在由 Spring 给你，至于怎么给你就是 DI 了。</li><li>IOC 容器是 Spring 用来实现 IOC 的载体， IOC 容器实际上就是个 Map（key，value），Map 中存放的是各种对象。</li></ul><p><strong>2. IOC 实现原理</strong></p><ul><li>创建 xml 配置文件，配置要创建的对象类。</li><li>通过反射创建实例。</li><li><p>获取需要注入的接口实现类并将其赋值给该接口。</p><p><strong>3. 优点</strong></p></li><li><p>解耦合，开发更方便组织分工</p></li><li>高层不依赖于底层（依赖倒置）</li><li>让应用更容易测试</li><li>因为把对象生成放在了 XML 里定义，所以当我们需要换一个实现子类将会变成很简单（一般这样的对象都是实现于某种接口的），只要修改 XML 就可以了，这样我们甚至可以实现对象的热插拨</li></ul><h4 id="AOP"><a href="#AOP" class="headerlink" title="AOP"></a>AOP</h4><p><strong>1. AOP是什么？</strong></p><ul><li>AOP（Aspect Oriented Programming ）称为面向切面编程，扩展功能不是修改源代码实现，在程序开发中主要用来解决一些系统层面上的问题，比如日志，事务，权限等待，Struts2 的拦截器设计就是基于 AOP 的思想，是个比较经典的例子。</li><li>面向切面编程（aop）是对面向对象编程（oop）的补充。</li><li>面向切面编程提供声明式事务管理。</li><li>AOP就是典型的代理模式的体现。</li></ul><p><strong>2. AOP 实现原理</strong></p><ul><li>动态代理（利用<strong>反射和动态编译</strong>将代理模式变成动态的）</li><li>JDK 的动态代理<ul><li>JDK 内置的 Proxy 动态代理可以在运行时动态生成字节码，而没必要针对每个类编写代理类</li><li>JDK Proxy 返回动态代理类，是目标类所实现接口的另一个实现版本，它实现了对目标类的代理（如同 UserDAOProxy 与 UserDAOImp 的关系）</li></ul></li><li>cglib动态代理<ul><li>CGLibProxy 返回的动态代理类，则是目标代理类的一个子类（代理类扩展了 UserDaoImpl 类）</li><li>cglib 继承被代理的类，重写方法，织入通知，动态生成字节码并运行</li></ul></li><li>两种实现的区别<ul><li>JDK 动态代理只能对实现了接口的类生成代理，而不能针对类</li><li>cglib 是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法因为是继承，所以该类或方法最好不要声明成 final</li><li>JDK 代理是不需要以来第三方的库，只要 JDK 环境就可以进行代理</li><li>cglib 必须依赖于 cglib 的类库，但是它需要类来实现任何接口代理的是指定的类生成一个子类，覆盖其中的方法，是一种继承</li></ul></li></ul><p><strong>3. 优点</strong></p><ul><li>各个步骤之间的良好隔离性</li><li>源代码无关性</li><li>松耦合</li><li>易扩展</li><li>代码复用</li></ul><h2 id="依赖注入"><a href="#依赖注入" class="headerlink" title="依赖注入"></a>依赖注入</h2><p><strong>DI 是什么？</strong></p><p>DI(Dependency Injection) ，即依赖注入，是 Spring 中实现 IOC 的方式。所谓依赖注入，就是把底层类作为参数传入上层类，实现上层类对下层类的控制。DI 依赖注入，向类里面属性注入值 ，依赖注入不能单独存在，需要在 IOC 基础上完成操作。</p><p><strong>3种注入方式（使用注解）</strong></p><ul><li><p>field 注入，简单易用，但可能会出现依赖循环，且无法适用于 IOC 容器以外的环境。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FooController</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Autowired</span></span><br><span class="line">  <span class="comment">//@Inject</span></span><br><span class="line">  <span class="keyword">private</span> FooService fooService;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">//简单的使用例子，下同</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> List&lt;Foo&gt; <span class="title">listFoo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> fooService.list();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>使用 setter 方法注入，比构造器注入轻量，另外 setter 方式能让类在之后重新配置或重新注入。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FooController</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">private</span> FooService fooService;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">//使用方式上同，略</span></span><br><span class="line">  <span class="meta">@Autowired</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setFooService</span><span class="params">(FooService fooService)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.fooService = fooService;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>使用构造器注入，Spring 官方建议使用构造器注入，因为其能保证<strong>组件不可变</strong>，并且确保需要的<strong>依赖不为空</strong>。此外，构造器注入的依赖总是能够在返回客户端（组件）代码的时候保证<strong>完全初始化的状态</strong>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Controller</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FooController</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> FooService fooService;</span><br><span class="line">  </span><br><span class="line">  <span class="meta">@Autowired</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">FooController</span><span class="params">(FooService fooService)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.fooService = fooService;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">//使用方式上同，略</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="Spring-IOC-初始化过程"><a href="#Spring-IOC-初始化过程" class="headerlink" title="Spring IOC 初始化过程"></a>Spring IOC 初始化过程</h2><p><img src="http://qnya.pomo16.club/233.png" alt></p><ol><li>Resource 资源定位。这个 Resouce 指的是 BeanDefinition 的资源定位。这个过程就是容器找数据的过程，就像水桶装水需要先找到水一样。</li><li><p>BeanDefinition 的载入过程。这个载入过程是把用户定义好的 Bean 表示成 IOC 容器内部的数据结构，而这个容器内部的数据结构就是 BeanDefition。</p></li><li><p>向 IOC 容器注册这些 BeanDefinition 的过程，这个过程就是将前面的 BeanDefition 保存到 HashMap 中的过程。</p></li></ol><h2 id="Spring-AOP-的使用"><a href="#Spring-AOP-的使用" class="headerlink" title="Spring AOP 的使用"></a>Spring AOP 的使用</h2><p>AOP（Aspect Oriented Programming ）称为面向切面编程，扩展功能不是修改源代码实现，在程序开发中主要用来解决一些系统层面上的问题，比如日志，事务，权限等待， Struts2 的拦截器设计就是基于 AOP 的思想，是个比较经典的例子。</p><ul><li><strong>Joinpoint</strong>（连接点）：类里面可以被增强的方法，这些方法称为连接点</li><li><strong>Pointcut</strong>（切入点）：所谓切入点是指我们要对哪些 Joinpoint 进行拦截的定义</li><li><strong>Advice</strong>（通知/增强）：所谓通知是指拦截到 Joinpoint 之后所要做的事情就是通知。通知分为前置通知，后置通知，异常通知，最终通知，环绕通知（切面要完成的功能）</li><li>Aspect（切面）：是切入点和通知（引介）的结合</li><li>Introduction（引介）：引介是一种特殊的通知在不修改类代码的前提下，Introduction可以在运行期为类动态地添加一些方法或 Field</li><li>Target（目标对象）：代理的目标对象（要增强的类）</li><li>Weaving（织入）：是把增强应用到目标的过程，把 advice 应用到 target 的过程</li><li>Proxy（代理）：一个类被 AOP 织入增强后，就产生一个结果代理类</li></ul><p><strong>Spring 的 AOP 常用的是拦截器</strong></p><p>一般拦截器都是实现 HandlerInterceptor，其中有三个方法 preHandle、postHandle、afterCompletion。</p><ol><li>preHandle：执行 controller 之前执行</li><li>postHandle：执行完 controller，return modelAndView 之前执行，主要操作 modelAndView 的值</li><li>afterCompletion：controller 返回后执行</li></ol><h2 id="Spring-的事务管理"><a href="#Spring-的事务管理" class="headerlink" title="Spring 的事务管理"></a>Spring 的事务管理</h2><p>事务管理可以帮助我们保证数据的一致性，对应企业的实际应用很重要。</p><p>Spring 的事务机制包括声明式事务和编程式事务。</p><ul><li><strong>编程式事务管理</strong>：Spring 推荐使用 TransactionTemplate，实际开发中使用声明式事务较多。</li><li><strong>声明式事务管理</strong>：将我们从复杂的事务处理中解脱出来，获取连接，关闭连接、事务提交、回滚、异常处理等这些操作都不用我们处理了，Spring 都会帮我们处理。</li></ul><p>声明式事务管理使用了 AOP 面向切面编程实现的，本质就是在目标方法执行前后进行拦截。在目标方法执行前加入或创建一个事务，在执行方法执行后，根据实际情况选择提交或是回滚事务。</p><p><strong>如何使用？</strong></p><p>Spring 事务管理主要包括3个接口，Spring 的事务主要是由它们(PlatformTransactionManager，TransactionDefinition，TransactionStatus)三个共同完成的。</p><ol><li><p>PlatformTransactionManager：事务管理器，主要用于平台相关事务的管理。</p><p>主要有三个方法：commit 事务提交；rollback 事务回滚；getTransaction 获取事务状态。</p></li><li><p>TransactionDefinition：事务定义信息，用来定义事务相关的属性，给事务管理器 PlatformTransactionManager 使用。</p><p>该接口有四个主要方法：</p><ul><li>getIsolationLevel：获取隔离级别；</li><li>getPropagationBehavior：获取传播行为；</li><li>getTimeout：获取超时时间；</li><li>isReadOnly：是否只读（保存、更新、删除时属性变为false–可读写，查询时为true–只读）</li></ul><p>事务管理器能够根据这个返回值进行优化，这些事务的配置信息，都可以通过配置文件进行配置。</p></li><li><p>TransactionStatus：事务具体运行状态，事务管理过程中，每个时间点事务的状态信息。</p><p>一些方法：</p><ul><li>hasSavepoint()：返回这个事务内部是否包含一个保存点</li><li>isCompleted()：返回该事务是否已完成，也就是说，是否已经提交或回滚</li><li>isNewTransaction()：判断当前事务是否是一个新事务</li></ul></li></ol><p><strong>声明式事务的优缺点</strong>：</p><ul><li><strong>优点</strong>：不需要在业务逻辑代码中编写事务相关代码，只需要在配置文件配置或使用注解（@Transaction），这种方式没有侵入性。</li><li><strong>缺点</strong>：声明式事务的最细粒度作用于方法上，如果像代码块也有事务需求，只能变通下，将代码块变为方法。</li></ul><h2 id="Spring-事务隔离级别及传播行为"><a href="#Spring-事务隔离级别及传播行为" class="headerlink" title="Spring 事务隔离级别及传播行为"></a>Spring 事务隔离级别及传播行为</h2><h4 id="传播行为"><a href="#传播行为" class="headerlink" title="传播行为"></a>传播行为</h4><p>事务的第一个方面是传播行为。传播行为定义关于客户端和被调用方法的事务边界。Spring 定义了7中传播行为。</p><p><strong>支持当前事务的情况：</strong></p><ul><li><strong>TransactionDefinition.PROPAGATION_REQUIRED：</strong> 如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。</li><li><strong>TransactionDefinition.PROPAGATION_SUPPORTS：</strong> 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。</li><li><strong>TransactionDefinition.PROPAGATION_MANDATORY：</strong> 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。（mandatory：强制性）</li></ul><p><strong>不支持当前事务的情况：</strong></p><ul><li><strong>TransactionDefinition.PROPAGATION_REQUIRES_NEW：</strong> 创建一个新的事务，如果当前存在事务，则把当前事务挂起。</li><li><strong>TransactionDefinition.PROPAGATION_NOT_SUPPORTED：</strong> 以非事务方式运行，如果当前存在事务，则把当前事务挂起。</li><li><strong>TransactionDefinition.PROPAGATION_NEVER：</strong> 以非事务方式运行，如果当前存在事务，则抛出异常。</li></ul><p><strong>其他情况：</strong></p><ul><li><strong>TransactionDefinition.PROPAGATION_NESTED：</strong> 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于 TransactionDefinition.PROPAGATION_REQUIRED。</li></ul><h4 id="隔离级别"><a href="#隔离级别" class="headerlink" title="隔离级别"></a>隔离级别</h4><table><thead><tr><th>隔离级别</th><th>含义</th></tr></thead><tbody><tr><td>ISOLATION_DEFAULT</td><td>使用后端数据库默认的隔离级别。</td></tr><tr><td>ISOLATION_READ_UNCOMMITTED</td><td>允许读取尚未提交的更改。可能导致脏读、幻影读或不可重复读。</td></tr><tr><td>ISOLATION_READ_COMMITTED</td><td>允许从已经提交的并发事务读取。可防止脏读，但幻影读和不可重复读仍可能会发生。</td></tr><tr><td>ISOLATION_REPEATABLE_READ</td><td>对相同字段的多次读取的结果是一致的，除非数据被当前事务本身改变。可防止脏读和不可重复读，但幻影读仍可能发生。</td></tr><tr><td>ISOLATION_SERIALIZABLE</td><td>完全服从 ACID 的隔离级别，确保不发生脏读、不可重复读和幻影读。这在所有隔离级别中也是最慢的，因为它通常是通过完全锁定当前事务所涉及的数据表来完成的。</td></tr></tbody></table><h2 id="Spring-中的-Bean"><a href="#Spring-中的-Bean" class="headerlink" title="Spring 中的 Bean"></a>Spring 中的 Bean</h2><h4 id="如何创建-Spring-容器？"><a href="#如何创建-Spring-容器？" class="headerlink" title="如何创建 Spring 容器？"></a>如何创建 Spring 容器？</h4><p>容器是 Spring 的核心，在基于 Spring 的应用里，应用对象生存于 Spring 容器中。容器负责创建对象，装配它们，配置它们并管理它们的整个生命周期，从生存到死亡（类似从 new 到 finalize() ）。Spring 可以归为两种不同的类型：</p><ul><li>bean 工厂(由 org.springframework.beans.factory.BeanFactory 接口定义)是最简单的容器，提供基本的 DI 功能。</li><li>应用上下文(由 org.springframework.context.ApplicationContext 接口定义)基于 BeanFactory 构建，并提供应用框架级别的服务，例如从属性文件解析文本信息以及发布应用事件给感兴趣的事件监听者。</li></ul><p>一般来说，bean 工厂太低级了，应用上下文的使用更为广泛。</p><p><strong>使用应用上下文</strong></p><p>常见五种类型：</p><ul><li><p>AnnotationConfigApplicationContext：从一个或多个基于 java 的配置类中加载 Spring 应用上下文</p></li><li><p>AnnotationConfigWebApplicationContext：从一个或多个基于 java 的配置类中加载Spring Web 应用上下文</p></li><li><p>ClassPathXmlApplicationContext：从路径下的一个或多个 XML 配置文件中加载上下文定义，把应用上下文的定义文件作为类资源</p></li><li><p>FileSystemXmlApplicationContext：从文件系统下的一个或多个 XML 配置文件中加载上下文定义</p></li><li><p>XmlWebApplicationContext：从 Web 应用下的一个或多个 XML 配置文件中加载上下文定义</p></li></ul><p><strong>ApplicationContext 上下文的生命周期</strong></p><ol><li>实例化一个 Bean，也就是我们通常说的 new；</li><li>按照 Spring 上下文对实例化的 Bean 进行配置，也就是 IOC 注入</li><li>如果这个 Bean 实现了 BeanNameAware 接口，会调用它实现的 setBeanName(String beanId) 方法，此处传递的是 Spring 配置文件中 Bean 的 ID</li><li>如果这个 Bean 实现了 BeanFactoryAware 接口，会调用它实现的 setBeanFactory() ，传递的是 Spring 工厂本身（可以用这个方法获取到其他 Bean）</li><li>如果这个 Bean 实现了 ApplicationContextAware 接口，会调用 setApplicationContext(ApplicationContext) 方法，传入 Spring 上下文，该方式同样可以实现步骤4，但比4更好，因为 ApplicationContext 是 BeanFactory 的子接口，有更多的实现方法</li><li>如果这个 Bean 关联了 BeanPostProcessor 接口，将会调用postProcessBeforeInitialization(Object obj, String s) 方法，BeanPostProcessor 经常被用作是 Bean 内容的更改，并且由于这个是在 Bean 初始化结束时调用 After 方法，也可用于内存或缓存技术</li><li>如果这个 Bean 在 Spring 配置文件中配置了 init-method 属性会自动调用其配置的初始化方法</li><li>如果这个 Bean 关联了 BeanPostProcessor 接口，将会调用 postAfterInitialization(Object obj, String s) 方法；</li></ol><p>注意：以上工作完成以后就可以用这个 Bean 了，那这个 Bean 是一个 single 的，所以一般情况下我们调用同一个 ID 的 Bean 会是在内容地址相同的实例</p><ol start="9"><li><p>当 Bean 不再需要时，会经过清理阶段，如果 Bean 实现了 DisposableBean 接口，会调用其实现的 destroy 方法</p></li><li><p>最后，如果这个 Bean 的 Spring 配置中配置了 destroy-method 属性，会自动调用其配置的销毁方法</p></li></ol><p>以上10步骤可以作为面试或者笔试的模板，另外这里描述的是应用 Spring 上下文 Bean 的生命周期，如果应用 Spring 的工厂也就是 BeanFactory 的话去掉第5步就Ok了。</p><h4 id="Bean-生命周期"><a href="#Bean-生命周期" class="headerlink" title="Bean 生命周期"></a>Bean 生命周期</h4><p><img src="http://qnya.pomo16.club/234.png" alt></p><ol><li>Spring 对 Bean 进行实例化</li><li>Spring 将值和 Bean 的引用注入进 Bean 对应的属性中</li><li><strong>如果 Bean 实现了 BeanNameAware 接口</strong>，Spring 将 Bean 的 ID 传递给 setBeanName() 方法</li><li><strong>如果 Bean 实现了 BeanFactoryAware 接口</strong>，Spring 将调用 setBeanFactory(BeanFactory bf) 方法并把 BeanFactory 容器实例作为参数传入<ul><li>实现 BeanFactoryAware 主要目的是为了获取 Spring 容器，如 Bean 通过 Spring 容器发布事件等</li></ul></li><li><strong>如果 Bean 实现了 ApplicationContextAwaer 接口</strong>，Spring 容器将调用 setApplicationContext(ApplicationContext ctx) 方法，将 bean 所在的应用上下文的引用传入进来<ul><li>作用与 BeanFactory 类似都是为了获取 Spring 容器，不同的是 Spring 容器在调用 setApplicationContext 方法时会把它自己作为 setApplicationContext 的参数传入，而 Spring 容器在调用 setBeanFactory 前需要程序员自己指定（注入） setBeanFactory 里的 BeanFactory 参数</li></ul></li><li><strong>如果 Bean 实现了 BeanPostProcessor 接口</strong>，Spring 将调用它们的 postProcessBeforeInitialization() 预初始化方法<ul><li>作用是在 Bean 实例创建成功后对进行增强处理，如对 Bean 进行修改，增加某个功能</li></ul></li><li><strong>如果 Bean 实现了 InitializingBean 接口</strong>，Spring 将调用它们的 afterPropertiesSet() 方法，作用与在配置文件中对 Bean 使用 init-method 声明初始化的作用一样，都是在 Bean 的全部属性设置成功后执行的初始化方法</li><li><strong>如果 Bean 实现了 BeanPostProcessor 接口</strong>，Spring 将调用它们的 postProcessAfterInitialization() 后初始化方法<ul><li>作用与6的一样，只不过6是在 Bean 初始化前执行的，而这个是在 Bean 初始化后执行的，时机不同</li></ul></li><li>经过以上的工作后，Bean 将一直驻留在应用上下文中给应用使用，直到应用上下文被销毁</li><li><strong>如果 Bean 实现了 DispostbleBean 接口</strong>，Spring 将调用它的 destory 方法，作用与在配置文件中对 Bean 使用 destory-method 属性的作用一样，都是在 Bean 实例销毁前执行的方法。</li></ol><h4 id="Bean-实例化的三种方式"><a href="#Bean-实例化的三种方式" class="headerlink" title="Bean 实例化的三种方式"></a>Bean 实例化的三种方式</h4><ul><li>使用类的无参构造创建（此种方式用的最多）</li><li>使用静态工厂创建对象</li><li>使用实例工厂创建对象</li></ul><h4 id="Bean-的作用域"><a href="#Bean-的作用域" class="headerlink" title="Bean 的作用域"></a>Bean 的作用域</h4><table><thead><tr><th>类型</th><th>说明</th></tr></thead><tbody><tr><td>单例(Singleton)</td><td>在整个应用中，只创建 bean 的一个实例。(默认)</td></tr><tr><td>原型(Prototype)</td><td>每次注入或者通过 Spring 应用上下文获取的时候，都会创建一个新的 bean 的实例。</td></tr><tr><td>会话(Session)</td><td>在 Web 应用中，为每个会话创建一个 bean 实例。</td></tr><tr><td>请求(Request)</td><td>在 Web 应用中，为每个请求创建一个 bean 实例。</td></tr></tbody></table><h4 id="BeanFactory-和-FactoryBean-的区别"><a href="#BeanFactory-和-FactoryBean-的区别" class="headerlink" title="BeanFactory 和 FactoryBean 的区别"></a>BeanFactory 和 FactoryBean 的区别</h4><ul><li><strong>BeanFactory</strong> 是个 Factory，也就是 IOC 容器或对象工厂，在 Spring 中，所有的 Bean 都是由 BeanFactory (也就是 IOC 容器)来进行管理的，提供了实例化对象和拿对象的功能。</li><li><strong>FactoryBean</strong> 是个 Bean，这个 Bean 不是简单的 Bean，而是一个能生产或者修饰对象生成的工厂 Bean，它的实现与设计模式中的工厂模式和修饰器模式类似。</li></ul><h4 id="BeanFactory-和-ApplicationContext-的区别"><a href="#BeanFactory-和-ApplicationContext-的区别" class="headerlink" title="BeanFactory 和 ApplicationContext 的区别"></a>BeanFactory 和 ApplicationContext 的区别</h4><table><thead><tr><th>区别</th><th>BeanFactory</th><th>ApplicationContext</th></tr></thead><tbody><tr><td>功能</td><td>BeanFactory 是 Spring 里面最低层的接口，提供了最简单的容器的功能，只提供了实例化对象和拿对象的功能。BeanFactory 需要在代码中通过手工调用 <code>addBeanPostProcessor()</code> 方法进行注册。</td><td>ApplicationContext 会利用 Java 反射机制自动识别出配置文件中定义的 BeanPostProcessor、 InstantiationAwareBeanPostProcessor 和 BeanFactoryPostProcessor 后置器，并自动将它们注册到应用上下文中。</td></tr><tr><td>装载 Bean</td><td>BeanFactory 在初始化容器的时候并未实例化 Bean，直到第一次访问某个 Bean 时才实例化目标 Bean。</td><td>ApplicationContext 在初始化应用上下文的时候就实例化所有单实例的 Bean。</td></tr></tbody></table><p><strong>我们该用 BeanFactory 还是 ApplicationContent ？</strong></p><p><strong>BeanFactory</strong> 延迟实例化的优点：</p><p>应用启动的时候占用资源很少，对资源要求较高的应用，比较有优势，而且通过 Bean 工厂创建的 bean 生命周期会简单一些。</p><p>缺点：速度会相对来说慢一些，而且有可能会出现空指针异常的错误。</p><p><strong>ApplicationContext</strong> 不延迟实例化的优点：</p><ul><li>所有的 Bean 在启动的时候都加载，系统运行的速度快。</li><li>在启动的时候所有的 Bean 都加载了，我们就能在系统启动的时候，尽早的发现系统中的配置问题。</li><li>建议 web 应用，在启动的时候就把所有的 Bean 都加载了。</li></ul><p>缺点：把费时的操作放到系统启动中完成，所有的对象都可以预加载，缺点就是消耗服务器的内存。</p><p><strong>ApplicationContext 的其他特点</strong></p><p>除了提供 BeanFactory 所支持的所有功能外，ApplicationContext 还有额外的功能</p><ul><li>默认初始化所有的 Singleton，也可以通过配置取消预初始化。</li><li>继承 MessageSource，因此支持国际化。</li><li>资源访问，比如访问 URL 和文件（ResourceLoader）。</li><li>事件机制，（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的 web 层。</li><li>同时加载多个配置文件。</li><li>消息发送、响应机制（ApplicationEventPublisher）。</li><li>以声明式方式启动并创建 Spring 容器。</li></ul><p>由于 ApplicationContext 会预先初始化所有的 Singleton Bean，于是在系统创建前期会有较大的系统开销，但一旦 ApplicationContext 初始化完成，程序后面获取 Singleton Bean 实例时候将有较好的性能。</p><p>也可以为 bean 设置 lazy-init 属性为 true，即 Spring 容器将不会预先初始化该 bean。</p><h4 id="Spring-中的单例-bean-的线程安全问题了解吗？"><a href="#Spring-中的单例-bean-的线程安全问题了解吗？" class="headerlink" title="Spring 中的单例 bean 的线程安全问题了解吗？"></a>Spring 中的单例 bean 的线程安全问题了解吗？</h4><p>大部分时候我们并没有在系统中使用多线程，所以很少有人会关注这个问题。单例 Bean 存在线程问题，主要是因为当多个线程操作同一个对象的时候，对这个对象的非静态成员变量的写操作会存在线程安全问题。</p><p>常见的有两种解决办法：</p><ol><li>在 Bean 对象中尽量避免定义可变的成员变量（不太现实）。</li><li>在类中定义一个 ThreadLocal 成员变量，将需要的可变成员变量保存在 ThreadLocal 中（推荐的一种方式）。</li></ol><h2 id="Spring中-autowire-和-resourse-关键字的区别"><a href="#Spring中-autowire-和-resourse-关键字的区别" class="headerlink" title="Spring中 autowire 和 resourse 关键字的区别"></a>Spring中 autowire 和 resourse 关键字的区别</h2><p>@Resource 和 @Autowired 都是做 bean 的注入时使用，其实 @Resource 并不是 Spring 的注解，它的包是 javax.annotation.Resource，需要导入，但是 Spring 支持该注解的注入。</p><h4 id="共同点"><a href="#共同点" class="headerlink" title="共同点"></a>共同点</h4><p>两者都可以写在字段和 setter 方法上。两者如果都写在字段上，那么就不需要再写 setter 方法。</p><h4 id="不同点"><a href="#不同点" class="headerlink" title="不同点"></a>不同点</h4><p><strong>@Autowired</strong></p><p>@Autowired 为 Spring 提供的注解，需要导入包 org.springframework.beans.factory.annotation.Autowired; </p><p>只按照 byType 注入。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestServiceImpl</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 下面两种@Autowired只要使用一种即可</span></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> UserDao userDao; <span class="comment">// 用于字段上</span></span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUserDao</span><span class="params">(UserDao userDao)</span> </span>&#123; <span class="comment">// 用于属性的方法上</span></span><br><span class="line">        <span class="keyword">this</span>.userDao = userDao;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>@Autowired 注解是按照类型（byType）装配依赖对象，默认情况下它要求依赖对象必须存在，如果允许 null 值，可以设置它的 required 属性为 false。如果我们想使用按照名称（byName）来装配，可以结合 @Qualifier 注解一起使用。如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestServiceImpl</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="meta">@Qualifier</span>(<span class="string">"userDao"</span>)</span><br><span class="line">    <span class="keyword">private</span> UserDao userDao; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>@Resource</strong></p><p>@Resource 默认按照 byName 自动注入，由 J2EE 提供，需要导入包javax.annotation.Resource。</p><p>@Resource 有两个重要的属性：name 和 type，而 Spring 将@Resource 注解的 name 属性解析为 bean 的名字，而 type 属性则解析为 bean 的类型。所以，如果使用 name 属性，则使用 byName 的自动注入策略，而使用 type 属性时则使用 byType 自动注入策略。如果既不制定 name 也不制定 type 属性，这时将通过反射机制使用 byName 自动注入策略。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestServiceImpl</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 下面两种@Resource只要使用一种即可</span></span><br><span class="line">    <span class="meta">@Resource</span>(name=<span class="string">"userDao"</span>)</span><br><span class="line">    <span class="keyword">private</span> UserDao userDao; <span class="comment">// 用于字段上</span></span><br><span class="line">    </span><br><span class="line">    <span class="meta">@Resource</span>(name=<span class="string">"userDao"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUserDao</span><span class="params">(UserDao userDao)</span> </span>&#123; <span class="comment">// 用于属性的setter方法上</span></span><br><span class="line">        <span class="keyword">this</span>.userDao = userDao;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注：最好是将 @Resource 放在 setter 方法上，因为这样更符合面向对象的思想，通过 set、get 去操作属性，而不是直接去操作属性。</p><p>@Resource 装配顺序：</p><ol><li>如果同时指定了 name 和 type，则从 Spring 上下文中找到唯一匹配的 bean 进行装配，找不到则抛出异常。</li><li>如果指定了 name，则从上下文中查找名称（id）匹配的 bean 进行装配，找不到则抛出异常。</li><li>如果指定了 type，则从上下文中找到类似匹配的唯一 bean 进行装配，找不到或是找到多个，都会抛出异常。</li><li>如果既没有指定 name，又没有指定 type，则自动按照 byName 方式进行装配；如果没有匹配，则回退为一个原始类型进行匹配，如果匹配则自动装配。</li></ol><p><strong>@Resource 的作用相当于 @Autowired，只不过 @Autowired 按照 byType 自动注入。@Resource 注解的使用性更为灵活，可指定名称，也可以指定类型 ；@Autowired 注解进行装配容易抛出异常，特别是装配的 bean 类型有多个的时候，而解决的办法是需要在增加 @Qualifier 进行限定。</strong></p><h2 id="Spring-常用注解"><a href="#Spring-常用注解" class="headerlink" title="Spring 常用注解"></a>Spring 常用注解</h2><h4 id="一、组件类注解"><a href="#一、组件类注解" class="headerlink" title="一、组件类注解"></a>一、组件类注解</h4><table><thead><tr><th>注解</th><th>作用</th></tr></thead><tbody><tr><td>@Component</td><td>标准一个普通的 Spring Bean 类</td></tr><tr><td>@Repository</td><td>标注一个 DAO 组件类</td></tr><tr><td>@Service</td><td>标注一个业务逻辑组件类</td></tr><tr><td>@Controller</td><td>标注一个控制器组件类</td></tr></tbody></table><p>这些都是注解在平时的开发过程中出镜率极高，@Component、@Repository、@Service、@Controller 实质上属于同一类注解，用法相同，功能相同，区别在于标识组件的类型。@Component 可以代替 @Repository、@Service、@Controller，因为这三个注解是被 @Component 标注的。如下代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Target</span>(&#123;ElementType.TYPE&#125;)</span><br><span class="line"><span class="meta">@Retention</span>(RetentionPolicy.RUNTIME)</span><br><span class="line"><span class="meta">@Documented</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> Controller &#123;</span><br><span class="line">    <span class="function">String <span class="title">value</span><span class="params">()</span> <span class="keyword">default</span> ""</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>注意点</strong></p><ol><li>被注解的 java 类当做 Bean 实例，Bean 实例的名称默认是 Bean 类的首字母小写，其他部分不变。@Service 也可以自定义 Bean 名称，但是必须是唯一的！</li><li>尽量使用对应组件注解的类替换 @Component 注解，在 Spring 未来的版本中，@Controller，@Service，@Repository 会携带更多语义。并且便于开发和维护！</li><li>指定了某些类可作为 Spring Bean 类使用后，最好还需要让 Spring 搜索指定路径，在 Spring 配置文件加入如下配置：</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 自动扫描指定包及其子包下的所有Bean类 --&gt;</span><br><span class="line">&lt;context:component-scan base-<span class="keyword">package</span>=<span class="string">"org.springframework.*"</span>/&gt;</span><br></pre></td></tr></table></figure><h4 id="二、装配bean时常用的注解"><a href="#二、装配bean时常用的注解" class="headerlink" title="二、装配bean时常用的注解"></a>二、装配bean时常用的注解</h4><table><thead><tr><th>注解</th><th>作用</th></tr></thead><tbody><tr><td>@Autowired</td><td>属于 Spring 的 org.springframework.beans.factory.annotation 包下,可用于为类的属性、构造器、方法进行注值</td></tr><tr><td>@Resource</td><td>不属于 Spring 的注解，而是来自于 JSR-250 位于 javax.annotation 包下，使用该 annotation 为目标 bean 指定协作者 Bean</td></tr><tr><td>@PostConstruct</td><td>实现初始化之前的操作</td></tr><tr><td>@PreDestroy</td><td>实现销毁 bean 之前进行的操作</td></tr></tbody></table><p><strong>注意点</strong></p><p>使用 @Resource 也要注意添加配置文件到 Spring，如果没有配置 <code>component-scan</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">context:component-scan</span>&gt;</span> </span><br><span class="line"><span class="comment">&lt;!--&lt;context:component-scan&gt;的使用，是默认激活&lt;context:annotation-config&gt;功能--&gt;</span></span><br></pre></td></tr></table></figure><p>则一定要配置 <code>annotation-config</code></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">context:annotation-config</span>/&gt;</span></span><br></pre></td></tr></table></figure><h4 id="三、-Component-vs-Configuration-and-Bean"><a href="#三、-Component-vs-Configuration-and-Bean" class="headerlink" title="三、@Component vs @Configuration and @Bean"></a>三、@Component vs @Configuration and @Bean</h4><p><strong>@Component vs @Configuration</strong> (类级)</p><p>Spring 的官方团队说 @Component 可以替代 @Configuration 注解，事实上我们看源码也可以发现看到，如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Target</span>(&#123;ElementType.TYPE&#125;)</span><br><span class="line"><span class="meta">@Retention</span>(RetentionPolicy.RUNTIME)</span><br><span class="line"><span class="meta">@Documented</span></span><br><span class="line"><span class="meta">@Component</span>  <span class="comment">//看这里！！！</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> Configuration &#123;</span><br><span class="line">    <span class="function">String <span class="title">value</span><span class="params">()</span> <span class="keyword">default</span> ""</span>;</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>虽然说可以替代但是两个注解之间还是有区别的！</p><p>@Configuration 中所有带 @Bean 注解的方法都会被动态代理，因此调用该方法返回的都是同一个实例。@Configuration 本质上还是 @Component，因此 <code>&lt;context:component-scan/&gt;</code> 或者 <code>@ComponentScan</code> 都能处理 @Configuration 注解的类。</p><p> @Configuration 注解的 bean 都已经变成了<strong>增强的类</strong>。示例：</p><p>@Bean 注解方法执行策略</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyBeanConfig</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Country <span class="title">country</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Country();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> UserInfo <span class="title">userInfo</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> UserInfo(country());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>直接调用 country() 方法返回的是同一个实例，因为注解是 @Configuration 增强版本类，但是如果是变成 @Component 之后，此时返回的就不是一个实例了，每次都会创建一个实例。下例其实 new 了两次 Country：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyBeanConfig</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Country <span class="title">country</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Country();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> UserInfo <span class="title">userInfo</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> UserInfo(country());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不过有一招可以让 @Component 也保证使用同一个实例——那就是用 @Autowired 来注入。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyBeanConfig</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> Country country;</span><br><span class="line"> </span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Country <span class="title">country</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Country();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> UserInfo <span class="title">userInfo</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> UserInfo(country);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>@Configuration 标记的类必须符合下面的要求：</p><ul><li>配置类必须以类的形式提供（不能是工厂方法返回的实例），允许通过生成子类在运行时增强（cglib 动态代理）。</li><li>配置类不能是 final 类（没法动态代理）。</li><li>配置注解通常为了通过 @Bean 注解生成 Spring 容器管理的类，</li><li>配置类必须是非本地的（即不能在方法中声明，不能是 private）。</li><li>任何嵌套配置类都必须声明为 static。</li><li>@Bean 方法可能不会反过来创建进一步的配置类（也就是返回的 bean 如果带有 @Configuration，也不会被特殊处理，只会作为普通的 bean）。</li></ul><p><strong>@Bean</strong> (方法级)</p><p>@Bean 注解主要用于告诉方法，产生一个 Bean 对象，然后这个 Bean 对象交给 Spring 管理。产生这个 Bean 对象的方法 Spring 只会调用一次，随后这个 Spring 将会将这个 Bean 对象放在自己的 IOC 容器中。</p><p>当使用了 @Bean 注解，我们可以连续使用多种定义 bean 时用到的注解，譬如用 @Qualifier 注解定义工厂方法的名称，用 @Scope 注解定义该 bean 的作用域范围，譬如是 singleton 还是 prototype 等。</p><p>Spring 中新的 Java 配置支持的核心就是 @Configuration 注解的类。这些类主要包括 @Bean 注解的方法来为 Spring 的 IOC 容器管理的对象定义实例，配置和初始化逻辑。</p><p>使用 @Configuration 来注解类表示类可以被 Spring 的 IOC 容器所使用，作为 bean 定义的资源。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AppConfig</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> MyService <span class="title">myService</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> MyServiceImpl();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这和 Spring 的 XML 文件中的非常类似。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;beans&gt;</span><br><span class="line">    &lt;bean id=<span class="string">"myService"</span> <span class="class"><span class="keyword">class</span></span>=<span class="string">"com.acme.services.MyServiceImpl"</span>/&gt;</span><br><span class="line">&lt;/beans&gt;</span><br></pre></td></tr></table></figure><p>@Bean 注解扮演了和元素相同的角色。</p><h4 id="四、Spring-MVC模块注解"><a href="#四、Spring-MVC模块注解" class="headerlink" title="四、Spring MVC模块注解"></a>四、Spring MVC模块注解</h4><p><strong>web模块常用到的注解</strong></p><ul><li>@Controller ：表明该类会作为与前端作交互的控制层组件，通过服务接口定义的提供访问应用程序的一种行为，解释用户的输入，将其转换成一个模型然后将试图呈献给用户。Spring MVC 使用 @Controller 定义控制器，它还允许自动检测定义在类路径下的组件（配置文件中配置扫描路径）并自动注册。</li><li>@RequestMapping ： 这个注解用于将 url 映射到整个处理类或者特定的处理请求的方法。可以只用通配符！既可以作用在类级别，也可以作用在方法级别。可以使用 value 属性指定具体路径，也可以用 method 属性标记所接受的请求类型。</li><li>@RequestParam ：将请求的参数绑定到方法中的参数上，有 required 参数，默认情况下，required = true，也就是该参数必须要传。如果该参数可以传可不传，可以配置required = false。</li><li>@PathVariable ： 该注解用于方法修饰方法参数，会将修饰的方法参数变为可供使用的 uri 变量（可用于动态绑定）。</li><li><p>@RequestBody ： 可以将请求体中的 JSON 字符串绑定到相应的 bean 上，当然，也可以将其分别绑定到对应的字符串上。</p></li><li><p>@ResponseBody ： @ResponseBody 与 @RequestBody 类似，它的作用是将返回类型直接输入到 HTTP response body 中。@ResponseBody 在输出 JSON 格式的数据时，会经常用到。</p></li><li>@RestController ：控制器实现了 REST 的 API，只为服务于 JSON，XML 或其它自定义的类型内容，@RestController 用来创建 REST 类型的控制器。@RestController = @Controller + @ResponseBody。</li></ul><h4 id="五、Spring-事务模块注解"><a href="#五、Spring-事务模块注解" class="headerlink" title="五、Spring 事务模块注解"></a>五、Spring 事务模块注解</h4><p><strong>@Transactional</strong></p><p>在处理 dao 层或 service 层的事务操作时，譬如删除失败时的回滚操作。使用 @Transactional 作为注解，但是需要在配置文件激活。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 开启注解方式声明事务 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">tx:annotation-driven</span> <span class="attr">transaction-manager</span>=<span class="string">"transactionManager"</span> /&gt;</span></span><br></pre></td></tr></table></figure><p>举例：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Service</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CompanyServiceImpl</span> <span class="keyword">implements</span> <span class="title">CompanyService</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Autowired</span></span><br><span class="line">  <span class="keyword">private</span> CompanyDAO companyDAO;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Transactional</span>(propagation = Propagation.REQUIRED, readOnly = <span class="keyword">false</span>, rollbackFor = Exception.class)</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">deleteByName</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> result = companyDAO.deleteByName(name);</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th>属性</th><th>作用</th></tr></thead><tbody><tr><td>readOnly</td><td>事务的读写属性，取 true 或者 false，true 为只读，默认为 false</td></tr><tr><td>rollbackFor</td><td>回滚策略，当遇到指定异常时回滚。譬如上例遇到异常就回滚</td></tr><tr><td>timeout</td><td>设置超时时间，单位为秒</td></tr><tr><td>isolation</td><td>设置事务隔离级别，枚举类型，一共五种</td></tr></tbody></table><h2 id="Spring-中用了哪些设计模式"><a href="#Spring-中用了哪些设计模式" class="headerlink" title="Spring 中用了哪些设计模式"></a>Spring 中用了哪些设计模式</h2><p>Spring框架中使用到了大量的设计模式，下面列举了比较有代表性的：</p><ul><li>代理模式：在 AOP 和 remoting 中被用的比较多。</li><li>单例模式：在 Spring 配置文件中定义的 bean 默认为单例模式。</li><li>模板方法：用来解决代码重复的问题。比如: RestTemplate, JmsTemplate, JpaTemplate。</li><li>工厂模式：BeanFactory 用来创建对象的实例。</li><li>适配器：Spring AOP</li><li>装饰器：Spring data hashmapper</li><li>观察者：Spring 时间驱动模型</li><li>回调：Spring ResourceLoaderAware 回调接口</li></ul><h2 id="Spring-MVC的工作原理"><a href="#Spring-MVC的工作原理" class="headerlink" title="Spring MVC的工作原理"></a>Spring MVC的工作原理</h2><p><img src="http://qnya.pomo16.club/235.png" alt></p><ol><li><p>客户端的所有请求都交给前端控制器 DispatcherServlet 来处理，它会负责调用系统的其他模块来真正处理用户的请求。 </p></li><li><p>DispatcherServlet 把请求转发到 HandlerMapping 处理映射器。 </p></li><li><p>找到具体映射之后，生成具体的对象或者拦截对象返回给 DispatcherServlet。</p></li><li><p>DispatcherServlet 请求 HandlerAdapter 适配器执行 Handler。</p></li><li><p>Handler(controller) 执行、调用处理器相应功能处理方法。</p></li><li><p>处理请求完毕后，返回 ModelAndView 给 DispatcherServlet。</p></li><li><p>DispatcherServlet 把 ModelAndView 交给 ViewResolver 视图解析器解析。</p></li><li><p>ViewResolver 视图解析器返回 view 给 DispatcherServlet。</p></li><li><p>DispatcherServlet 根据 view 进行渲染。(把 Model 填进视图)</p></li><li><p>返回响应给用户。</p></li></ol><p><strong>组件及作用</strong></p><ol><li><p>前端控制器 (DispatcherServlet)</p><p>接收请求，响应结果，相当于转发器，中央处理器。负责调用系统的其他模块来真正处理用户的请求。 </p><p>有了 DispatcherServlet 减少了其他组件之间的耦合度</p></li><li><p>处理器映射器 (HandlerMapping)</p><p>作用：根据请求的 url 查找 Handler</p></li><li><p><strong>处理器 (Handler)</strong></p><p>注意：编写 Handler 时按照 HandlerAdapter 的要求去做，这样适配器才可以去正确执行 Handler</p></li><li><p>处理器适配器 (HandlerAdapter)</p><p>作用：按照特定规则（HandlerAdapter要求的规则）执行 Handler。</p></li><li><p>视图解析器 (ViewResolver)</p><p>作用：进行视图解析，根据逻辑视图解析成真正的视图 (View)</p></li><li><p><strong>视图 (View)</strong></p><p>View 是一个接口实现类支持不同的 View 类型（jsp、pdf、图片、json字符串、XML、HTML等等）</p></li></ol><p>注意：只需要程序员开发，处理器和视图。</p><h2 id="Spring-注解的优点"><a href="#Spring-注解的优点" class="headerlink" title="Spring 注解的优点"></a>Spring 注解的优点</h2><ul><li>可以充分利用 Java 的反射机制获取类结构信息，这些信息可以有效减少配置的工作。如使用 JPA 注释配置 ORM 映射时，我们就不需要指定 PO 的属性名、类型等信息，如果关系表字段和 PO 属性名、类型都一致，您甚至无需编写任务属性映射信息——因为这些信息都可以通过 Java 反射机制获取。 </li><li>注释和 Java 代码位于一个文件中，而 XML 配置采用独立的配置文件，大多数配置信息在程序开发完成后都不会调整，如果配置信息和 Java 代码放在一起，有助于增强程序的内聚性。而采用独立的 XML 配置文件，程序员在编写一个功能时，往往需要在程序文件和配置文件中不停切换，这种思维上的不连贯会降低开发效率。 </li><li>编译期校验，错误的注解在编译期间就会报错。注解在java代码中，从而避免了额外的文件维护工作。注解被编译成java字节码，消耗的内存小，读取速度快，往往比xml配置文件解析快几个数量级，利用测试和维护。</li></ul><h2 id="Spring-AOP-和-AspectJ-AOP-有什么区别？"><a href="#Spring-AOP-和-AspectJ-AOP-有什么区别？" class="headerlink" title="Spring AOP 和 AspectJ AOP 有什么区别？"></a>Spring AOP 和 AspectJ AOP 有什么区别？</h2><p><strong>Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。</strong> Spring AOP 基于代理 (Proxying)，而 AspectJ 基于字节码操作 (Bytecode Manipulation)。</p><p>Spring AOP 已经集成了 AspectJ  ，AspectJ  应该算的上是 Java 生态系统中最完整的 AOP 框架了。AspectJ  相比于 Spring AOP 功能更加强大，但是 Spring AOP 相对来说更简单，</p><p>如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比 Spring AOP 快很多。</p>]]></content>
    
    <summary type="html">
    
      记录 Spring 框架必知必会的一些基础知识
    
    </summary>
    
      <category term="java" scheme="http://yoursite.com/categories/java/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="Spring" scheme="http://yoursite.com/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>JavaWeb基础</title>
    <link href="http://yoursite.com/2019/06/07/JavaWeb%E5%9F%BA%E7%A1%80/"/>
    <id>http://yoursite.com/2019/06/07/JavaWeb基础/</id>
    <published>2019-06-07T10:25:39.000Z</published>
    <updated>2019-06-07T10:44:32.837Z</updated>
    
    <content type="html"><![CDATA[<p><a href="#1-什么是-Servlet？">1. 什么是 Servlet？</a></p><p><a href="#2-Servlet-类的继承关系">2. Servlet 类的继承关系</a></p><p><a href="#3-Servlet-实现方式">3. Servlet 实现方式</a></p><p><a href="#4-Tomcat-容器等级">4. Tomcat 容器等级</a></p><p><a href="#5-Servlet-执行流程">5. Servlet 执行流程</a></p><p><a href="#6-Servlet-生命周期">6. Servlet 生命周期</a></p><p><a href="#7-Tomcat-装载-Servlet-的三种情况">7. Tomcat 装载 Servlet 的三种情况</a></p><p><a href="#8-forward-和-redirect">8. forward 和 redirect</a></p><p><a href="#9-Jsp-和-Servlet-的区别">9. Jsp 和 Servlet 的区别</a></p><p><a href="#10-Tomcat-和-Servlet-的联系">10. Tomcat 和 Servlet 的联系</a></p><p><a href="#11-cookie-和-session">11. cookie 和 session</a></p><p><a href="#12-JavaEE-中的三层结构和-MVC">12. JavaEE 中的三层结构和 MVC</a></p><p><a href="#13-RESTful-架构">13. RESTful 架构</a></p><h2 id="1-什么是-Servlet？"><a href="#1-什么是-Servlet？" class="headerlink" title="1. 什么是 Servlet？"></a>1. 什么是 Servlet？</h2><p>Servlet 是在服务器上运行的小程序。一个 servlet 就是一个 Java 类，并且可以通过 “请求—响应” 编程模式来访问的这个驻留在服务器内存里的 servlet 程序。</p><h2 id="2-Servlet-类的继承关系"><a href="#2-Servlet-类的继承关系" class="headerlink" title="2. Servlet 类的继承关系"></a>2. Servlet 类的继承关系</h2><p><img src="http://qnya.pomo16.club/221.png" alt></p><h2 id="3-Servlet-实现方式"><a href="#3-Servlet-实现方式" class="headerlink" title="3. Servlet 实现方式"></a>3. Servlet 实现方式</h2><ul><li><p>实现 javax.servlet.Servlet 接口</p></li><li><p>继承 javax.servlet.GenericServlet 类</p></li><li><p>继承 javax.servlet.http.HttpServlet 类</p><p>通常会去继承 HttpServlet 类来完成 Servlet</p></li></ul><h2 id="4-Tomcat-容器等级"><a href="#4-Tomcat-容器等级" class="headerlink" title="4. Tomcat 容器等级"></a>4. Tomcat 容器等级</h2><p>Tomcat 的容器分为4个等级，Servlet 的容器管理 Context 容器，一个 Context 对应一个 Web 工程。</p><p><img src="http://qnya.pomo16.club/222.png" alt></p><h2 id="5-Servlet-执行流程"><a href="#5-Servlet-执行流程" class="headerlink" title="5. Servlet 执行流程"></a>5. Servlet 执行流程</h2><p>主要描述了从浏览器到服务器，再从服务器到浏览器的整个执行过程。</p><p><strong>1.浏览器请求</strong></p><p><img src="http://qnya.pomo16.club/223.png" alt></p><p>浏览器向服务器请求时，服务器不会直接执行我们的类，而是到 web.xml 里寻找路径名。</p><p>① 浏览器输入访问路径后，携带了请求行，头，体 </p><p>② 根据访问路径找到已注册的 servlet 名称</p><p>③ 根据映射找到对应的 servlet 名 </p><p>④ 根据根据 servlet 名找到我们全限定类名，既我们自己写的类</p><p><strong>2.服务器创建对象</strong></p><p><img src="http://qnya.pomo16.club/224.png" alt></p><p>① 服务器找到全限定类名后，通过反射创建对象，同时也创建了 servletConfig，里面存放了一些初始化信息（注意服务器只会创建一次 servlet 对象，所以 servletConfig 也只有一个）</p><p><strong>3.调用 init 方法</strong></p><p><img src="http://qnya.pomo16.club/225.png" alt></p><p>① 对象创建好之后，首先要执行 init 方法，但是我们发现我们自定义类下没有 init 方法，所以程序会到其父类 HttpServlet 里找</p><p>② 我们发现 HttpServlet 里也没有 init 方法，所以继续向上找，既向其父类 GenericServlet 中继续寻找，在 GenericServlet 中我们发现了 init 方法，则执行 init 方法（对接口 Servlet 中的 init 方法进行了重写）</p><p>注意： 在 GenericServlet 中执行 public void init(ServletConfig config) 方法的时候，又调用了自己无参无方法体的 init() 方法，其目的是为了方便开发者，如果开发者在初始化的过程中需要实现一些功能，可以重写此方法。</p><p><strong>4.调用 service 方法</strong></p><p><img src="http://qnya.pomo16.club/226.png" alt></p><p>接着，服务器会先创建两个对象：ServletRequest 请求对象和 ServletResponse 响应对象，用来封装浏览器的请求数据和封装向浏览器的响应数据</p><p> ① 接着服务器会默认在我们写的类里寻找 service(ServletRequest req, ServletResponse res) 方法，但是 DemoServlet 中不存在，那么会到其父类中寻找 </p><p>② 到父类 HttpServlet 中发现有此方法，则直接调用此方法，并将之前创建好的两个对象传入</p><p>③ 然后将传入的两个参数强转，并调用 HttpServlet 下的另外个 service 方法</p><p>④ 接着执行 <code>service(HttpServletRequest req, HttpServletResponse resp)</code> 方法，在此方法内部进行了判断请求方式，并执行 doGet 和 doPost，但是 doGet 和 doPost 方法已经被我们自己重写了，所以会执行我们重写的方法</p><p>看到这里，你或许有疑问：为什么我们不直接重写 service 方法？ 因为如果重写 service 方法的话，我们需要将强转，以及一系列的安全保护判断重新写一遍，会存在安全隐患。</p><p><strong>4.向浏览器响应</strong></p><p><img src="http://qnya.pomo16.club/227.png" alt></p><h2 id="6-Servlet-生命周期"><a href="#6-Servlet-生命周期" class="headerlink" title="6. Servlet 生命周期"></a>6. Servlet 生命周期</h2><ul><li><strong>加载和实例化</strong>：Servlet 容器负责加载和实例化 Servlet 对象。</li><li><strong>初始化</strong>：<code>void init(ServletConfig servletConfig)</code> Servlet 对象创建之后马上执行的初始化方法，只执行一次。</li><li><strong>请求处理</strong>：<code>void service(ServletRequest servletRequest, ServletResponse servletResponse)</code> 每次处理请求都是在调用这个方法，它会被调用多次</li><li><strong>销毁</strong>：<code>void destroy()</code> 在 Servlet 被销毁之前调用，负责释放 Servlet 对象占用的资源的方法</li></ul><p><strong>服务器执行流程</strong></p><ol><li>Servlet 类由自己编写，但对象由服务器来创建，并由服务器来调用相应的方法。　</li><li>服务器启动时 ( web.xml 中配置 <code>load-on-startup=1</code>，默认为0 ) 或者第一次请求该 Servlet 时，就会初始化一个 Servlet 对象，也就是会执行初始化方法 init(ServletConfig conf)。</li><li>该 Servlet 对象去处理所有客户端请求，在 <code>service(ServletRequest req，ServletResponse res)</code> 方法中执行。</li><li>最后服务器关闭时，才会销毁这个 Servlet 对象，执行 destroy() 方法。</li></ol><p><img src="http://qnya.pomo16.club/228.png" alt></p><p><strong>一些问题</strong></p><p>Servlet 何时创建？ 答：默认第一次访问 Servlet 时创建该对象(调用 init() 方法)</p><p>Servlet何时销毁？答：服务器关闭 Servlet 就销毁了(调用 destroy() 方法)</p><p>每次访问必须执行的方法是什么？答：public void service(ServletRequest arg0, ServletResponse arg1)</p><h2 id="7-Tomcat-装载-Servlet-的三种情况"><a href="#7-Tomcat-装载-Servlet-的三种情况" class="headerlink" title="7. Tomcat 装载 Servlet 的三种情况"></a>7. Tomcat 装载 Servlet 的三种情况</h2><ul><li><p>Servlet 容器启动时自动装载某些 Servlet，实现它只需要在 web.xml 文件中的 <code>&lt;servlet&gt;&lt;/servlet&gt;</code> 之间添加以下代码：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">load-on-startup</span>&gt;</span>1<span class="tag">&lt;/<span class="name">load-on-startup</span>&gt;</span></span><br></pre></td></tr></table></figure><p>其中，数字越小表示优先级越高。启动和关闭 Tomcat：优先级高的先启动也先关闭。</p></li><li><p>客户端首次向某个 Servlet 发送请求。</p></li><li><p>Servlet 类被修改后，Tomcat 容器会重新装载 Servlet。</p></li></ul><h2 id="8-forward-和-redirect"><a href="#8-forward-和-redirect" class="headerlink" title="8. forward 和 redirect"></a>8. forward 和 redirect</h2><p>Servlet 中主要有两种实现跳转的方式：forward 与 redirect 方式。</p><p>forward 是服务器内部的重定向，服务器直接访问目标地址的 URL，把那个 URL 的响应内容读取过来，而客户端并不知道，因此在客户端浏览器的地址栏中不会显示转向后的地址，还是原来的地址。由于在整个定向的过程中用的是同一个 Request，因此 forward 会将 Request 的信息带到被定向的 JSP 或 Servlet 中使用。</p><p>redirect 则是客户端的重定向，是完全的跳转，即客户端浏览器会获取到跳转后的地址，然后重新发送请求，因此浏览器中会显示跳转后的地址。同事，由于这种方式比 forward 方式多了一次网络请求，因此其效率要低于 forward 方式。需要注意的是，客户端的重定向可以通过设置特定的 HTTP 头或改写 JavaScript 脚本实现。</p><p><img src="http://qnya.pomo16.club/229.png" alt></p><p>鉴于以上的区别，一般当 forward 方式可以满足需求时，尽可能地使用 forward 方式。但在有些情况下，例如，需要跳转到下一个其他服务器上的资源，则必须使用 redirect 方式。</p><p><strong>引申：filter的作用是什么？主要实现什么方法？</strong></p><p>filter 使用户可以改变一个 request 并且修改一个 response。filter 不是一个 Servlet，它不能产生一个 response，但它能够在一个 request 到达 Servlet 之前预处理 request，也可以在离开 Servlet 时处理 response。filter 其实是一个 “Servlet Chaining” (Servler 链)。</p><p>一个 filter 的作用包括以下几个方面：</p><ol><li>在 Servlet 被调用之前截获</li><li>在 Servlet 被调用之前检查 Servlet Request</li><li>根据需要修改 Request 头和 Request 数据</li><li>根据需要修改 Response 头和 Response 数据</li><li>在 Servlet 被调用之后截获</li></ol><h2 id="9-Jsp-和-Servlet-的区别"><a href="#9-Jsp-和-Servlet-的区别" class="headerlink" title="9. Jsp 和 Servlet 的区别"></a>9. Jsp 和 Servlet 的区别</h2><p><strong>不同之处在哪？</strong></p><ul><li>Servlet 在 Java 代码中通过 HttpServletResponse 对象动态输出 HTML 内容</li><li>JSP 在静态 HTML 内容中嵌入 Java 代码，Java 代码被动态执行后生成 HTML 内容</li></ul><p><strong>各自的特点</strong></p><ul><li>Servlet 能够很好地组织业务逻辑代码，但是在 Java 源文件中通过字符串拼接的方式生成动态 HTML 内容会导致代码维护困难、可读性差</li><li>JSP 虽然规避了 Servlet 在生成 HTML 内容方面的劣势，但是在 HTML 中混入大量、复杂的业务逻辑同样也是不可取的</li></ul><p><strong>通过 MVC 双剑合璧</strong></p><p>既然 JSP 和 Servlet 都有自身的适用环境，那么能否扬长避短，让它们发挥各自的优势呢？答案是肯定的——MVC(Model-View-Controller)模式非常适合解决这一问题。</p><p>MVC模式（Model-View-Controller）是软件工程中的一种软件架构模式，把软件系统分为三个基本部分：模型（Model）、视图（View）和控制器（Controller）：</p><ul><li>Controller——负责转发请求，对请求进行处理</li><li>View——负责界面显示</li><li>Model——业务功能编写（例如算法实现）、数据库设计以及数据存取操作实现</li></ul><p>在 JSP/Servlet 开发的软件系统中，这三个部分的描述如下所示：</p><p><img src="http://qnya.pomo16.club/230.png" alt></p><ol><li>Web 浏览器发送 HTTP 请求到服务端，被 Controller(Servlet) 获取并进行处理（例如参数解析、请求转发）</li><li>Controller(Servlet) 调用核心业务逻辑——Model部分，获得结果</li><li>Controller(Servlet) 将逻辑处理结果交给 View（JSP），动态输出 HTML 内容</li><li>动态生成的 HTML 内容返回到浏览器显示</li></ol><p>MVC 模式在 Web 开发中的好处是非常明显，它规避了 JSP 与 Servlet 各自的短板，Servlet 只负责业务逻辑而不会通过 out.append() 动态生成 HTML 代码；JSP 中也不会充斥着大量的业务代码。这大大提高了代码的可读性和可维护性。</p><h2 id="10-Tomcat-和-Servlet-的联系"><a href="#10-Tomcat-和-Servlet-的联系" class="headerlink" title="10. Tomcat 和 Servlet 的联系"></a>10. Tomcat 和 Servlet 的联系</h2><p>Tomcat 是 Web 应用服务器，是一个 Servlet/JSP 容器。Tomcat 作为 Servlet 容器，负责处理客户请求，把请求传送给 Servlet，并将 Servlet 的响应传送回给客户。而 Servlet 是一种运行在支持 Java 语言的服务器上的组件。Servlet 最常见的用途是扩展 Java Web 服务器功能，提供非常安全的，可移植的，易于使用的 CGI 替代品。</p><p><img src="http://qnya.pomo16.club/231.png" alt></p><p>① Tomcat 将 HTTP 请求文本接收并解析，然后封装成 HttpServletRequest 类型的 request 对象，所有的 HTTP 头数据读可以通过 request 对象调用对应的方法查询到。</p><p>② Tomcat 同时会要响应的信息封装为 HttpServletResponse 类型的 response 对象，通过设置 response 属性就可以控制要输出到浏览器的内容，然后将 response 交给 tomcat，Tomcat 就会将其变成响应文本的格式发送给浏览器。</p><p>Java Servlet API 是 Servlet 容器(tomcat) 和 servlet 之间的接口，它定义了 serlvet 的各种方法，还定义了 Servlet 容器传送给 Servlet 的对象类，其中最重要的就是 ServletRequest 和 ServletResponse。所以说我们在编写 servlet 时，需要实现 Servlet 接口，按照其规范进行操作。</p><h2 id="11-cookie-和-session"><a href="#11-cookie-和-session" class="headerlink" title="11. cookie 和 session"></a>11. cookie 和 session</h2><h4 id="什么是-cookie？"><a href="#什么是-cookie？" class="headerlink" title="什么是 cookie？"></a>什么是 cookie？</h4><p>Cookie 是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现 Session 的一种方式。通常，它用于告知服务端两个请求是否来自同一浏览器，如保持用户的登录状态。Cookie 使基于无状态的 HTTP 协议记录稳定的状态信息成为了可能。</p><h4 id="什么是-session？"><a href="#什么是-session？" class="headerlink" title="什么是 session？"></a>什么是 session？</h4><p>Session 代表着服务器和客户端一次会话的过程。Session 对象存储特定用户会话所需的属性及配置信息。这样，当用户在应用程序的 Web 页之间跳转时，存储在 Session 对象中的变量将不会丢失，而是在整个用户会话中一直存在下去。当客户端关闭会话，或者 Session 超时失效时会话结束。</p><h4 id="二者区别"><a href="#二者区别" class="headerlink" title="二者区别"></a>二者区别</h4><table><thead><tr><th>区别</th><th>cookie</th><th>session</th></tr></thead><tbody><tr><td>作用范围</td><td>保存在客户端(浏览器)</td><td>保存在服务器端</td></tr><tr><td>存取方式</td><td>只能保存 ASCII</td><td>可以存任意数据类型，一般情况下我们可以在 Session 中保持一些常用变量信息，比如说 UserId 等</td></tr><tr><td>有效期</td><td>可设置为长时间保持，比如我们经常使用的默认登录功能</td><td>一般失效时间较短，客户端关闭或者 Session 超时都会失效</td></tr><tr><td>隐私策略</td><td>存储在客户端，比较容易遭到不法获取</td><td>存储在服务端，安全性相对 Cookie 要好一些</td></tr><tr><td>存储大小</td><td>单个 Cookie 保存的数据不能超过 4K</td><td>可存储数据远高于 Cookie</td></tr></tbody></table><h4 id="为什么需要-cookie-和-session，他们有什么关联？"><a href="#为什么需要-cookie-和-session，他们有什么关联？" class="headerlink" title="为什么需要 cookie 和 session，他们有什么关联？"></a>为什么需要 cookie 和 session，他们有什么关联？</h4><p>说起来为什么需要 Cookie ，这就需要从浏览器开始说起，我们都知道浏览器是没有状态的(HTTP 协议无状态)，这意味着浏览器并不知道是张三还是李四在和服务端打交道。这个时候就需要有一个机制来告诉服务端，本次操作用户是否登录，是哪个用户在执行的操作，那这套机制的实现就需要 Cookie 和 Session 的配合。</p><p><img src="http://qnya.pomo16.club/232.png" alt></p><p>既然服务端是根据 Cookie 中的信息判断用户是否登录，那么如果浏览器中禁止了 Cookie，如何保障整个机制的正常运转。</p><p>第一种方案，每次请求中都携带一个 SessionID 的参数，也可以 Post 的方式提交，也可以在请求的地址后面拼接 <code>xxx?SessionID=123456...</code>。</p><p>第二种方案，Token 机制。Token 机制多用于 App 客户端和服务器交互的模式，也可以用于 Web 端做用户状态管理。</p><p>Token 的意思是“令牌”，是服务端生成的一串字符串，作为客户端进行请求的一个标识。Token 机制和 Cookie 和 Session 的使用机制比较类似。</p><p>当用户第一次登录后，服务器根据提交的用户信息生成一个 Token，响应时将 Token 返回给客户端，以后客户端只需带上这个 Token 前来请求数据即可，无需再次登录验证。</p><h4 id="如何考虑分布式-Session-问题？"><a href="#如何考虑分布式-Session-问题？" class="headerlink" title="如何考虑分布式 Session 问题？"></a>如何考虑分布式 Session 问题？</h4><p>在互联网公司为了可以支撑更大的流量，后端往往需要多台服务器共同来支撑前端用户请求，那如果用户在 A 服务器登录了，第二次请求跑到服务 B 就会出现登录失效问题。</p><p>分布式 Session 一般会有以下几种解决方案：</p><ul><li>Nginx ip_hash 策略，服务端使用 Nginx 代理，每个请求按访问 IP 的 hash 分配，这样来自同一 IP 固定访问一个后台服务器，避免了在服务器 A 创建 Session，第二次分发到服务器 B 的现象。</li><li>Session 复制，任何一个服务器上的 Session 发生改变（增删改），该节点会把这个 Session 的所有内容序列化，然后广播给所有其它节点。</li><li>共享 Session，服务端无状态话，将用户的 Session 等信息使用缓存中间件来统一管理，保障分发到每一个服务器的响应结果都一致。</li></ul><h2 id="12-JavaEE-中的三层结构和-MVC"><a href="#12-JavaEE-中的三层结构和-MVC" class="headerlink" title="12. JavaEE 中的三层结构和 MVC"></a>12. JavaEE 中的三层结构和 MVC</h2><p>做企业应用开发时，经常采用三层架构分层：表示层、业务层、持久层。</p><p>表示层：负责接收用户请求、转发请求、显示数据等。</p><p>业务层：负责组织业务逻辑。</p><p>持久层：负责持久化业务对象。</p><p>这三个分层，每一层都有不同的模式，就是架构模式。<strong>表示层</strong>最常用的架构模式就是 MVC。</p><p>MVC 是<strong>客户端</strong>的一种设计模式，所以他天然就不考虑数据如何存储的问题。作为客户端，只需要解决用户界面、交互和业务逻辑就好了。在 MVC 模式中，View 负责的是用户界面，Controller 负责交互，Model 负责业务逻辑。至于数据如何存储和读取，当然是由 Model 调用服务端的接口来完成。</p><p>在三层架构中，并没有客户端/服务端的概念，所以表示层、业务层的任务其实和 MVC 没什么区别，而持久层在 MVC 里面是没有的。</p><p><strong>总结：MVC = 表示层 + 业务层，但不包括持久层。</strong></p><h2 id="13-RESTful-架构"><a href="#13-RESTful-架构" class="headerlink" title="13. RESTful 架构"></a>13. RESTful 架构</h2><h4 id="什么是REST？"><a href="#什么是REST？" class="headerlink" title="什么是REST？"></a>什么是REST？</h4><p>REST 是所有 Web 应用都应该遵守的架构设计指导原则。 面向资源是 REST 最明显的特征，对于同一个资源的一组不同的操作。对于每个资源只能执行一组有限的操作。（7个HTTP方法：GET/POST/PUT/DELETE/PATCH/HEAD/OPTIONS）</p><h4 id="常用操作"><a href="#常用操作" class="headerlink" title="常用操作"></a>常用操作</h4><table><thead><tr><th>HTTP方法</th><th>功能</th></tr></thead><tbody><tr><td>GET</td><td>select，从服务器取出资源（一项或多项）。</td></tr><tr><td>POST</td><td>create，在服务器新建一个资源。</td></tr><tr><td>PUT</td><td>update，在服务器更新资源（客户端提供改变后的完整资源）。</td></tr><tr><td>DELETE</td><td>delete，从服务器删除资源。</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      总结 Servlet、JSP、Tomcat等一些 web 基础知识。
    
    </summary>
    
      <category term="java" scheme="http://yoursite.com/categories/java/"/>
    
      <category term="jsp" scheme="http://yoursite.com/categories/java/jsp/"/>
    
      <category term="Servlet" scheme="http://yoursite.com/categories/java/jsp/Servlet/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="jsp" scheme="http://yoursite.com/tags/jsp/"/>
    
      <category term="Servlet" scheme="http://yoursite.com/tags/Servlet/"/>
    
  </entry>
  
  <entry>
    <title>秒杀系统服务器优化思路</title>
    <link href="http://yoursite.com/2019/06/01/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BC%98%E5%8C%96%E6%80%9D%E8%B7%AF/"/>
    <id>http://yoursite.com/2019/06/01/秒杀系统服务器优化思路/</id>
    <published>2019-05-31T17:22:35.000Z</published>
    <updated>2019-06-05T14:36:57.626Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、Tomcat-优化-Tomcat8"><a href="#一、Tomcat-优化-Tomcat8" class="headerlink" title="一、Tomcat 优化(Tomcat8)"></a>一、Tomcat 优化(Tomcat8)</h2><h4 id="内存优化-catalina-sh"><a href="#内存优化-catalina-sh" class="headerlink" title="内存优化 catalina.sh"></a>内存优化 catalina.sh</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS=<span class="string">"-server -Xms2048M -Xmx2048M  -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=5  -XX:+PrintGCDetails -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=<span class="variable">$CATALINA_HOME</span>/logs/heap.dump"</span></span><br></pre></td></tr></table></figure><h4 id="并发优化"><a href="#并发优化" class="headerlink" title="并发优化"></a>并发优化</h4><p>参考 ${tomcat}/webapps/docs/config/http.html</p><table><thead><tr><th>主要参数</th><th>作用</th></tr></thead><tbody><tr><td>maxConnections</td><td>最大连接数，The maximum number of connections that the server will accept and process at any given time.</td></tr><tr><td>acceptCount</td><td>最大接收数，The maximum queue length for incoming connection requests when all possible request processing threads are in use.</td></tr><tr><td>maxThreads</td><td>工作线程，The maximum number of request processing threads to be created by this Connector.</td></tr><tr><td>minSpareThreads</td><td>最小空闲的工作线程（初始化线程数），The minimum number of threads always kept running.</td></tr></tbody></table><h4 id="其他优化"><a href="#其他优化" class="headerlink" title="其他优化"></a>其他优化</h4><ol><li><p>参考 ${tomcat}/webapps/docs/config/host.html</p><p>autoDeploy：This flag value indicates if Tomcat should check periodically for new or updated web applications while Tomcat is running.</p></li><li><p>参考 ${tomcat}/webapps/docs/config/http.html</p><p>enableLookups：false</p></li><li><p>参考 ${tomcat}/webapps/docs/config/context.html</p><p>reloadable：false</p></li><li><p>connector：apr优化</p><p>详见 <a href="http://apr.apache.org/" target="_blank" rel="noopener">http://apr.apache.org/</a>，这是一种全新的网络调度模型，打破了传统的 BIO 和 NIO限制。</p><p>注意：开启了 apr 之后，JVM 用到的 native 内存会增大，因此要适当调大 Metaspace 空间，添加 JVM 选项：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-XX:MetaspaceSize=128m</span><br><span class="line">JAVA_OPTS=<span class="string">"-server -Xms2048M -Xmx2048M -XX:MetaspaceSize=128M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=<span class="variable">$CATALINA_HOME</span>/logs/heap.dump"</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="二、nginx-优化"><a href="#二、nginx-优化" class="headerlink" title="二、nginx 优化"></a>二、nginx 优化</h2><p>文档地址：<a href="http://nginx.org/en/docs/" target="_blank" rel="noopener">http://nginx.org/en/docs/</a></p><h4 id="工作线程数和并发连接数"><a href="#工作线程数和并发连接数" class="headerlink" title="工作线程数和并发连接数"></a>工作线程数和并发连接数</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">worker_rlimit_nofile 20480; <span class="comment">#每个进程打开的最大的文件数=worker_connections*2是安全的，受限于操作系统(/etc/security/limits.conf)</span></span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/security/limits.conf</span><br><span class="line">* hard nofile 204800</span><br><span class="line">* soft nofile 204800</span><br><span class="line">* soft core unlimited</span><br><span class="line">* soft stack 204800</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">worker_processes 4; <span class="comment">#cpu,如果nginx单独在一台机器上，一般为核数的1~2倍</span></span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections 10240; <span class="comment">#每一个进程打开的最大连接数，包含了nginx与客户端和upstream之间的连接</span></span><br><span class="line">    multi_accept on; <span class="comment">#可以一次建立多个连接</span></span><br><span class="line">    use epoll;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="操作系统优化"><a href="#操作系统优化" class="headerlink" title="操作系统优化"></a>操作系统优化</h4><p>配置文件 <code>/etc/sysctl.conf</code></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w net.ipv4.tcp_syncookies=1; <span class="comment">#防止一个套接字在有过多试图连接到达时引起过载</span></span><br><span class="line">sysctl-w net.core.somaxconn=1024; <span class="comment">#默认128，连接队列</span></span><br><span class="line">sysctl-w net.ipv4.tcp_fin_timeout=10; <span class="comment">#timewait的超时时间</span></span><br><span class="line">sysctl -w net.ipv4.tcp_tw_reuse=1; <span class="comment">#os直接使用timewait的连接</span></span><br><span class="line">sysctl -w net.ipv4.tcp_tw_recycle=0; <span class="comment">#回收禁用</span></span><br></pre></td></tr></table></figure><h4 id="Keepalive-长连接"><a href="#Keepalive-长连接" class="headerlink" title="Keepalive 长连接"></a>Keepalive 长连接</h4><p>nginx 与 upstream server：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">upstream server_pool&#123;</span><br><span class="line">        server localhost:8080 weight=1 max_fails=2 fail_timeout=30s;</span><br><span class="line">        keepalive 300;  <span class="comment">#300个长连接</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同时要在 location 中设置：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">location /  &#123;</span><br><span class="line">proxy_http_version 1.1;</span><br><span class="line">proxy_set_header Upgrade <span class="variable">$http_upgrade</span>;</span><br><span class="line">proxy_set_header Connection <span class="string">"upgrade"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>客户端与 nginx(默认是打开的)：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">keepalive_timeout 60s; <span class="comment">#长连接的超时时间</span></span><br><span class="line">keepalive_requests 100; <span class="comment">#100个请求之后就关闭连接，可以调大</span></span><br><span class="line">keepalive_disable msie6; <span class="comment">#ie6禁用</span></span><br></pre></td></tr></table></figure><h4 id="启用压缩"><a href="#启用压缩" class="headerlink" title="启用压缩"></a>启用压缩</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">gzip on;</span><br><span class="line">gzip_http_version 1.1;</span><br><span class="line">gzip_disable <span class="string">"MSIE [1-6]\.(?!.*SV1)"</span>;</span><br><span class="line">gzip_proxied any;</span><br><span class="line">gzip_types text/plain text/css application/javascript application/x-javascript application/json application/xml application/vnd.ms-fontobject application/x-font-ttf application/svg+xml application/x-icon;</span><br><span class="line">gzip_vary on; <span class="comment">#Vary: Accept-Encoding</span></span><br><span class="line">gzip_static on; <span class="comment">#如果有压缩好的，直接使用</span></span><br></pre></td></tr></table></figure><h4 id="状态监控"><a href="#状态监控" class="headerlink" title="状态监控"></a>状态监控</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">location = /nginx_status &#123;</span><br><span class="line">stub_status on;</span><br><span class="line">access_log off;</span><br><span class="line">allow &lt;YOURIPADDRESS&gt;;</span><br><span class="line">deny all;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Active connections: 1 </span><br><span class="line">server accepts handled requests</span><br><span class="line"> 17122 17122 34873 </span><br><span class="line">Reading: 0 Writing: 1 Waiting: 0</span><br></pre></td></tr></table></figure><p>Active connections: 当前实时的并发连接数<br>accepts: 收到的总连接数<br>handled: 处理的总连接数<br>requests: 处理的总请求数<br>Reading: 当前有多少个读，读取客户端的请求<br>Writing: 当前有多少个写，向客户端输出<br>Waiting: 当前有多少个长连接 (reading + writing)<br>reading – nginx reads request header<br>writing – nginx reads request body, processes request, or writes response to a client<br>waiting – keep-alive connections, actually it is active - (reading + writing)</p><h4 id="实时请求信息统计-ngxtop"><a href="#实时请求信息统计-ngxtop" class="headerlink" title="实时请求信息统计 ngxtop"></a>实时请求信息统计 ngxtop</h4><p><a href="https://github.com/lebinh/ngxtop" target="_blank" rel="noopener">https://github.com/lebinh/ngxtop</a></p><ol><li><p>安装 python-pip</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install epel-release</span><br><span class="line">yum install python-pip</span><br></pre></td></tr></table></figure></li><li><p>安装 ngxtop</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install ngxtop</span><br></pre></td></tr></table></figure></li><li><p>使用</p><p>指定配置文件：<code>ngxtop -c ./conf/nginx.conf</code></p><p>查询状态是200：<code>ngxtop -c ./conf/nginx.conf  --filter &#39;status == 200&#39;</code></p><p>查询哪个 ip 访问最多：<code>ngxtop -c ./conf/nginx.conf  --group-by remote_addr</code></p></li></ol><h2 id="三、LVS-四层负载均衡"><a href="#三、LVS-四层负载均衡" class="headerlink" title="三、LVS 四层负载均衡"></a>三、LVS 四层负载均衡</h2><h4 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h4><p>LVS：linux virtual server</p><p>相关文章：</p><p><a href="http://www.linuxvirtualserver.org/" target="_blank" rel="noopener">http://www.linuxvirtualserver.org/</a><br><a href="http://zh.linuxvirtualserver.org/" target="_blank" rel="noopener">http://zh.linuxvirtualserver.org/</a></p><p><a href="http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/" target="_blank" rel="noopener">http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/</a><br><a href="http://www.linuxvirtualserver.org/whatis.html" target="_blank" rel="noopener">http://www.linuxvirtualserver.org/whatis.html</a></p><p><img src="http://qnya.pomo16.club/219.png" style="height:400px;"></p><h4 id="工作模式"><a href="#工作模式" class="headerlink" title="工作模式"></a>工作模式</h4><ol><li>VS/NAT：修改报文头信息</li><li>VS/TUNE：IP隧道</li><li>VS/DR：必须得在同一个网段(一般用这个)</li></ol><h4 id="八种调度算法"><a href="#八种调度算法" class="headerlink" title="八种调度算法"></a>八种调度算法</h4><p>轮询，加权轮询，最小连接，加权最小连接，局部最小连接，带复制的局部最小连接，目标地址散列，原地址散列</p><h2 id="四、Keepalived-高可用"><a href="#四、Keepalived-高可用" class="headerlink" title="四、Keepalived 高可用"></a>四、Keepalived 高可用</h2><p><a href="http://www.keepalived.org/" target="_blank" rel="noopener">http://www.keepalived.org/</a></p><p>Keepalived 双机热备</p><p><img src="http://qnya.pomo16.club/220.png" alt></p>]]></content>
    
    <summary type="html">
    
      谈谈如何通过服务器优化来提高系统负载能力
    
    </summary>
    
      <category term="projects" scheme="http://yoursite.com/categories/projects/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="projects" scheme="http://yoursite.com/tags/projects/"/>
    
  </entry>
  
  <entry>
    <title>BIO,NIO和AIO</title>
    <link href="http://yoursite.com/2019/05/20/BIO-NIO%E5%92%8CAIO/"/>
    <id>http://yoursite.com/2019/05/20/BIO-NIO和AIO/</id>
    <published>2019-05-19T17:30:32.000Z</published>
    <updated>2019-05-19T17:49:52.206Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在 Java 中，有三种 IO 模型: BIO, NIO, AIO。介绍这三种 IO 模型之前，需要介绍一下同步，异步与阻塞，非阻塞的概念，然后再从 Java 和 Linux OS 的角度去分析 BIO, NIO 和 AIO。</p><h2 id="同步和异步"><a href="#同步和异步" class="headerlink" title="同步和异步"></a>同步和异步</h2><h4 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h4><p>同步就是发起一个调用后，<strong>被调用者</strong>未处理完请求之前，调用不返回。</p><h4 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h4><p>异步就是发起一个调用后，立刻得到<strong>被调用者</strong>的回应表示已接收到请求，但是被调用者并没有返回结果，此时我们可以处理其他的请求，被调用者通常<strong>依靠事件，回调</strong>等机制来通知调用者其返回结果。</p><h4 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h4><p>同步与异步最大的区别就是<strong>被调用方</strong>的<strong>执行方式</strong>和<strong>返回时机</strong>，同步指的是<strong>被调用方</strong>做完事情之后再返回，异步指的是<strong>被调用方</strong>先返回，然后再做事情，做完之后再想办法通知调用方。</p><h2 id="阻塞和非阻塞"><a href="#阻塞和非阻塞" class="headerlink" title="阻塞和非阻塞"></a>阻塞和非阻塞</h2><h4 id="阻塞"><a href="#阻塞" class="headerlink" title="阻塞"></a>阻塞</h4><p>阻塞就是发起一个请求，<strong>调用者</strong>一直等待请求结果返回，也就是当前线程会被挂起，无法从事其他任务，只有当条件就绪才能继续。</p><h4 id="非阻塞"><a href="#非阻塞" class="headerlink" title="非阻塞"></a>非阻塞</h4><p>非阻塞就是发起一个请求，<strong>调用者</strong>不用一直等着结果返回，可以先去干其他事情。</p><h2 id="同步、异步和阻塞、非阻塞的区别"><a href="#同步、异步和阻塞、非阻塞的区别" class="headerlink" title="同步、异步和阻塞、非阻塞的区别"></a>同步、异步和阻塞、非阻塞的区别</h2><p>阻塞和同步不是一回事，同步，异步与阻塞，非阻塞针对的对象是不一样的，<strong>阻塞,非阻塞是说的调用者，同步，异步说的是被调用者</strong>。</p><h2 id="BIO、NIO、AIO概览"><a href="#BIO、NIO、AIO概览" class="headerlink" title="BIO、NIO、AIO概览"></a>BIO、NIO、AIO概览</h2><ul><li><strong>BIO(Blocking I/O)</strong>：BIO 也就是传统的同步阻塞 IO 模型，对应 Java.io 包，它提供了很多 IO 功能，比如输入输出流，对文件进行操作。在网络编程( Socket 通信)中也同样进行 IO 操作。</li><li><strong>NIO(New I/O)</strong>: NIO 是一种同步非阻塞的 I/O 模型，在 Java 1.4 中引入了 NIO 框架，对应 java.nio 包，提供了 Channel , Selector，Buffer 等抽象。</li><li><strong>AIO</strong>: AIO 也就是 NIO 2。在 Java 7 中引入了 NIO 的改进版 NIO 2,它是异步非阻塞的 IO 模型。</li></ul><h2 id="Linux的5种-I-O模型"><a href="#Linux的5种-I-O模型" class="headerlink" title="Linux的5种 I/O模型"></a>Linux的5种 I/O模型</h2><p>上面简单介绍了 Java 中的三种 IO 模型，三种模型提供的与 IO 有关的 API，在文件处理时，底层实际上是依赖操作系统层面的 IO 操作实现的，比如在 Linux 2.6 以后，Java 中的 NIO 和 AIO 都是通过 epoll 来实现的，关于 epoll 等概念后面也会阐述。</p><p>而实际上在 Linux(Unix) 操作系统中，共有五种 IO 模型，分别是：<strong>阻塞 IO 模型</strong>、<strong>非阻塞 IO 模型</strong>、<strong>IO 复用模型</strong>、<strong>信号驱动 IO 模型</strong>以及<strong>异步 IO 模型</strong>，而4种都是同步的，只有最后一种是异步的。</p><h4 id="阻塞IO模型-BIO"><a href="#阻塞IO模型-BIO" class="headerlink" title="阻塞IO模型 - BIO"></a>阻塞IO模型 - BIO</h4><p><img src="http://qnya.pomo16.club/213.png" alt></p><p>一个输入操作通常包括两个不同的阶段：</p><ul><li>等待数据准备好</li><li>从内核向进程复制数据</li></ul><p>对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达，当所等待分组到达时，它被复制到内核中的某个缓冲区，第二步就是把数据从内核缓冲区复制到应用进程缓冲区。</p><p>从上图可以看出，<strong>应用进程通过系统调用 <code>recvfrom</code> 去接收数据，而由于内核数据没有准备好，应用进程就会阻塞，直到内核准备好数据并将其从内核复制到应用进程的缓冲区中或者发生错误才返回</strong>。最常见的错误就是系统调用被信号中断。进程从调用 recvfrom 开始到它返回的整段时间内是被阻塞的。</p><p>Linux下的阻塞式 I/O 模型就对应了 Java下的 BIO 模型，BIO 的底层实现是调用操作系统的 API 去执行的，也就是调用操作系统的 Socket 套接字。</p><h4 id="非阻塞式I-O模型-NIO"><a href="#非阻塞式I-O模型-NIO" class="headerlink" title="非阻塞式I/O模型 - NIO"></a>非阻塞式I/O模型 - NIO</h4><p><img src="http://qnya.pomo16.club/214.png" alt></p><p>应用进程通过系统调用 <code>recvfrom</code> 不断的去和内核交互，直到内核数据报准备好，而如果内核无数据准备好，转而立即返回一个 <code>EWOULDBLOCK</code> 的错误，过一段时间再次发送 <code>recvfrom</code> 请求，在此期间进程可以做其他事情，不用一直等待，这就是非阻塞。</p><p>当一个应用进程循环调用 <code>recvfrom</code> 时，我们称之为<strong>轮询(polling)</strong>，应用进程持续轮询内核，以查看某个操作是否就绪。Java 的 NIO 映射到 Linux 操作系统就是如上图所示的非阻塞 I/O  模型。</p><h4 id="I-O复用模型"><a href="#I-O复用模型" class="headerlink" title="I/O复用模型"></a>I/O复用模型</h4><p><img src="http://qnya.pomo16.club/215.png" alt></p><p>IO 多路复用使用 <code>select/poll/epoll</code> 函数，多个进程的 IO 都可以注册在同一个  <code>select</code> 上，当用户进程调用该 <code>select</code> 时，<code>select</code> 去监听所有注册好的 IO,<strong>如果所有被监听的 IO 需要的数据都没有准备好，那么 select 调用进程会被阻塞</strong>，只要任意一个 IO 的数据报套接字变为可读，即数据报已经准备好，<code>select</code> 就返回套接字可读这一条件，然后调用 <code>recvfrom</code> 把所读数据报复制到应用进程缓冲区。</p><p><strong>强调一点就是，IO 多路复用模型并没有涉及到非阻塞</strong>，进程在发出 <code>select</code> 后，要一直阻塞等待其监听的所有 IO 操作至少有一个数据准备好才返回，强调阻塞状态，不存在非阻塞。</p><p>而在 Java NIO 中也可以实现多路复用，主要是利用多路复用器 <strong>Selector</strong>，与这里的 <code>select</code>函数类型，<strong>Selector</strong> 会不断轮询注册在其上的通道 Channel，如果有某一个 Channel 上面发生读或写事件，这个 Channel 处于就绪状态，就会被 Selector 轮询出来。关于 Java NIO 实现多路复用更多的介绍请查询相关文章。</p><p><strong>I/O 多路复用的主要应用场景</strong></p><ul><li>服务器需要同时处理多个处于监听状态或者多个连接状态的套接字</li><li>服务器需要同时处理多种网络协议的套接字</li></ul><p><strong>I/O多路复用的系统调用函数</strong></p><p>目前支持 I/O 多路复用的系统调用函数有 <code>select，pselect，poll，epoll</code>。在 Linux 网络编程中，很长一段时间都使用 <code>select</code> 做轮询和网络事件通知。然而因为 <code>select</code> 的一些固有缺陷导致它的应用受到了很大的限制，比如 <code>select</code> 单个进程打开的最大句柄数是有限的。最终在 Linux 2.6 选择 <code>epoll</code> 替代了 <code>select</code>，Java NIO 和 AIO 底层就是用 <code>epoll</code>。</p><h4 id="信号驱动式I-O模型"><a href="#信号驱动式I-O模型" class="headerlink" title="信号驱动式I/O模型"></a>信号驱动式I/O模型</h4><p><img src="http://qnya.pomo16.club/216.png" alt></p><p>应用进程预先向内核安装一个信号处理函数，然后立即返回，进程继续工作，不阻塞，当数据报准备好读取时，内核就为该进程产生一个信号通知进程，然后进程再调用 <code>recvfrom</code> 读取数据报。</p><p><strong>信号驱动式IO不是异步的</strong></p><p>信号驱动式 IO 在数据准备阶段是异步的，当内核中有数据报准备后再通知进程，但是在调用  <strong>recvfrom</strong> 操作进行数据拷贝时是同步的，所以总体来说，整个 IO 过程不能是异步的。</p><h4 id="异步I-O模型-AIO"><a href="#异步I-O模型-AIO" class="headerlink" title="异步I/O模型 - AIO"></a>异步I/O模型 - AIO</h4><p><img src="http://qnya.pomo16.club/217.png" alt></p><p>应用进程调用 <code>aio_read</code> 函数，给内核传递描述符，缓存区指针，缓存区大小和文件偏移，并告诉内核当整个操作完成时如何通知进程，然后该系统调用立即返回，而且在等待 I/O 完成期间，我们的进程不被阻塞，进程可以去干其他事情，然后内核开始等待数据准备，数据准备好以后再拷贝数据到进程缓冲区，最后通知整个 IO 操作已完成。</p><p>Java 的 AIO 提供了异步通道 API，其操作系统底层实现就是这个异步 I/O 模型。</p><p><strong>与信号驱动式I/O的区别</strong></p><p>主要区别在于: 信号驱动式 I/O 是由内核通知我们何时去启动一个 I/O 操作，而异步 I/O 模型是由内核通知我们 I/O 操作何时完成。</p><h4 id="5种I-O模型的比较"><a href="#5种I-O模型的比较" class="headerlink" title="5种I/O模型的比较"></a>5种I/O模型的比较</h4><p><img src="http://qnya.pomo16.club/218.png" alt></p><p>由上图可以再次看出，IO操作主要分为两个阶段:</p><ul><li>等待数据报准备阶段</li><li>数据拷贝阶段</li></ul><p><strong>前4种 IO 模型都是同步 IO 模型，为什么说都是同步的，因为它们在第二步数据拷贝阶段都是阻塞的，这会导致整个请求进程存在阻塞的情况，所以是同步的，而异步 IO 模型不会导致请求进程阻塞。</strong></p><h2 id="I-O复用的实现"><a href="#I-O复用的实现" class="headerlink" title="I/O复用的实现"></a>I/O复用的实现</h2><p>select/poll/epoll 都是 I/O 多路复用的具体实现，select 出现的最早，之后是 poll，再是 epoll。</p><h4 id="select"><a href="#select" class="headerlink" title="select"></a>select</h4><p>有三种类型的描述符类型：readset、writeset、exceptset，分别对应读、写、异常条件的描述符集合。fd_set 使用数组实现，数组大小使用 FD_SETSIZE 定义。</p><p>timeout 为超时参数，调用 select 会一直阻塞直到有描述符的事件到达或者等待的时间超过 timeout。</p><p>成功调用返回结果大于 0，出错返回结果为 -1，超时返回结果为 0。</p><h4 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h4><p>pollfd 使用链表实现。</p><h4 id="select-和-poll-比较"><a href="#select-和-poll-比较" class="headerlink" title="select 和 poll 比较"></a>select 和 poll 比较</h4><ol><li><p>功能</p><p>select 和 poll 的功能基本相同，不过在一些实现细节上有所不同。</p><ul><li>select 会修改描述符，而 poll 不会；</li><li>select 的描述符类型使用数组实现，FD_SETSIZE 大小默认为 1024，因此默认只能监听 1024 个描述符。如果要监听更多描述符的话，需要修改 FD_SETSIZE 之后重新编译；而 poll 的描述符类型使用链表实现，没有描述符数量的限制；</li><li>poll 提供了更多的事件类型，并且对描述符的重复利用上比 select 高。</li><li>如果一个线程对某个描述符调用了 select 或者 poll，另一个线程关闭了该描述符，会导致调用结果不确定。</li></ul></li><li><p>速度</p><p>select 和 poll 速度都比较慢。</p><ul><li>select 和 poll 每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区。</li><li>select 和 poll 的返回结果中没有声明哪些描述符已经准备好，所以如果返回值大于 0 时，应用进程都需要使用轮询的方式来找到 I/O 完成的描述符。</li></ul></li><li><p>可移植性</p><p>几乎所有的系统都支持 select，但是只有比较新的系统支持 poll。</p></li></ol><h4 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h4><p>epoll_ctl() 用于向内核注册新的描述符或者是改变某个文件描述符的状态。已注册的描述符在内核中会被维护在一棵红黑树上，通过回调函数内核会将 I/O 准备好的描述符加入到一个链表中管理，进程调用 epoll_wait() 便可以得到事件完成的描述符。</p><p>从上面的描述可以看出，epoll 只需要将描述符从进程缓冲区向内核缓冲区拷贝一次，并且进程不需要通过轮询来获得事件完成的描述符。</p><p>epoll 仅适用于 Linux OS。</p><p>epoll 比 select 和 poll 更加灵活而且没有描述符数量限制。</p><p>epoll 对多线程编程更有友好，一个线程调用了 epoll_wait() 另一个线程关闭了同一个描述符也不会产生像 select 和 poll 的不确定情况。</p><h4 id="epoll工作模式"><a href="#epoll工作模式" class="headerlink" title="epoll工作模式"></a>epoll工作模式</h4><p>epoll 的描述符事件有两种触发模式：LT（level trigger）和 ET（edge trigger）。</p><ol><li><p>LT 模式</p><p>当 epoll_wait() 检测到描述符事件到达时，将此事件通知进程，进程可以不立即处理该事件，下次调用 epoll_wait() 会再次通知进程。是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。</p></li><li><p>ET 模式</p><p>和 LT 模式不同的是，通知之后进程必须立即处理事件，下次再调用 epoll_wait() 时不会再得到事件到达的通知。</p><p>很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。只支持 No-Blocking，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。</p></li></ol><h4 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h4><p>很容易产生一种错觉认为只要用 epoll 就可以了，select 和 poll 都已经过时了，其实它们都有各自的使用场景。</p><ol><li><p>select 应用场景</p><p>select 的 timeout 参数精度为 1ns，而 poll 和 epoll 为 1ms，因此 select 更加适用于实时性要求比较高的场景，比如核反应堆的控制。</p><p>select 可移植性更好，几乎被所有主流平台所支持。</p></li><li><p>poll 应用场景</p><p>poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。</p></li><li><p>epoll 应用场景</p><p>只需要运行在 Linux 平台上，有大量的描述符需要同时轮询，并且这些连接最好是长连接。</p><p>需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。</p><p>需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且 epoll 的描述符存储在内核，不容易调试。</p></li></ol>]]></content>
    
    <summary type="html">
    
      介绍这三种Java IO模型，以及Linux的五种IO模型
    
    </summary>
    
      <category term="web" scheme="http://yoursite.com/categories/web/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="IO" scheme="http://yoursite.com/tags/IO/"/>
    
  </entry>
  
  <entry>
    <title>Redis</title>
    <link href="http://yoursite.com/2019/04/27/Redis/"/>
    <id>http://yoursite.com/2019/04/27/Redis/</id>
    <published>2019-04-27T06:39:22.000Z</published>
    <updated>2019-04-27T06:49:45.033Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="#一、概述">一、概述</a></li><li><a href="#二、数据类型">二、数据类型</a></li><li><a href="#三、常用基本操作">三、常用基本操作</a></li><li><a href="#四、配置文件">四、配置文件</a></li><li><a href="#五、持久化">五、持久化</a></li><li><a href="#六、事务">六、事务</a></li><li><a href="#七、发布订阅">七、发布订阅</a></li><li><a href="#八、复制">八、复制</a></li><li><a href="#九、Jedis">九、Jedis</a></li></ul><h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><p>Redis 是速度非常快的非关系型（NoSQL）内存键值数据库，可以存储键和五种不同类型的值之间的映射。</p><p>键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。</p><p>Redis 支持很多特性，例如将内存中的数据持久化到硬盘中，使用复制来扩展读性能，使用分片来扩展写性能。</p><h2 id="二、数据类型"><a href="#二、数据类型" class="headerlink" title="二、数据类型"></a>二、数据类型</h2><table><thead><tr><th>数据类型</th><th>可以存储的值</th><th>操作</th></tr></thead><tbody><tr><td>STRING</td><td>字符串、整数或者浮点数</td><td>对整个字符串或者字符串的其中一部分执行操作 对整数和浮点数执行自增或者自减操作</td></tr><tr><td>LIST</td><td>列表</td><td>从两端压入或者弹出元素  对单个或者多个元素 进行修剪，只保留一个范围内的元素</td></tr><tr><td>SET</td><td>无序集合</td><td>添加、获取、移除单个元素 检查一个元素是否存在于集合中 计算交集、并集、差集 从集合里面随机获取元素</td></tr><tr><td>HASH</td><td>包含键值对的无序散列表</td><td>添加、获取、移除单个键值对 获取所有键值对 检查某个键是否存在</td></tr><tr><td>ZSET</td><td>有序集合</td><td>添加、获取、删除元素 根据分值范围或者成员来获取元素 计算一个键的排名</td></tr></tbody></table><h3 id="string"><a href="#string" class="headerlink" title="string"></a>string</h3><p><img src="http://qnya.pomo16.club/206.png" width="60%"></p><p>string 是 redis 最基本的类型，你可以理解成与 Memcached 一模一样的类型，一个 key 对应一个 value。</p><p>string 类型是二进制安全的。意思是 redis 的 string 可以包含任何数据。比如 jpg 图片或者序列化的对象 。</p><p>string 类型是 Redis 最基本的数据类型，一个 redis 中字符串 value 最多可以是 512M。</p><h3 id="list"><a href="#list" class="headerlink" title="list"></a>list</h3><p><img src="http://qnya.pomo16.club/207.png" width="60%"></p><p>Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素导列表的头部（左边）或者尾部（右边）。它的底层实际是个链表。</p><h3 id="set"><a href="#set" class="headerlink" title="set"></a>set</h3><p><img src="http://qnya.pomo16.club/208.png" width="60%"></p><p>Redis 的 set 是 string 类型的无序集合。它是通过 HashTable 实现实现的。</p><h3 id="hash"><a href="#hash" class="headerlink" title="hash"></a>hash</h3><p><img src="http://qnya.pomo16.club/209.png" width="60%"></p><p>Redis hash 是一个键值对集合。</p><p>Redis hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。</p><p>类似 Java 里面的 Map&lt;String,Object&gt;。</p><h3 id="zset"><a href="#zset" class="headerlink" title="zset"></a>zset</h3><p><img src="http://qnya.pomo16.club/210.png" width="60%"></p><p>sorted set：有序集合。</p><p>Redis zset 和 set 一样也是 string 类型元素的集合,且不允许重复的成员。</p><p>不同的是每个元素都会关联一个 double 类型的分数。</p><p>redis 正是通过分数来为集合中的成员进行从小到大的排序。zset 的成员是唯一的,但分数 (score) 却可以重复。</p><h3 id="Redis常见数据结构操作命令"><a href="#Redis常见数据结构操作命令" class="headerlink" title="Redis常见数据结构操作命令"></a>Redis常见数据结构操作命令</h3><p><a href="http://redisdoc.com/" target="_blank" rel="noopener">http://redisdoc.com/</a></p><h2 id="三、常用基本操作"><a href="#三、常用基本操作" class="headerlink" title="三、常用基本操作"></a>三、常用基本操作</h2><h3 id="key"><a href="#key" class="headerlink" title="key"></a>key</h3><table><thead><tr><th>指令</th><th>作用</th></tr></thead><tbody><tr><td>keys *</td><td>查看所有 key</td></tr><tr><td>exists key的名字</td><td>判断某个 key 是否存在</td></tr><tr><td>move key db</td><td>移动 key 到 db</td></tr><tr><td>expire key 秒数</td><td>为 key 设置过期时间</td></tr><tr><td>ttl key</td><td>查看还有所少秒过期，-1表示永不过期，-2表示已过期</td></tr><tr><td>type key</td><td>查看 key 的类型</td></tr></tbody></table><h3 id="string-单值单-value"><a href="#string-单值单-value" class="headerlink" title="string (单值单 value)"></a>string (单值单 value)</h3><table><thead><tr><th>指令</th><th>作用</th></tr></thead><tbody><tr><td>set/get/del/append/strlen</td><td>增、查、删、追加、返回长度</td></tr><tr><td>lncr/decr/incrby/decrby</td><td>加1，减1，加n，减n(数字才能加减，n路:incrby k1 n)</td></tr><tr><td>getrange/setrange</td><td>getrange: 获取指定区间范围内的值，从零到负一表示全部。<br>setrange: 设置指定区间范围内的值，格式是setrange key 开始位 值(例:setrange k1 0 xxx)</td></tr><tr><td>setex key 秒数 值</td><td>即 set with expire，设置带过期时间的 key，动态设置</td></tr><tr><td>setnx key value</td><td>即 set if not exist，只有在 key 不存在时设置 key 的值</td></tr><tr><td>mset/mget/msetnx</td><td>mset: 同时设置一个或多个 key-value 对。<br>mget: 获取所有(一个或多个)给定 key 的值。<br>msetnx: 同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。</td></tr><tr><td>getset</td><td>即先 get 再 set，将给定 key 的值设为 value ，并返回 key 的旧值(old value)。</td></tr></tbody></table><h3 id="list-单值多-value"><a href="#list-单值多-value" class="headerlink" title="list (单值多 value)"></a>list (单值多 value)</h3><table><thead><tr><th>指令</th><th>作用</th></tr></thead><tbody><tr><td>lpush/rpush/lrange</td><td>lpush: 从左侧按顺序添加(例: lpush list01 1 2 3 4 5)<br>rpush: 从右侧按顺序添加(例: rpush list02 1 2 3 4 5)<br>lrange: 按范围查询(lrange 列表名 0 -1 查询全部)</td></tr><tr><td>lpop/rpop</td><td>lpop: 左出；rpop: 右出(lpop/rpop 列表名)</td></tr><tr><td>lindex</td><td>通过索引获取列表中的元素 lindex key index</td></tr><tr><td>llen</td><td>返回列表 key 的长度</td></tr><tr><td>lerm key count value</td><td>删除 count 个等于 value 的 key，如果 count 为0则删除全部</td></tr><tr><td>ltrim key startindex endindex</td><td>截取指定索引区间的元素</td></tr><tr><td>rpoplpush 源列表 目的列表</td><td>移除列表的最后一个元素，并将该元素添加到另一个列表并返回</td></tr><tr><td>lset key index value</td><td>通过索引设置列表元素的值</td></tr><tr><td>linsert key before/after value1 value2</td><td>在 list 某个已有值的前后再添加具体值</td></tr></tbody></table><p><strong>性能分析</strong></p><p>它是一个字符串链表，left、right 都可以插入添加；<br>如果键不存在，创建新的链表；<br>如果键已存在，新增内容；<br>如果值全移除，对应的键也就消失了。<br>链表的操作无论是头和尾效率都极高，但假如是对中间元素进行操作，效率就很惨淡了。</p><h3 id="set-单值多-value"><a href="#set-单值多-value" class="headerlink" title="set (单值多 value)"></a>set (单值多 value)</h3><table><thead><tr><th>参数</th><th>作用</th></tr></thead><tbody><tr><td>sadd/smembers/sismember</td><td>添加、返回集合中的所有的成员(smembers key)、判断成员元素是否是集合的成员(sismember key value)</td></tr><tr><td>scard key</td><td>返回集合中元素的数量</td></tr><tr><td>srem key value1…valueN</td><td>移除集合中的一个或多个成员元素，不存在的成员元素会被忽略。</td></tr><tr><td>srandmember key [count]</td><td>返回集合中的一个随机元素。如果 count 为正数，且小于集合基数，那么命令返回一个包含 count 个元素的数组，数组中的元素各不相同。如果 count 大于等于集合基数，那么返回整个集合。如果 count 为负数，那么命令返回一个数组，数组中的元素可能会重复出现多次，而数组的长度为 count 的绝对值。</td></tr><tr><td>spop key [count]</td><td>用于移除集合中的指定 key 的一个或多个随机元素，移除后会返回移除的元素。</td></tr><tr><td>smove key1 key2 在key1里某个值</td><td>作用是将 key1 里的某个值赋给 key2</td></tr><tr><td>sdiff FIRST_KEY OTHER_KEY1..OTHER_KEYN</td><td>返回给定集合之间的差集。差集的结果来自前面的 FIRST_KEY ,而不是后面的 OTHER_KEY1，也不是整个 FIRST_KEY OTHER_KEY1..OTHER_KEYN 的差集。</td></tr><tr><td>sunion KEY KEY1..KEYN</td><td>返回给定集合的并集。不存在的集合 key 被视为空集。</td></tr><tr><td>sinter KEY KEY1..KEYN</td><td>返回给定所有给定集合的交集。 不存在的集合 key 被视为空集。 当给定集合当中有一个空集时，结果也为空集(根据集合运算定律)。</td></tr></tbody></table><h3 id="hash-KV-模式不变，但-V-是一个键值对"><a href="#hash-KV-模式不变，但-V-是一个键值对" class="headerlink" title="hash (KV 模式不变，但 V 是一个键值对)"></a>hash (KV 模式不变，但 V 是一个键值对)</h3><table><thead><tr><th>参数</th><th>作用</th></tr></thead><tbody><tr><td>hset/hget/hmset/hmget/hgetall/hdel</td><td>设值、获取、同时设值多个、获取所有给定字段的值、获取在哈希表中指定 key 的所有字段和值、删除一个或多个哈希表字段</td></tr><tr><td>hlen key</td><td>获取哈希表中字段的数量</td></tr><tr><td>hexists key field</td><td>查看哈希表 key 中，指定的字段是否存在</td></tr><tr><td>hkeys key/hvals key</td><td>获取所有哈希表中的字段、获取哈希表中所有值</td></tr><tr><td>hincrby key field increment/hincrbyfloatkey field increment</td><td>为哈希表 key 中的指定字段的整数值加上增量 increment 、为哈希表 key 中的指定字段的浮点数值加上增量 increment 。</td></tr><tr><td>hsetnx key field value</td><td>只有在字段 field 不存在时，设置哈希表字段的值。</td></tr></tbody></table><h3 id="zset-sorted-set，在set基础上，加一个score值。之前set是k1-v1-v2-v3，现在zset是k1-score1-v1-score2-v2"><a href="#zset-sorted-set，在set基础上，加一个score值。之前set是k1-v1-v2-v3，现在zset是k1-score1-v1-score2-v2" class="headerlink" title="zset (sorted set，在set基础上，加一个score值。之前set是k1 v1 v2 v3，现在zset是k1 score1 v1 score2 v2)"></a>zset (sorted set，在set基础上，加一个score值。之前set是k1 v1 v2 v3，现在zset是k1 score1 v1 score2 v2)</h3><table><thead><tr><th>参数</th><th>作用</th></tr></thead><tbody><tr><td>zadd/zrange</td><td>向有序集合添加一个或多个成员，或者更新已存在成员的分数、通过索引区间返回有序集合成指定区间内的成员</td></tr><tr><td>zrangebyscore key min max [WITHSCORES] [LIMIT]</td><td>返回有序集合中指定分数区间的成员列表。</td></tr><tr><td>zrem key member [member …]</td><td>移除有序集中的一个或多个成员，不存在的成员将被忽略。</td></tr><tr><td>zcard key/zcount key min max/zrank key member/zscore key member</td><td>获取有序集合的成员数、计算在有序集合中指定区间分数的成员数、返回有序集合中指定成员的索引、返回有序集中，成员的分数值</td></tr><tr><td>zrevrank key member</td><td>返回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序</td></tr><tr><td>zrevrange key start stop [WITHSCORES]</td><td>返回有序集中指定区间内的成员，通过索引，分数从高到底</td></tr><tr><td>zrevrangebyscore key max min [WITHSCORES]</td><td>返回有序集中指定分数区间内的成员，分数从高到低排序</td></tr></tbody></table><h2 id="四、配置文件"><a href="#四、配置文件" class="headerlink" title="四、配置文件"></a>四、配置文件</h2><ol><li>Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程<br>daemonize no</li><li>当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定<br>pidfile /var/run/redis.pid</li><li>指定Redis监听端口，默认端口为6379，作者在自己的一篇博文中解释了为什么选用6379作为默认端口，因为6379在手机按键上MERZ对应的号码，而MERZ取自意大利歌女Alessia Merz的名字<br>port 6379</li><li>绑定的主机地址<br>bind 127.0.0.1</li><li>当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能<br>timeout 300</li><li>指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose<br>loglevel verbose</li><li>日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null<br>logfile stdout</li><li>设置数据库的数量，默认数据库为0，可以使用SELECT <dbid>命令在连接上指定数据库id<br>databases 16</dbid></li><li>指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合<br>save <seconds> <changes><br>Redis默认配置文件中提供了三个条件：<br>save 900 1<br>save 300 10<br>save 60 10000<br>分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。</changes></seconds></li><li>指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大<br>rdbcompression yes</li><li>指定本地数据库文件名，默认值为dump.rdb<br>dbfilename dump.rdb</li><li>指定本地数据库存放目录<br>dir ./</li><li>设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步<br>slaveof <masterip> <masterport></masterport></masterip></li><li>当master服务设置了密码保护时，slav服务连接master的密码<br>masterauth <master-password></master-password></li><li>设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH <password>命令提供密码，默认关闭<br>requirepass foobared</password></li><li>设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息<br>maxclients 128</li><li>指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区<br>maxmemory <bytes></bytes></li><li>指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为no<br>appendonly no</li><li>指定更新日志文件名，默认为appendonly.aof<br>appendfilename appendonly.aof</li><li>指定更新日志条件，共有3个可选值：<br>no：表示等操作系统进行数据缓存同步到磁盘（快）<br>always：表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全）<br>everysec：表示每秒同步一次（折衷，默认值）<br>appendfsync everysec</li><li>指定是否启用虚拟内存机制，默认值为no，简单的介绍一下，VM机制将数据分页存放，由Redis将访问量较少的页即冷数据swap到磁盘上，访问多的页面由磁盘自动换出到内存中（在后面的文章我会仔细分析Redis的VM机制）<br>vm-enabled no</li><li>虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享<br>vm-swap-file /tmp/redis.swap</li><li>将所有大于vm-max-memory的数据存入虚拟内存,无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys),也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0<br>vm-max-memory 0</li><li>Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享，vm-page-size是要根据存储的 数据大小来设定的，作者建议如果存储很多小对象，page大小最好设置为32或者64bytes；如果存储很大大对象，则可以使用更大的page，如果不 确定，就使用默认值<br>vm-page-size 32</li><li>设置swap文件中的page数量，由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的，，在磁盘上每8个pages将消耗1byte的内存。<br>vm-pages 134217728</li><li>设置访问swap文件的线程数,最好不要超过机器的核数,如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4<br>vm-max-threads 4</li><li>设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启<br>glueoutputbuf yes</li><li>指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法<br>hash-max-zipmap-entries 64<br>hash-max-zipmap-value 512</li><li>指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍）<br>activerehashing yes</li><li>指定包含其它的配置文件，可以在同一主机上多个Redis实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件<br>include /path/to/local.conf</li></ol><h2 id="五、持久化"><a href="#五、持久化" class="headerlink" title="五、持久化"></a>五、持久化</h2><p> Redis 是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。</p><h3 id="RDB-Redis-DataBase"><a href="#RDB-Redis-DataBase" class="headerlink" title="RDB (Redis DataBase)"></a>RDB (Redis DataBase)</h3><h4 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h4><p>在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话讲的 Snapshot 快照，它恢复时是将快照文件直接读到内存里。(rdb 保存的是 dump.rdb 文件)</p><p>Redis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。</p><p>整个过程中，主进程是不进行任何 IO 操作的，这就确保了极高的性能。</p><p>如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那 RDB 方式要比AOF 方式更加的高效。RDB 的缺点是最后一次持久化后的数据可能丢失。</p><h4 id="fork"><a href="#fork" class="headerlink" title="fork"></a>fork</h4><p>fork 的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等）数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程。</p><h4 id="如何触发-RDB-快照"><a href="#如何触发-RDB-快照" class="headerlink" title="如何触发 RDB 快照"></a>如何触发 RDB 快照</h4><ol><li><p>配置文件中默认的快照配置，1分钟改1w次或5分钟改10次或15分钟改1次(可以冷拷贝后重新使用cp dump.rdb dump_new.rdb)</p></li><li><p>命令 save 或者 bgsave</p><p>Save：save 时只管保存，其它不管，全部阻塞。</p><p>BGSAVE：Redis 会在后台异步进行快照操作，快照同时还可以响应客户端请求。可以通过 lastsave 命令获取最后一次成功执行快照的时间</p></li><li><p>执行 flushall 命令，也会产生 dump.rdb 文件，但里面是空的，无意义</p></li></ol><h4 id="如何恢复"><a href="#如何恢复" class="headerlink" title="如何恢复"></a>如何恢复</h4><p>将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可</p><p>CONFIG GET dir 获取目录</p><h4 id="优劣"><a href="#优劣" class="headerlink" title="优劣"></a>优劣</h4><p>优势：适合大规模的数据恢复，对数据完整性和一致性要求不高</p><p>劣势：在一定间隔时间做一次备份，所以如果 redis 意外 down 掉的话，就</p><p>会丢失最后一次快照后的所有修改；fork 的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑</p><h4 id="如何停止"><a href="#如何停止" class="headerlink" title="如何停止"></a>如何停止</h4><p>动态停止所有 RDB 保存规则的方法：redis-cli config set save “”</p><h3 id="AOF-Append-Only-File"><a href="#AOF-Append-Only-File" class="headerlink" title="AOF (Append Only File)"></a>AOF (Append Only File)</h3><h4 id="是什么-1"><a href="#是什么-1" class="headerlink" title="是什么"></a>是什么</h4><p>以日志的形式来记录每个写操作，将 redis 执行过的所有写指令记录下来(读操作不记录)，只许追加文件但不可以改写文件，redis 启动之初会读取该文件重新构建数据，换言之，redis 重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。(AOF 保存的是 appendonly.aof 文件)</p><h4 id="AOF-启动-修复-恢复"><a href="#AOF-启动-修复-恢复" class="headerlink" title="AOF 启动/修复/恢复"></a>AOF 启动/修复/恢复</h4><h4 id="正常恢复"><a href="#正常恢复" class="headerlink" title="正常恢复"></a>正常恢复</h4><ol><li>启动：修改默认的 appendonly no，改为 yes</li><li>将有数据的 AOF 文件复制一份保存到对应目录( config get dir )</li><li>恢复：重启 redis 然后重新加载</li></ol><h4 id="异常恢复"><a href="#异常恢复" class="headerlink" title="异常恢复"></a>异常恢复</h4><ol><li>启动：修改默认的 appendonly no，改为 yes</li><li>备份被写坏的 AOF 文件</li><li>修复：redis-check-aof –fix 进行修复</li><li>恢复：重启 redis 然后重新加载</li></ol><h4 id="rewrite"><a href="#rewrite" class="headerlink" title="rewrite"></a>rewrite</h4><p><strong>是什么</strong></p><p>AOF 采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制，当 AOF 文件的大小超过所设定的阈值时，Redis 就会启动 AOF 文件的内容压缩，只保留可以恢复数据的最小指令集。可以使用命令 bgrewriteaof。</p><p><strong>重写原理</strong></p><p>AOF 文件持续增长而过大时，会 fork 出一条新进程来将文件重写(也是先写临时文件最后再 rename)，遍历新进程的内存中数据，每条记录有一条的 Set 语句。重写 AOF 文件的操作，并没有读取旧的 AOF 文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的 AOF 文件，这点和快照有点类似。</p><p><strong>触发机制</strong></p><p>redis 会记录上次重写时的 AOF 大小，默认配置是当 AOF 文件大小是上次 rewrite 后大小的一倍且文件大于 64M 时触发。</p><h4 id="优劣-1"><a href="#优劣-1" class="headerlink" title="优劣"></a>优劣</h4><p>优势：每修改同步：appendfsync always 同步持久化 每次发生数据变更会被立即记录到磁盘  性能较差但数据完整性比较好；每秒同步：appendfsync everysec    异步操作，每秒记录   如果一秒内宕机，有数据丢失；不同步：appendfsync no   从不同步。</p><p>劣势：相同数据集的数据而言 aof 文件要远大于 rdb 文件，恢复速度慢于 rdb；aof 运行效率要慢于 rdb，每秒同步策略效率较好，不同步效率和 rdb 相同。</p><h3 id="总结-用哪个"><a href="#总结-用哪个" class="headerlink" title="总结(用哪个)"></a>总结(用哪个)</h3><ol><li>RDB 持久化方式能够在指定的时间间隔能对你的数据进行快照存储</li><li>AOF 持久化方式记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据，AOF 命令以 redis 协议追加保存每次写的操作到文件末尾。redis 还能对 AOF 文件进行后台重写，使得 AOF 文件的体积不至于过大。</li><li>只做缓存：如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式。</li><li>同时开启两种持久化方式<ul><li>在这种情况下，当 redis 重启的时候会优先载入 AOF 文件来恢复原始的数据，因为在通常情况下 AOF 文件保存的数据集要比 RDB 文件保存的数据集要完整。</li><li>RDB 的数据不实时，同时使用两者时服务器重启也只会找 AOF 文件。那要不要只使用 AOF 呢？作者建议不要，因为 RDB 更适合用于备份数据库(AOF 在不断变化不好备份)，快速重启，而且不会有 AOF 可能潜在的 bug，留着作为一个万一的手段。</li></ul></li><li>性能建议<ul><li>因为 RDB 文件只用作后备用途，建议只在 Slave 上持久化 RDB 文件，而且只要15分钟备份一次就够了，只保留 save 900 1 这条规则。</li><li>如果 Enalbe AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只 load 自己的 AOF 文件就可以了。代价一是带来了持续的 IO，二是 AOF rewrite 的最后将 rewrite 过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少 AOF rewrite 的频率，AOF 重写的基础大小默认值64M 太小了，可以设到 5G 以上。默认超过原大小 100% 大小时重写可以改到适当的数值。</li><li>如果不 Enable AOF ，仅靠 Master-Slave Replication 实现高可用性也可以。能省掉一大笔 IO 也减少了 rewrite 时带来的系统波动。代价是如果 Master/Slave 同时倒掉，会丢失十几分钟的数据，启动脚本也要比较两个 Master/Slave 中的 RDB 文件，载入较新的那个。新浪微博就选用了这种架构。</li></ul></li></ol><h2 id="六、事务"><a href="#六、事务" class="headerlink" title="六、事务"></a>六、事务</h2><h3 id="是什么-2"><a href="#是什么-2" class="headerlink" title="是什么"></a>是什么</h3><p>可以一次执行多个命令，本质是一组命令的集合。一个事务中的所有命令都会序列化，按顺序地串行化执行而不会被其它命令插入，不许加塞。</p><h3 id="能干嘛"><a href="#能干嘛" class="headerlink" title="能干嘛"></a>能干嘛</h3><p>一个队列中，一次性、顺序性、排他性的执行一系列命令。</p><h4 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h4><ol><li>正常执行</li><li>放弃事务</li><li>全体连坐(一条有错，全军覆没)</li><li>冤头债主(exec 才发现的错误，不影响事务中其他语句的执行)</li><li>watch 监控<ul><li>场景：初始化信用卡可用余额和欠额<ul><li>无加塞篡改，先监控再开启 multi，保证两笔金额变动在同一个事务内。</li><li>有加塞篡改，监控了 key，如果 key 被修改了，后面一个事务的执行失效。</li><li>unwatch</li><li>一旦执行了 exec 之前加的监控锁都会被取消掉了</li></ul></li><li>小结<ul><li>Watch 指令，类似乐观锁，事务提交时，如果 Key 的值已被别的客户端改变，比如某个 list 已被别的客户端 push/pop 过了，整个事务队列都不会被执行。</li><li>通过 WATCH 命令在事务执行之前监控了多个 Keys，倘若在 WATCH 之后有任何 Key 的值发生了变化，EXEC 命令执行的事务都将被放弃，同时返回 Nullmulti-bulk 应答以通知调用者事务执行失败。</li></ul></li></ul></li></ol><h3 id="指令"><a href="#指令" class="headerlink" title="指令"></a>指令</h3><table><thead><tr><th>指令</th><th>作用</th></tr></thead><tbody><tr><td>DISCARD</td><td>取消事务，放弃执行事务块内的所有命令。</td></tr><tr><td>EXEC</td><td>执行所有事务块内的命令。</td></tr><tr><td>MULTI</td><td>标记一个事务块的开始。</td></tr><tr><td>UNWATCH</td><td>取消 WATCH 命令对所有 key 的监视。</td></tr><tr><td>WATCH key [key …]</td><td>监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。</td></tr></tbody></table><h3 id="三阶段"><a href="#三阶段" class="headerlink" title="三阶段"></a>三阶段</h3><p>开启：以 MULTI 开始一个事务。</p><p>入队：将多个命令入队到事务中，接到这些命令并不会立即执行，而是放到等待执行的事务队列里面。</p><p>执行：由 EXEC 命令触发事务。</p><h3 id="三特性"><a href="#三特性" class="headerlink" title="三特性"></a>三特性</h3><p>单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</p><p>没有隔离级别的概念：队列中的命令没有提交之前都不会实际的被执行，因为事务提交前任何指令都不会被实际执行，也就不存在”事务内的查询要看到事务里的更新，在事务外查询不能看到”这个让人万分头痛的问题。</p><p>不保证原子性：redis 同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚。(部分支持事务：全体连坐和冤头债主)</p><h2 id="七、发布订阅"><a href="#七、发布订阅" class="headerlink" title="七、发布订阅"></a>七、发布订阅</h2><h3 id="是什么-3"><a href="#是什么-3" class="headerlink" title="是什么"></a>是什么</h3><p>进程间的一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。</p><p>下图展示了频道 channel1 ， 以及订阅这个频道的三个客户端 —— client2 、 client5 和 client1 之间的关系：</p><p><img src="http://qnya.pomo16.club/211.png" alt></p><p>当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端：</p><p><img src="http://qnya.pomo16.club/212.png" alt></p><p>实际中不会用 redis 做消息中间件</p><h2 id="八、复制"><a href="#八、复制" class="headerlink" title="八、复制"></a>八、复制</h2><h3 id="是什么-4"><a href="#是什么-4" class="headerlink" title="是什么"></a>是什么</h3><p>行话：也就是我们所说的主从复制，主机数据更新后根据配置和策略，自动同步到备机的 master/slaver 机制，Master以写为主，Slave以读为主。</p><h3 id="能干嘛-1"><a href="#能干嘛-1" class="headerlink" title="能干嘛"></a>能干嘛</h3><p>读写分离、容灾恢复</p><h3 id="怎么玩"><a href="#怎么玩" class="headerlink" title="怎么玩"></a>怎么玩</h3><ol><li><p>配从(库)不配主(库)</p></li><li><p>从库配置：slaveof 主库IP 主库端口</p><ul><li>每次与 master 断开之后，都需要重新连接，除非你配置进 redis.conf 文件</li><li>info replication</li></ul></li><li><p>修改配置文件细节操作</p><ul><li>拷贝多个 redis.conf 文件</li><li>开启 daemonize yes</li><li>pid 文件名字 (pidfile)</li><li>指定端口 (port)</li><li>log 文件名字 (logfile)</li><li>dump.rdb 名字 (dbfilename)</li></ul></li><li><p>常用技能</p><ul><li><p>一主二仆</p><ul><li><p>Init</p></li><li><p>一个 Master 两个 Slave</p></li><li><p>日志查看：主机日志、备机日志、info replication(查看状态)</p></li><li><p>一些问题</p><p>1 切入点问题？slave1、slave2 是从头开始复制还是从切入点开始复制?比如从 k4 进来，那之前的123是否也可以复制？（✔️）</p><p>2 从机是否可以写？set可否？（❌，读写分离呀，从机不可写。）</p><p>3 主机 shutdown 后情况如何？从机是上位还是原地待命？（从机原地待命。）</p><p>4 主机又回来了后，主机新增记录，从机还能否顺利复制？(可以，主机回来自动恢复)</p><p>5 其中一台从机 down 后情况如何？依照原有它能跟上大部队吗？(从机只要和 master 断开就要重连)</p></li></ul></li><li><p>薪火相传</p><ul><li>上一个 Slave 可以是下一个 Slave 的 Master，Slave 同样可以接收其他 Slaves 的连接和同步请求，那么该 Slave 作为了链条中下一个的 Master，可以有效减轻 Master 的写压力。</li><li>中途变更转向:会清除之前的数据，重新建立拷贝最新的。</li><li>slaveof 新主库IP 新主库端口</li></ul></li><li><p>反客为主</p><ul><li>SLAVEOF no one</li><li>使当前数据库停止与其他数据库的同步，转成主数据库</li></ul></li></ul></li></ol><h3 id="复制原理"><a href="#复制原理" class="headerlink" title="复制原理"></a>复制原理</h3><ol><li>slave 启动成功连接到 master 后会发送一个 sync 命令。</li><li>Master 接到命令启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，master 将传送整个数据文件到 slave，以完成一次完全同步。</li><li>全量复制：而 slave 服务在接收到数据库文件数据后，将其存盘并加载到内存中。</li><li>增量复制：Master 继续将新的所有收集到的修改命令依次传给 slave,完成同步。</li><li>但是只要是重新连接 master，一次完全同步（全量复制）将被自动执行。</li></ol><h3 id="哨兵模式-sentinel"><a href="#哨兵模式-sentinel" class="headerlink" title="哨兵模式 (sentinel)"></a>哨兵模式 (sentinel)</h3><p>反客为主的自动版，能够后台监控主机是否故障，如果故障了根据投票数自动将从库转换为主库。一组 sentinel 能同时监控多个 Master。</p><p><strong>使用步骤</strong></p><ol><li>调整结构，6379带着80、81</li><li>自定义的 /myredis 目录下新建 sentinel.conf 文件，名字绝不能错</li><li>配置哨兵，填写内容<ul><li>sentinel monitor 被监控数据库名字(自己起名字) 127.0.0.1 6379 1</li><li>上面最后一个数字1，表示主机挂掉后 salve 投票看让谁接替成为主机，得票数多少后成为主机</li></ul></li><li>启动哨兵<ul><li>redis-sentinel /myredis/sentinel.conf </li><li>上述目录依照各自的实际情况配置，可能目录不同</li></ul></li><li>正常主从演示，原有的master挂了，投票新选</li><li>重新主从继续开工，info replication查查看</li><li>问题：如果之前的 master 重启回来，会不会双 master 冲突？(❌，和反客为主不大一样，老 master 回来会变成新 master 的 slave)</li></ol><h3 id="复制的缺点"><a href="#复制的缺点" class="headerlink" title="复制的缺点"></a>复制的缺点</h3><p>复制延时：由于所有的写操作都是先在 Master 上操作，然后同步更新到 Slave 上，所以从 Master 同步到 Slave 机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，Slave 机器数量的增加也会使这个问题更加严重。</p><h2 id="九、Jedis"><a href="#九、Jedis" class="headerlink" title="九、Jedis"></a>九、Jedis</h2><h3 id="package"><a href="#package" class="headerlink" title="package"></a>package</h3><p>commons-pool-1.6.jar、jedis-2.1.0.jar</p><h3 id="连通性测试"><a href="#连通性测试" class="headerlink" title="连通性测试"></a>连通性测试</h3><p>返回 pong 则为连通</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//连接本地的 Redis 服务</span></span><br><span class="line">        Jedis jedis = <span class="keyword">new</span> Jedis(<span class="string">"127.0.0.1"</span>,<span class="number">6379</span>);</span><br><span class="line">        <span class="comment">// 查看服务是否运行，打出pong表示OK</span></span><br><span class="line">        System.out.println(<span class="string">"connection is OK==========&gt;: "</span> + jedis.ping());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="日常使用"><a href="#日常使用" class="headerlink" title="日常使用"></a>日常使用</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Set;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestAPI</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">Jedis jedis = <span class="keyword">new</span> Jedis(<span class="string">"127.0.0.1"</span>,<span class="number">6379</span>);</span><br><span class="line"></span><br><span class="line">jedis.set(<span class="string">"k1"</span>,<span class="string">"v1"</span>);</span><br><span class="line">jedis.set(<span class="string">"k2"</span>,<span class="string">"v2"</span>);</span><br><span class="line">jedis.set(<span class="string">"k3"</span>,<span class="string">"v3"</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">System.out.println(jedis.get(<span class="string">"k3"</span>));</span><br><span class="line"></span><br><span class="line">Set&lt;String&gt; sets = jedis.keys(<span class="string">"*"</span>);</span><br><span class="line">System.out.println(sets.size());</span><br><span class="line"></span><br><span class="line"><span class="comment">//后续请参考脑图，家庭作业，敲一遍......</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><p>加锁事务场景模拟</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.Transaction;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestTX</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">transMethod</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        Jedis jedis = <span class="keyword">new</span> Jedis(<span class="string">"127.0.0.1"</span>, <span class="number">6379</span>);</span><br><span class="line">        <span class="keyword">int</span> balance;<span class="comment">// 可用余额100元（set balance 100）</span></span><br><span class="line">        <span class="keyword">int</span> debt;<span class="comment">// 欠额(set debt 0)</span></span><br><span class="line">        <span class="keyword">int</span> amtToSubtract = <span class="number">10</span>;<span class="comment">// 实刷额度10元</span></span><br><span class="line"></span><br><span class="line">        jedis.watch(<span class="string">"balance"</span>);</span><br><span class="line">        <span class="comment">// jedis.set("balance","5");</span></span><br><span class="line">        <span class="comment">// 此句不该出现，模拟其他程序已经修改了该条目</span></span><br><span class="line">        <span class="comment">// 模拟系统停顿7秒，期间若有改动，则该程序能够监控到变化</span></span><br><span class="line">        Thread.sleep(<span class="number">7000</span>);</span><br><span class="line">        balance = Integer.parseInt(jedis.get(<span class="string">"balance"</span>));</span><br><span class="line">        <span class="keyword">if</span> (balance &lt; amtToSubtract) &#123;</span><br><span class="line">            jedis.unwatch();</span><br><span class="line">            System.out.println(<span class="string">"modify"</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">"***********transaction"</span>);</span><br><span class="line">            Transaction transaction = jedis.multi();</span><br><span class="line">            transaction.decrBy(<span class="string">"balance"</span>, amtToSubtract);</span><br><span class="line">            transaction.incrBy(<span class="string">"debt"</span>, amtToSubtract);</span><br><span class="line">            transaction.exec();</span><br><span class="line">            balance = Integer.parseInt(jedis.get(<span class="string">"balance"</span>));</span><br><span class="line">            debt = Integer.parseInt(jedis.get(<span class="string">"debt"</span>));</span><br><span class="line"></span><br><span class="line">            System.out.println(<span class="string">"*******"</span> + balance);</span><br><span class="line">            System.out.println(<span class="string">"*******"</span> + debt);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 通俗点讲，watch命令就是标记一个键，如果标记了一个键，</span></span><br><span class="line"><span class="comment">     * 在提交事务前如果该键被别人修改过，那事务就会失败，这种情况通常可以在程序中</span></span><br><span class="line"><span class="comment">     * 重新再尝试一次。</span></span><br><span class="line"><span class="comment">     * 首先标记了键balance，然后检查余额是否足够，不足就取消标记，并不做扣减；</span></span><br><span class="line"><span class="comment">     * 足够的话，就启动事务进行更新操作，</span></span><br><span class="line"><span class="comment">     * 如果在此期间键balance被其它人修改， 那在提交事务（执行exec）时就会报错，</span></span><br><span class="line"><span class="comment">     * 程序中通常可以捕获这类错误再重新执行一次，直到成功。</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> InterruptedException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        TestTX test = <span class="keyword">new</span> TestTX();</span><br><span class="line">        <span class="keyword">boolean</span> retValue = test.transMethod();</span><br><span class="line">        System.out.println(<span class="string">"main retValue-------: "</span> + retValue);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h3><p>6379,6380启动，先各自先独立，主写从读。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestMS</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">Jedis jedis_M = <span class="keyword">new</span> Jedis(<span class="string">"127.0.0.1"</span>,<span class="number">6379</span>);</span><br><span class="line">Jedis jedis_S = <span class="keyword">new</span> Jedis(<span class="string">"127.0.0.1"</span>,<span class="number">6380</span>);</span><br><span class="line"></span><br><span class="line">jedis_S.slaveof(<span class="string">"127.0.0.1"</span>,<span class="number">6379</span>);</span><br><span class="line"></span><br><span class="line">jedis_M.set(<span class="string">"class"</span>,<span class="string">"1122V2"</span>);</span><br><span class="line"></span><br><span class="line">String result = jedis_S.get(<span class="string">"class"</span>);</span><br><span class="line">System.out.println(result);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="JedisPool"><a href="#JedisPool" class="headerlink" title="JedisPool"></a>JedisPool</h3><p>获取 Jedis 实例需要从 JedisPool 中获取。</p><p>用完 Jedis 实例需要返还给 JedisPool。</p><p>如果 Jedis 在使用过程中出错，则也需要还给 JedisPool。</p><p>连接池（懒汉式单例）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.JedisPool;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.JedisPoolConfig;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JedisPoolUtil</span> </span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">volatile</span> JedisPool jedisPool = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="title">JedisPoolUtil</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> JedisPool <span class="title">getJedisPoolInstance</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(<span class="keyword">null</span> == jedisPool)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">synchronized</span> (JedisPoolUtil.class)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">if</span>(<span class="keyword">null</span> == jedisPool)</span><br><span class="line">&#123;</span><br><span class="line">JedisPoolConfig poolConfig = <span class="keyword">new</span> JedisPoolConfig();</span><br><span class="line">poolConfig.setMaxActive(<span class="number">1000</span>);</span><br><span class="line">poolConfig.setMaxIdle(<span class="number">32</span>);</span><br><span class="line">poolConfig.setMaxWait(<span class="number">100</span>*<span class="number">1000</span>);</span><br><span class="line">poolConfig.setTestOnBorrow(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">jedisPool = <span class="keyword">new</span> JedisPool(poolConfig,<span class="string">"127.0.0.1"</span>,<span class="number">6379</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> jedisPool;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">release</span><span class="params">(JedisPool jedisPool,Jedis jedis)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(<span class="keyword">null</span> != jedis)</span><br><span class="line">&#123;</span><br><span class="line">jedisPool.returnResourceObject(jedis);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试连接池：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> redis.clients.jedis.Jedis;</span><br><span class="line"><span class="keyword">import</span> redis.clients.jedis.JedisPool;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestPool</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">JedisPool jedisPool = JedisPoolUtil.getJedisPoolInstance();</span><br><span class="line">JedisPool jedisPool2 = JedisPoolUtil.getJedisPoolInstance();</span><br><span class="line"></span><br><span class="line">System.out.println(jedisPool == jedisPool2);</span><br><span class="line"></span><br><span class="line">Jedis jedis = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">jedis = jedisPool.getResource();</span><br><span class="line">jedis.set(<span class="string">"aa"</span>,<span class="string">"bb"</span>);</span><br><span class="line">&#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">e.printStackTrace();</span><br><span class="line">&#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">JedisPoolUtil.release(jedisPool, jedis);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>配置</strong></p><p>JedisPool 的配置参数大部分是由 JedisPoolConfig 的对应项来赋值的。</p><p><strong>maxActive</strong>：控制一个 pool 可分配多少个 jedis 实例，通过 pool.getResource() 来获取；如果赋值为 -1，则表示不限制；如果 pool 已经分配了 maxActive 个 jedis 实例，则此时 pool 的状态为 exhausted。</p><p><strong>maxIdle</strong>：控制一个 pool 最多有多少个状态为 idle(空闲) 的 jedis 实例。</p><p>whenExhaustedAction：表示当 pool 中的 jedis 实例都被 allocated 完时，pool 要采取的操作，默认有三种：</p><ul><li>WHEN_EXHAUSTED_FAIL –&gt; 表示无jedis实例时，直接抛出 NoSuchElementException</li><li>WHEN_EXHAUSTED_BLOCK –&gt; 则表示阻塞住，或者达到 maxWait 时抛出JedisConnectionException</li><li>WHEN_EXHAUSTED_GROW –&gt; 则表示新建一个jedis实例，也就说设置的maxActive无用；</li></ul><p><strong>maxWait</strong>：表示当 borrow 一个 jedis 实例时，最大的等待时间，如果超过等待时间，则直接抛 JedisConnectionException。</p><p><strong>testOnBorrow</strong>：获得一个 jedis 实例的时候是否检查连接可用性（ping()）；如果为 true，则得到的 jedis 实例均是可用的。</p><p>testOnReturn：return  一个 jedis 实例给 pool 时，是否检查连接可用性（ping()）；</p><p>testWhileIdle：如果为 true，表示有一个 idle object evitor 线程对 idle object 进行扫描，如果 validate 失败，此 object 会被从 pool 中 drop 掉；这一项只有在 timeBetweenEvictionRunsMillis 大于0时才有意义。</p><p>timeBetweenEvictionRunsMillis：表示 idle object evitor 两次扫描之间要 sleep 的毫秒数。</p><p>numTestsPerEvictionRun：表示 idle object evitor 每次扫描的最多的对象数。</p><p>minEvictableIdleTimeMillis：表示一个对象至少停留在 idle 状态的最短时间，然后才能被 idle object evitor 扫描并驱逐；这一项只有在 timeBetweenEvictionRunsMillis 大于0时才有意义。</p><p>softMinEvictableIdleTimeMillis：在 minEvictableIdleTimeMillis 基础上，加入了至少 minIdle 个对象已经在 pool 里面了。如果为 -1，evicted 不会根据 idle time 驱逐任何对象。如果 minEvictableIdleTimeMillis&gt;0，则此项设置无意义，且只有在 timeBetweenEvictionRunsMillis 大于0时才有意义；</p><p>lifo：borrowObject 返回对象时，是采用 DEFAULT_LIFO（last in first out，即类似cache的最频繁使用队列），如果为 False，则表示 FIFO 队列；</p><hr><p>其中 JedisPoolConfig 对一些参数的默认设置如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">testWhileIdle = <span class="keyword">true</span></span><br><span class="line">minEvictableIdleTimeMills = <span class="number">60000</span></span><br><span class="line">timeBetweenEvictionRunsMillis = <span class="number">30000</span></span><br><span class="line">numTestsPerEvictionRun = -<span class="number">1</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      Redis攻略
    
    </summary>
    
      <category term="java" scheme="http://yoursite.com/categories/java/"/>
    
      <category term="Redis" scheme="http://yoursite.com/categories/java/Redis/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="Redis" scheme="http://yoursite.com/tags/Redis/"/>
    
  </entry>
  
</feed>
